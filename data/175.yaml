- en: Fine-Tuning Stable Diffusion with LoRA
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 LoRA 微调稳定扩散
- en: 原文：[https://machinelearningmastery.com/fine-tuning-stable-diffusion-with-lora/](https://machinelearningmastery.com/fine-tuning-stable-diffusion-with-lora/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://machinelearningmastery.com/fine-tuning-stable-diffusion-with-lora/](https://machinelearningmastery.com/fine-tuning-stable-diffusion-with-lora/)
- en: Stable Diffusion can generate an image based on your input. There are many models
    that are similar in architecture and pipeline, but their output can be quite different.
    There are many ways to adjust their behavior, such as when you give a prompt,
    the output will be in a certain style by default. LoRA is one technique that does
    not require you to recreate a large model. In this post, you will see how you
    can create a LoRA on your own.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 稳定扩散可以根据你的输入生成图像。有许多模型在架构和流程上类似，但它们的输出可能差别很大。有许多方法可以调整它们的行为，例如，当你给出一个提示时，输出默认会呈现某种风格。LoRA
    是一种不需要重新创建大型模型的技术。在这篇文章中，你将看到如何自己创建一个 LoRA。
- en: After finishing this post, you will learn
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 完成本文后，你将学习到
- en: How to prepare and train a LoRA model
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何准备和训练 LoRA 模型
- en: How to use the trained LoRA in Python
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在 Python 中使用训练好的 LoRA
- en: '**Kick-start your project** with my book [Mastering Digital Art with Stable
    Diffusion](https://machinelearningmastery.com/mastering-digital-art-with-stable-diffusion/).
    It provides **self-study tutorials** with **working code**.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**启动你的项目**，可以参考我的书籍 [《掌握稳定扩散数字艺术》](https://machinelearningmastery.com/mastering-digital-art-with-stable-diffusion/)。它提供了
    **自学教程** 和 **可运行的代码**。'
- en: Let’s get started.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: '![](../Images/995f329f4e69f8321a2ac32530d3a5bd.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/995f329f4e69f8321a2ac32530d3a5bd.png)'
- en: Fine-tuning Stable Diffusion with LoRA
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 LoRA 微调稳定扩散
- en: Photo by [Thimo Pedersen](https://unsplash.com/photos/red-and-white-ladybug-toy-on-white-and-yellow-book-dip9IIwUK6w).
    Some rights reserved.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源 [Thimo Pedersen](https://unsplash.com/photos/red-and-white-ladybug-toy-on-white-and-yellow-book-dip9IIwUK6w)。部分权利保留。
- en: Overview
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: This post is in three parts; they are
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本文分为三个部分；它们是
- en: Preparation for Training a LoRA
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 训练 LoRA 的准备工作
- en: Training a LoRA with Diffusers Library
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Diffusers 库训练 LoRA
- en: Using Your Trained LoRA
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用你训练好的 LoRA
- en: Preparation for Training a LoRA
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 训练 LoRA 的准备工作
- en: We covered the idea of using LoRA in the Web UI in a [previous post](https://machinelearningmastery.com/using-lora-in-stable-diffusion/).
    If you want to create your own LoRA, a plugin in the Web UI allows you to do that,
    or you can create one using your own program. Since all training will be computationally
    intensive, be sure you have a machine with GPU to continue.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 [上一篇文章](https://machinelearningmastery.com/using-lora-in-stable-diffusion/)
    中介绍了在 Web UI 中使用 LoRA 的概念。如果你想创建自己的 LoRA，Web UI 插件允许你这样做，或者你可以使用自己的程序来创建一个。由于所有训练将是计算密集型的，请确保你有一台配备
    GPU 的机器继续进行。
- en: 'We will use the training script from the example directory of the diffusers
    library. Before you start, you have to set up the environment by installing the
    required Python libraries, using the following commands:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用来自 diffusers 库示例目录的训练脚本。在开始之前，你需要通过安装所需的 Python 库来设置环境，使用以下命令：
- en: '[PRE0]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: The first command is to install the `diffusers` library from GitHub, which will
    be the development version. This is required because you will use the training
    script from GitHub, hence you should use the matching version.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个命令是从 GitHub 安装 `diffusers` 库，这是开发版本。这样做是因为你将使用来自 GitHub 的训练脚本，因此需要使用匹配的版本。
- en: 'The last command above confirmed you have installed the `accelerate` library
    and detect what GPU you have on your computer. You have downloaded and installed
    many libraries. You can try to run the Python statements below to confirm that
    all are installed correctly and that you have no import error:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 上述最后一个命令确认你已经安装了 `accelerate` 库，并检测了你计算机上的 GPU。你已经下载并安装了许多库。你可以尝试运行下面的 Python
    语句来确认所有库已正确安装，并且没有导入错误：
- en: '[PRE1]'
  id: totrans-22
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You will use the LoRA training script from the examples of diffusers. Let’s
    download the script first:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 你将使用来自 diffusers 示例的 LoRA 训练脚本。首先下载脚本：
- en: '[PRE2]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Training a LoRA with Diffusers Library
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Diffusers 库训练 LoRA
- en: For fine-tuning, you will be using the [Pokémon BLIP captions with English and
    Chinese dataset](https://huggingface.co/datasets/svjack/pokemon-blip-captions-en-zh)
    on the base model `runwayml/stable-diffusion-v1-5` (the official Stable Diffusion
    v1.5 model). You can adjust hyperparameters to suit your specific use case, but
    you can start with the following Linux shell commands.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 对于微调，你将使用 [Pokémon BLIP captions with English and Chinese dataset](https://huggingface.co/datasets/svjack/pokemon-blip-captions-en-zh)
    在基础模型 `runwayml/stable-diffusion-v1-5`（官方 Stable Diffusion v1.5 模型）上。你可以调整超参数以适应你的具体用例，但你可以从以下
    Linux shell 命令开始。
- en: '[PRE3]'
  id: totrans-27
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Running this command will take hours to complete, even with a high-end GPU.
    But let’s look closer at what this does.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此命令将需要几个小时才能完成，即使使用高端 GPU。但让我们更详细地了解一下它的作用。
- en: The accelerate command helps you to launch the training across multiple GPUs.
    It does no harm if you have just one. Many modern GPUs support the “Brain Float
    16” floating point introduced by the Google Brain project. If it is supported,
    the option `--mixed_precision="bf16"` will save memory and run faster.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: accelerate 命令帮助你在多个 GPU 上启动训练。如果你只有一个 GPU，也不会有害。许多现代 GPU 支持 Google Brain 项目引入的“Brain
    Float 16”浮点数。如果支持，选项 `--mixed_precision="bf16"` 将节省内存并运行更快。
- en: The command script downloads the dataset from the Hugging Face Hub and uses
    it to train a LoRA model. The batch size, training steps, learning rate, and so
    on are the hyperparameters for the training. The trained model will be checkpointed
    once every 500 steps to the output directory.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令脚本从 Hugging Face Hub 下载数据集，并使用它来训练 LoRA 模型。批量大小、训练步骤、学习率等是训练的超参数。训练好的模型会在每500步时将检查点保存到输出目录。
- en: Training a LoRA requires a dataset with images (pixels) and corresponding captions
    (text). The caption text describes the image, and the trained LoRA will understand
    that these captions should mean those images. If you check out the dataset on
    Hugging Face Hub, you will see the caption name was `en_text`, and that is set
    to `--caption_column` above.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 训练 LoRA 需要一个包含图像（像素）和对应标题（文本）的数据集。标题文本描述了图像，而训练好的 LoRA 将理解这些标题应代表那些图像。如果你查看
    Hugging Face Hub 上的数据集，你会看到标题名称是 `en_text`，如上所述设置为 `--caption_column`。
- en: 'If you are providing your own dataset instead (e.g., manually create captions
    for the images you gathered), you should create a CSV file `metadata.csv` with
    first column named `file_name` and second column to be your text captions, like
    the following:'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你提供自己的数据集（例如，手动为你收集的图像创建标题），你应该创建一个 CSV 文件 `metadata.csv`，第一列命名为 `file_name`，第二列为你的文本标题，如下所示：
- en: '[PRE4]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: and keep this CSV together with all your images (matching the `file_name` column)
    in the same directory, and use the directory name as your dataset name.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 并将此 CSV 文件与所有图像（匹配 `file_name` 列）放在同一目录中，并使用目录名作为你的数据集名称。
- en: There will be many subdirectories and files created under the directory as assigned
    to `OUTPUT_DIR` in the script above. Each checkpoint will contain the full Stable
    Diffusion model weight, and extracted LoRA safetensors. Once you finish the training,
    you can delete all of them except the final LoRA file, `pytorch_lora_weights.safetensors`.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述脚本中指定为 `OUTPUT_DIR` 的目录下将创建许多子目录和文件。每个检查点将包含完整的稳定扩散模型权重和提取的 LoRA safetensors。一旦你完成训练，你可以删除除了最终
    LoRA 文件 `pytorch_lora_weights.safetensors` 之外的所有文件。
- en: Using Your Trained LoRA
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用你的训练好的 LoRA
- en: 'Running a Stable Diffusion pipeline with LoRA just require a small modification
    to your Python code. An example would be the following:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 运行一个稳定扩散（Stable Diffusion）管道与 LoRA 只需要对你的 Python 代码做一个小修改。一个例子如下：
- en: '[PRE5]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The code above downloaded a LoRA from the Hugging Face Hub repository `pcuenq/pokemon-lora`
    and attach it to the pipeline using the line `pipe.unet.load_attn_procs(model_path)`.
    The rest is just as usual. The image generated may look like the following:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码从 Hugging Face Hub 存储库 `pcuenq/pokemon-lora` 下载了一个 LoRA 并使用 `pipe.unet.load_attn_procs(model_path)`
    将其附加到管道中。其余的与平常一样。生成的图像可能如下所示：
- en: '![](../Images/9bdee499d4377ef93bbb00b2885ed4f6.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9bdee499d4377ef93bbb00b2885ed4f6.png)'
- en: Green pokemon as generated
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的绿色宝可梦
- en: This is the more verbose way of using the LoRA since you have to know that this
    particular LoRA should be loaded to the attention process of the pipeline’s `unet`
    part. Such details should be found in the model card in the repository.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用 LoRA 的一种更详细的方法，因为你需要知道这个特定的 LoRA 应该被加载到管道的 `unet` 部分的注意力过程（attention process）中。这些细节应该在存储库的模型卡中找到。
- en: 'An easier way of using the LoRA would be to use the auto pipeline, from which
    the model architecture is inferred from the model file:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 使用LoRA的更简单方法是使用自动流水线，从中推断出模型架构从模型文件中：
- en: '[PRE6]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The parameters to `load_lora_weights()` is the directory name and the file name
    to your trained LoRA file. This works for other LoRA files, such as those you
    downloaded from Civitai.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '`load_lora_weights()`函数的参数是您训练的LoRA文件的目录名称和文件名称。这也适用于其他LoRA文件，比如您从Civitai下载的文件。'
- en: Further Reading
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: This section provides more resources on the topic if you want to go deeper.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您希望更深入地了解该主题，本节提供了更多资源。
- en: 'LoRA training: [https://huggingface.co/docs/diffusers/en/training/lora](https://huggingface.co/docs/diffusers/en/training/lora)'
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LoRA训练：[https://huggingface.co/docs/diffusers/en/training/lora](https://huggingface.co/docs/diffusers/en/training/lora)
- en: 'Stable Diffusion text2image pipeline: [https://huggingface.co/docs/diffusers/v0.29.0/en/api/pipelines/stable_diffusion/text2img](https://huggingface.co/docs/diffusers/v0.29.0/en/api/pipelines/stable_diffusion/text2img)'
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 稳定扩散文本转图像流水线：[https://huggingface.co/docs/diffusers/v0.29.0/en/api/pipelines/stable_diffusion/text2img](https://huggingface.co/docs/diffusers/v0.29.0/en/api/pipelines/stable_diffusion/text2img)
- en: Summary
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: In this post, you saw how to create your own LoRA model, given a set of images
    and the description text. This is a time-consuming process, but the result is
    that you have a small weight file that can modify the behavior of the diffusion
    model. You learned how to run the training of LoRA using `diffusers` library.
    You also saw how to use a LoRA weight in your Stable Diffusion pipeline code.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，您看到如何根据一组图像和描述文本创建自己的LoRA模型。这是一个耗时的过程，但结果是您拥有一个可以修改扩散模型行为的小权重文件。您学会了如何使用`diffusers`库运行LoRA的训练。您还看到了如何在您的稳定扩散流水线代码中使用LoRA权重。
