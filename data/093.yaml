- en: Massaging Data Using Pandas
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Pandas 处理数据
- en: 原文：[https://machinelearningmastery.com/massaging-data-using-pandas/](https://machinelearningmastery.com/massaging-data-using-pandas/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://machinelearningmastery.com/massaging-data-using-pandas/](https://machinelearningmastery.com/massaging-data-using-pandas/)
- en: When we talk about managing data, it is quite inevitable to see data presented
    in tables. With column header, and sometimes with names for rows, it makes understanding
    data easier. In fact, it often happens that we see data of different types staying
    together. For example, we have quantity as numbers and name as strings in a table
    of ingredients for a recipe. In Python, we have the pandas library to help us
    handle tabular data.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们谈论数据管理时，看到以表格形式呈现的数据是不可避免的。带有列头，并且有时还会有行名，使得理解数据更容易。事实上，我们经常会看到不同类型的数据混在一起。例如，我们在一个食谱的配料表中，数量是数字，名称是字符串。在
    Python 中，我们可以使用 pandas 库来处理表格数据。
- en: 'After finishing this tutorial, you will learn:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 完成本教程后，你将学习到：
- en: What the pandas library provides
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: pandas 库提供了什么
- en: What is a DataFrame and a Series in pandas
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 pandas 中什么是 DataFrame 和 Series
- en: How to manipulate DataFrame and Series beyond the trivial array operations
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何超越平凡的数组操作来操纵 DataFrame 和 Series
- en: '**Kick-start your project** with my new book [Python for Machine Learning](https://machinelearningmastery.com/python-for-machine-learning/),
    including *step-by-step tutorials* and the *Python source code* files for all
    examples.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**启动你的项目**，请参考我新书[《Python 机器学习》](https://machinelearningmastery.com/python-for-machine-learning/)，包括*逐步教程*和*所有示例的
    Python 源代码*文件。'
- en: Let’s get started!![](../Images/bba3496226ca0851a3b7f37a917dae1b.png)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！！[](../Images/bba3496226ca0851a3b7f37a917dae1b.png)
- en: Massaging Data Using Pandas
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 Pandas 处理数据
- en: Photo by [Mark de Jong](https://www.pexels.com/photo/a-giant-panda-eating-bamboo-leaves-6939449/).
    Some rights reserved.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 照片来源：[Mark de Jong](https://www.pexels.com/photo/a-giant-panda-eating-bamboo-leaves-6939449/)。保留所有权利。
- en: Overview
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'This tutorial is divided into five parts:'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程分为五部分：
- en: DataFrame and Series
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DataFrame 和 Series
- en: Essential functions in DataFrame
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DataFrame 中的基本函数
- en: Manipulating DataFrames and Series
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 操作 DataFrames 和 Series
- en: Aggregation in DataFrames
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DataFrames 中的聚合
- en: Handling time series data in pandas
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 处理 pandas 中的时间序列数据
- en: DataFrame and Series
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DataFrame 和 Series
- en: 'To begin, let’s start with an example dataset. We will import pandas and read
    the [U.S. air pollutant emission data](https://www.epa.gov/air-emissions-inventories/air-pollutant-emissions-trends-data) into
    a DataFrame:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，让我们从一个示例数据集开始。我们将导入 pandas 并读取[美国空气污染物排放数据](https://www.epa.gov/air-emissions-inventories/air-pollutant-emissions-trends-data)到一个
    DataFrame 中：
- en: '[PRE0]'
  id: totrans-20
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: This is a table of pollutant emissions for each year, with the information on
    what kind of pollutant and the amount of emission per year.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一张每年的污染物排放表，包含了污染物种类和每年的排放量信息。
- en: 'Here we demonstrated one useful feature from pandas: You can read a CSV file
    using `read_csv()` or read an Excel file using `read_excel(),` as above. The filename
    can be a local file in your machine or an URL from where the file can be downloaded.
    We learned about this URL from the U.S. Environmental Protection Agency’s website.
    We know which worksheet contains the data and from which row the data starts,
    hence the extra arguments to the `read_excel()` function.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 这里我们演示了 pandas 的一个有用功能：你可以使用 `read_csv()` 读取 CSV 文件，或使用 `read_excel()` 读取 Excel
    文件。文件名可以是你机器上的本地文件或可以从中下载文件的 URL。我们从美国环境保护局的网站了解了这个 URL。我们知道哪个工作表包含数据以及数据从哪个行开始，因此在
    `read_excel()` 函数中添加了额外的参数。
- en: 'The pandas object created above is a DataFrame, presented as a table. Similar
    to NumPy, data in Pandas are organized in arrays. But Pandas assign a data type
    to columns rather than an entire array. This allows data of different types to
    be included in the same data structure. We can check the data type by either calling
    the `info()` function from the DataFrame:'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 上面创建的 pandas 对象是一个 DataFrame，以表格形式呈现。类似于 NumPy，Pandas 中的数据组织在数组中。但 Pandas 将数据类型分配给列，而不是整个数组。这允许不同类型的数据包含在同一个数据结构中。我们可以通过调用
    DataFrame 的 `info()` 函数来检查数据类型：
- en: '[PRE2]'
  id: totrans-25
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[PRE3]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'or we can also get the type as a pandas Series:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 或者我们也可以获取 pandas Series 类型：
- en: '[PRE4]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[PRE5]'
  id: totrans-29
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: In pandas, a DataFrame is a table, while a Series is a column of the table.
    This distinction is important because data behind a DataFrame is a 2D array while
    a Series is a 1D array.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在 pandas 中，DataFrame 是一个表格，而 Series 是表格中的一列。这一区分很重要，因为 DataFrame 背后的数据是一个二维数组，而
    Series 是一个一维数组。
- en: 'Similar to the fancy indexing in NumPy, we can extract columns from one DataFrame
    to create another:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于 NumPy 中的 fancy indexing，我们可以从一个 DataFrame 中提取列以创建另一个 DataFrame：
- en: '[PRE6]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[PRE7]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Or, if we pass in a column name as a string rather than a list of column names,
    we extract a column from a DataFrame as a Series:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果我们传递的是列名字符串而不是列名列表，我们可以从DataFrame中提取一个列作为Series：
- en: '[PRE8]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[PRE9]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Essential Functions in DataFrame
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DataFrame中的基本函数
- en: 'Pandas is feature-rich. Many essential operations on a table or a column are
    provided as functions defined on the DataFrame or Series. For example, we can
    see a list of pollutants covered in the table above by using:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas功能丰富。对表格或列的许多基本操作都作为DataFrame或Series上的函数提供。例如，我们可以通过以下方式查看上表中覆盖的污染物列表：
- en: '[PRE10]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '[PRE11]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'And we can find the mean (`mean()`), standard deviation (`std()`), minimum
    (`min()`), and maximum (`max()`) of a series similarly:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以找到系列的均值（`mean()`）、标准偏差（`std()`）、最小值（`min()`）和最大值（`max()`）：
- en: '[PRE12]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'But in fact, we are more likely to use the `describe()` function to explore
    a new DataFrame. Since the DataFrame in this example has too many columns, it
    is better to transpose the resulting DataFrame from `describe()`:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 但事实上，我们更可能使用`describe()`函数来探索新的DataFrame。由于本示例中的DataFrame列太多，最好是将`describe()`的结果转置为新的DataFrame：
- en: '[PRE13]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[PRE14]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Indeed, the DataFrame produced by `describe()` can help us get a sense of the
    data. From there, we can tell how much missing data there is (by looking at the
    count), how the data are distributed, whether there are outliers, and so on.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 的确，`describe()`生成的DataFrame可以帮助我们了解数据。从那里，我们可以了解到有多少缺失数据（通过查看计数），数据如何分布，是否存在异常值等等。
- en: Want to Get Started With Python for Machine Learning?
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 想要开始学习Python进行机器学习吗？
- en: Take my free 7-day email crash course now (with sample code).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 现在就免费获取我的7天电子邮件速成课程（包含示例代码）。
- en: Click to sign-up and also get a free PDF Ebook version of the course.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 点击注册并获得课程的免费PDF电子书版本。
- en: Manipulating DataFrame and Series
  id: totrans-50
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 操纵DataFrame和Series
- en: 'Similar to the Boolean indexing in NumPy, we can extract a subset of **rows** from
    a DataFrame. For example, this is how we can select the data for carbon monoxide
    emissions only:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于NumPy中的布尔索引，我们可以从DataFrame中提取一部分**行**。例如，以下是如何仅选择一氧化碳排放数据的方法：
- en: '[PRE15]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: '[PRE16]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'As you may expect, the `==` operator compares each element from a series `df["Pollutant"]`
    , resulting in a series of Boolean. If the lengths match, the DataFrame understands
    it is to select the rows based on the Boolean value. In fact, we can combine Booleans
    using bitwise operators. For example, this is how we select the rows of carbon
    monoxide emissions due to highway vehicles:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 正如您可能期望的那样，`==`运算符将从系列`df["Pollutant"]`中比较每个元素，结果是一个布尔值系列。如果长度匹配，DataFrame会根据布尔值选择行。实际上，我们可以使用位运算符组合布尔值。例如，这就是我们如何选择由高速公路车辆导致的一氧化碳排放行：
- en: '[PRE17]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: '[PRE18]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'If you prefer to select rows like a Python list, you may do so via the `iloc`
    interface. This is how we can select rows 5 to 10 (zero-indexed) or columns 1
    to 6 and rows 5 to 10:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您喜欢像Python列表一样选择行，可以通过`iloc`接口进行。以下是如何选择行5到10（从零开始索引）或列1到6以及行5到10的方法：
- en: '[PRE19]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'If you’re familiar with Excel, you probably know one of its exciting features
    called a “pivot table.” Pandas allows you to do the same. Let’s consider the pollution
    of carbon monoxide from all states in 2021 from this dataset:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您熟悉Excel，可能知道其令人兴奋的功能之一是“数据透视表”。Pandas允许您做同样的事情。让我们考虑从数据集中获取2021年所有州的一氧化碳污染：
- en: '[PRE20]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: '[PRE21]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Through the pivot table, we can make the different ways of emitting carbon
    monoxide as columns and different states as rows:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 通过数据透视表，我们可以将不同的一氧化碳排放方式作为列，不同的州作为行：
- en: '[PRE22]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '[PRE23]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'The `pivot_table()` function above does not require the values to be unique
    to the index and columns. In other words, should there be two “wildfire” rows
    in a state in the original DataFrame, this function will aggregate the two (the
    default is to take the mean). To reverse the pivot operation, we have the `melt()` function:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 上述`pivot_table()`函数不要求值在索引和列中唯一。换句话说，如果原始DataFrame中某个州有两行“wildfire”，该函数将对这两行进行聚合（默认为取平均值）。要撤销数据透视操作，我们使用`melt()`函数：
- en: '[PRE24]'
  id: totrans-66
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: '[PRE25]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: There is way more we can do with a DataFrame. For example, we can sort the rows
    (using the `sort_values()` function), rename columns (using the `rename()` function),
    remove redundant rows (`drop_duplicates()` function), and so on.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame还有更多操作可以进行。例如，我们可以对行进行排序（使用`sort_values()`函数）、重命名列（使用`rename()`函数）、移除冗余行（使用`drop_duplicates()`函数）等等。
- en: 'In a machine learning project, we often need to do some clean-up before we
    can use the data. It is handy to use pandas for this purpose. The `df_pivot` DataFrame
    we just created has some values marked as `NaN` for no data available. We can
    replace all those with zero with any of the following:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习项目中，我们经常需要在使用数据之前进行一些清理工作。使用 pandas 这一点非常方便。我们刚刚创建的 `df_pivot` DataFrame
    中有一些标记为`NaN`的值表示没有可用数据。我们可以用以下任何一种方法将这些值替换为零：
- en: '[PRE26]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE26]'
- en: Aggregation in DataFrames
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DataFrame 中的聚合
- en: 'In fact, pandas can provide table manipulation that otherwise can only be easily
    done using database SQL statements. Reusing the above example dataset, each pollutant
    in the table is broken down into different sources. If we want to know the aggregated
    pollutant emissions, we can just sum up all the sources. Similar to SQL, this
    is a “group by” operation. We can do so with the following:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，pandas 可以提供表格操作，否则只能使用数据库 SQL 语句轻松完成。重用上述示例数据集，表中每种污染物都被分解为不同的来源。如果我们想知道污染物的总排放量，我们只需将所有来源的数据相加即可。类似于
    SQL，这是一种“group by”操作。我们可以用以下方式做到：
- en: '[PRE27]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE27]'
- en: '[PRE28]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE28]'
- en: The result of the `groupby()` function will use the grouping column as the row
    index. It works by putting rows that have the same value for that grouping column
    into a group. Then as a group, some **aggregate** function is applied to reduce
    the many rows into one. In the above example, we are taking the sum across each
    column. Pandas comes with many other aggregate functions, such as taking the mean
    or just counting the number of rows. Since we are doing `sum()`, the non-numeric
    columns are dropped from the output as they do not apply to the operation.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '`groupby()` 函数的结果将使用分组列作为行索引。它通过将具有相同分组列值的行放入一个组中来运行。然后，作为一个组，应用某些**聚合**函数将多行减少为一行。在上述示例中，我们正在对每列进行求和。Pandas
    提供了许多其他聚合函数，例如计算均值或仅计数行数。因为我们在做`sum()`操作，非数值列从输出中被删除，因为它们不适用于该操作。'
- en: 'This allows us to do some interesting tasks. Let’s say, using the data in the
    DataFrame above, we create a table of the total emission of carbon monoxide (CO)
    and sulfur dioxide (SO2) in 2021 in each state. The reasoning on how to do that
    would be:'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这使我们能够执行一些有趣的任务。假设，使用上述 DataFrame 中的数据，我们创建了一个表，其中包含 2021 年每个州中一氧化碳（CO）和二氧化硫（SO2）的总排放量。如何实现这一点的推理如下：
- en: Group by “State” and “Pollutant,” then sum up each group. This is how we get
    the total emission of each pollutant in each state.
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 按“State”和“Pollutant”分组，然后对每个组进行求和。这是我们获取每个州中每种污染物的总排放量的方法。
- en: Select only the column for 2021
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 仅选择 2021 年的列
- en: Run pivot table to make states the rows and the pollutants the columns with
    the total emission as the values
  id: totrans-79
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 运行数据透视表，使州成为行，污染物成为列，总排放量作为值
- en: Select only the column for CO and SO2
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 仅选择 CO 和 SO2 的列
- en: 'In code, this can be:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在代码中，可以这样写：
- en: '[PRE29]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE29]'
- en: '[PRE30]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE30]'
- en: In the above code, each step after the `groupby()` function is to create a new
    DataFrame. Since we are using functions defined under DataFrame, we have the above
    functional **chained invocation syntax**.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述代码中，`groupby()` 函数后的每一步都是创建一个新的 DataFrame。由于我们使用的函数在 DataFrame 下定义，因此我们有上述功能链式调用语法。
- en: The `sum()` function will create a DataFrame from the `GroupBy` object that
    has the grouped columns “State” and “Pollutant” as an index. Therefore, after
    we diced the DataFrame to only one column, we used `reset_index()` to make the
    index as columns (i.e., there will be three columns, `State`, `Pollutant`, and `emissions21`).
    Since there will be more pollutants than we need, we use `filter()` to select
    only the columns for CO and SO2 from the resulting DataFrame. This is similar
    to using fancy indexing to select columns.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '`sum()`函数将创建一个 DataFrame，其中“State”和“Pollutant”作为索引的分组列。因此，当我们将 DataFrame 切片为只有一列时，我们使用了
    `reset_index()` 将索引作为列（即会有三列，`State`、`Pollutant` 和 `emissions21`）。由于我们需要的污染物比我们需要的多，我们使用
    `filter()` 从结果 DataFrame 中仅选择 CO 和 SO2 的列。这类似于使用花式索引来选择列。'
- en: 'Indeed, we can do the same differently:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，我们可以以不同的方式完成同样的操作：
- en: Select only the rows for CO and compute the total emission; select only the
    data for 2021
  id: totrans-87
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 仅选择 CO 的行并计算总排放量；仅选择 2021 年的数据
- en: Do the same for SO2
  id: totrans-88
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对 SO2 也是一样
- en: Combine the resulting DataFrame in the previous two steps
  id: totrans-89
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将前两步的结果 DataFrame 结合在一起
- en: 'In pandas, there is a `join()` function in DataFrame that helps us combine
    the columns with another DataFrame by matching the index. In code, the above steps
    are as follows:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在 pandas 中，DataFrame 中有一个 `join()` 函数，可以帮助我们通过匹配索引将列与另一个 DataFrame 结合起来。在代码中，以上步骤如下：
- en: '[PRE31]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE31]'
- en: 'The `join()` function is limited to index matching. If you’re familiar with
    SQL, the `JOIN` clause’s equivalent in pandas is the `merge()` function. If the
    two DataFrames we created for CO and SO2 have the states as a separate column,
    we can do the same as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '`join()`函数仅限于索引匹配。如果你熟悉 SQL，pandas 中`JOIN`子句的等效函数是`merge()`。如果我们为 CO 和 SO2
    创建的两个 DataFrame 中有一个单独的州列，我们可以按照以下方式进行相同的操作：'
- en: '[PRE32]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE32]'
- en: The `merge()` function in pandas can do all types of SQL joins. We can match
    different columns from a different DataFrame, and we can do left join, right join,
    inner join, and outer join. This will be very useful when wrangling the data for
    your project.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 中的`merge()`函数可以执行所有类型的 SQL 连接。我们可以匹配来自不同 DataFrame 的不同列，并可以进行左连接、右连接、内连接和外连接。这在整理项目数据时非常有用。
- en: 'The `groupby()` function in a DataFrame is powerful as it allows us to manipulate
    the DataFrame flexibly and opens the door to many sophisticated transformations.
    There may be a case that no built-in function can help after `groupby(),` but
    we can always provide our own. For example, this is how we can create a function
    to operate on a sub-DataFrame (on all columns except the group-by column) and
    apply it to find the years of minimum and maximum emissions:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: DataFrame 中的`groupby()`函数非常强大，因为它允许我们灵活地操作 DataFrame，并开启了许多复杂转换的大门。可能在`groupby()`之后没有内置函数可以帮助，但我们总是可以提供自己的函数。例如，以下是如何创建一个函数来操作子
    DataFrame（在所有列中，除了分组列）并应用它来找出最小和最大排放年份：
- en: '[PRE33]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE33]'
- en: The `apply()` function is the last resort to provide us the maximum flexibility.
    Besides GroupBy objects, there are also `apply()` interfaces in DataFrames and
    Series.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '`apply()`函数是最后的手段，它为我们提供了最大的灵活性。除了 GroupBy 对象，还有 DataFrames 和 Series 中的`apply()`接口。'
- en: 'The following is the complete code to demonstrate all operations we introduced
    above:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是演示我们上面介绍的所有操作的完整代码：
- en: '[PRE34]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE34]'
- en: Handling Time Series Data in Pandas
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 处理 Pandas 中的时间序列数据
- en: 'You will find another powerful feature from pandas if you are dealing with
    time series data. To begin, let’s consider some daily pollution data. We can select
    and download some from the EPA’s website:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你处理时间序列数据，你会发现 pandas 还有另一个强大的功能。首先，让我们考虑一些每日的污染数据。我们可以从 EPA 网站选择并下载一些数据：
- en: '[https://www.epa.gov/outdoor-air-quality-data/download-daily-data](https://www.epa.gov/outdoor-air-quality-data/download-daily-data)'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.epa.gov/outdoor-air-quality-data/download-daily-data](https://www.epa.gov/outdoor-air-quality-data/download-daily-data)'
- en: 'For illustration purposes, we downloaded the PM2.5 data of Texas in 2021\.
    We can import the [downloaded CSV](https://machinelearningmastery.com/wp-content/uploads/2022/04/ad_viz_plotval_data.csv)
    file, `ad_viz_plotval_data.csv`, as follows:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 为了演示目的，我们下载了 2021 年德克萨斯州的 PM2.5 数据。我们可以如下导入[下载的 CSV](https://machinelearningmastery.com/wp-content/uploads/2022/04/ad_viz_plotval_data.csv)
    文件`ad_viz_plotval_data.csv`：
- en: '[PRE35]'
  id: totrans-104
  prefs: []
  type: TYPE_PRE
  zh: '[PRE35]'
- en: '[PRE36]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE36]'
- en: The `read_csv()` function from pandas allows us to specify some columns as the
    date and parse them into `datetime` objects rather than a string. This is essential
    for further processing time series data. As we know, the first column (zero-indexed)
    is the date column; we provide the argument `parse_dates=[0]` above.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: pandas 的`read_csv()`函数允许我们指定某些列作为日期，并将其解析为`datetime`对象，而不是字符串。这对于进一步处理时间序列数据至关重要。如我们所知，第一列（从零开始计数）是日期列；我们在上面提供了参数`parse_dates=[0]`。
- en: 'For manipulating time series data, it is important to use time as an index
    in your DataFrame. We can make one of the columns an index by the `set_index()`
    function:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 对于处理时间序列数据，重要的是在 DataFrame 中使用时间作为索引。我们可以通过`set_index()`函数将其中一列设置为索引：
- en: '[PRE37]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE37]'
- en: '[PRE38]'
  id: totrans-109
  prefs: []
  type: TYPE_PRE
  zh: '[PRE38]'
- en: 'If we examine the index of this DataFrame, we will see the following:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们检查这个 DataFrame 的索引，我们会看到以下内容：
- en: '[PRE39]'
  id: totrans-111
  prefs: []
  type: TYPE_PRE
  zh: '[PRE39]'
- en: '[PRE40]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE40]'
- en: We know its type is `datetime64`, which is a timestamp object in pandas.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道它的类型是`datetime64`，这是 pandas 中的时间戳对象。
- en: 'From the index above, we can see each date is not unique. This is because the
    PM2.5 concentration is observed in different sites, and each will contribute a
    row to the DataFrame. We can filter the DataFrame to only one site to make the
    index unique. Alternatively, we can use `pivot_table()` to transform the DataFrame,
    where the pivot operation guarantees the resulting DataFrame will have unique
    index:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面的索引中，我们可以看到每个日期并非唯一。这是因为 PM2.5 浓度是在不同的地点观测到的，每个地点都会向 DataFrame 中添加一行。我们可以筛选
    DataFrame，只保留一个地点，以使索引唯一。或者，我们可以使用`pivot_table()`来转换 DataFrame，pivot 操作可以保证结果
    DataFrame 的索引是唯一的：
- en: '[PRE41]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE41]'
- en: '[PRE42]'
  id: totrans-116
  prefs: []
  type: TYPE_PRE
  zh: '[PRE42]'
- en: 'We can check the uniqueness with:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以通过以下方式检查唯一性：
- en: '[PRE43]'
  id: totrans-118
  prefs: []
  type: TYPE_PRE
  zh: '[PRE43]'
- en: 'Now, every column in this DataFrame is a **time series**. While pandas does
    not provide any forecasting function on the time series, it comes with tools to
    help you clean and transform the data. Setting a DateTimeIndex to a DataFrame
    will be handy for time series analysis projects because we can easily extract
    data for a time interval, e.g., the train-test split of the time series. Below
    is how we can extract a 3-month subset from the above DataFrame:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，这个数据框中的每一列都是一个**时间序列**。虽然pandas没有在时间序列上提供任何预测功能，但它提供了帮助您清洁和转换数据的工具。将DateTimeIndex设置为DataFrame将对时间序列分析项目非常有用，因为我们可以轻松提取时间间隔的数据，例如上述DataFrame中的3个月子集提取如下：
- en: '[PRE44]'
  id: totrans-120
  prefs: []
  type: TYPE_PRE
  zh: '[PRE44]'
- en: 'One commonly used function in a time series is to **resample** the data. Considering
    the daily data in this DataFrame, we can transform it into weekly observations
    instead. We can specify the resulting data to be indexed on every Sunday. But
    we still have to tell what we want the resampled data to be like. If it is sales
    data, we probably want to sum over the entire week to get the weekly revenue.
    In this case, we can take the average over a week to smooth out the fluctuations.
    An alternative is to take the first observation over each period, like below:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在时间序列中，常用的一个功能是**重新取样**数据。考虑到这个数据框中的日常数据，我们可以将其转换为每周观察。我们可以指定结果数据以每周星期日为索引。但我们仍然需要告诉它我们希望重新取样后的数据是什么样子的。如果是销售数据，我们可能希望在整个周内求和以得到周收入。在这种情况下，我们可以每周取平均以平滑波动。另一种选择是每个周期取第一个观察值，如下所示：
- en: '[PRE45]'
  id: totrans-122
  prefs: []
  type: TYPE_PRE
  zh: '[PRE45]'
- en: '[PRE46]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE46]'
- en: 'The string “`W-SUN`” is to determine the mean weekly on Sundays. It is called
    the “offset alias.” You can find the list of all offset alias from below:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 字符串“`W-SUN`”表示每周日进行平均。这被称为“偏移别名”。您可以在以下找到所有偏移别名的列表：
- en: '[https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases)'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases](https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#offset-aliases)'
- en: 'Resampling is particularly useful in financial market data. Imagine if we have
    the price data from the market, where the raw data does not come in regular intervals.
    We can still use resampling to convert the data into regular intervals. Because
    it is so commonly used, pandas even provides you the open-high-low-close (known
    as OHLC, i.e., first, maximum, minimum, and last observations over a period) from
    the resampling. We demonstrate below how to get the OHLC over a week on one of
    the observation sites:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在金融市场数据中，重新取样尤其有用。想象一下，如果我们有市场价格数据，其中原始数据不以常规间隔出现。我们仍然可以使用重新取样将数据转换为常规间隔。由于它非常常用，pandas甚至为您提供了开-高-低-收盘（称为OHLC，即周期内的第一个、最大、最小和最后观测值）的重新取样。我们以下演示如何在一个观察站上获取一周的OHLC：
- en: '[PRE47]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE47]'
- en: '[PRE48]'
  id: totrans-128
  prefs: []
  type: TYPE_PRE
  zh: '[PRE48]'
- en: 'In particular, if we resample a time series from a coarser frequency into a
    finer frequency, it is called **upsampling**. Pandas usually inserts `NaN` values
    during upsampling as the original time series does not have data during the in-between
    time instances. One way to avoid these `NaN` values during upsampling is to ask
    pandas to forward-fill (carry over values from an earlier time) or back-fill (using
    values from a later time) the data. For example, the following is to forward-fill
    the daily PM2.5 observations from one site into hourly:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 特别是，如果我们将时间序列从粗粒度频率重新取样为细粒度频率，则称为**上采样**。Pandas通常在上采样时插入`NaN`值，因为原始时间序列在中间时间实例时没有数据。避免在上采样时出现这些`NaN`值的一种方法是要求pandas前向填充（从较早的时间传递值）或后向填充（使用较晚时间的值）数据。例如，以下是将每日PM2.5观测值向前填充到每小时的操作：
- en: '[PRE49]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE49]'
- en: '[PRE50]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE50]'
- en: Besides resampling, we can also transform the data using a sliding window. For
    example, below is how we can make a 10-day moving average from the time series.
    It is not a resampling because the resulting data is still daily. But for each
    data point, it is the mean of the past 10 days. Similarly, we can find the 10-day
    standard deviation or 10-day maximum by applying a different function to the rolling
    object.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 除了重新取样，我们还可以使用滑动窗口来转换数据。例如，以下是如何从时间序列中制作一个10天的移动平均值。这不是重新取样，因为结果数据仍然是每日的。但对于每个数据点，它是过去10天的平均值。类似地，我们可以通过将不同函数应用于滚动对象来找到10天的标准偏差或10天的最大值。
- en: '[PRE51]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE51]'
- en: '[PRE52]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE52]'
- en: To show how the original and rolling average time series differs, below shows
    you the plot. We added the argument `min_periods=5` to the `rolling()` function
    because the original data has missing data on some days. This produces gaps in
    the daily data, but we ask that the mean still be computed as long as there are
    5 data points over the window of the past 10 days.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示原始数据和滚动平均时间序列的区别，下面展示了该图。我们向 `rolling()` 函数中添加了参数 `min_periods=5`，因为原始数据在某些天有缺失数据。这在每日数据中产生了间隙，但我们要求即使在过去
    10 天的窗口中只有 5 个数据点，均值仍然被计算。
- en: '[PRE53]'
  id: totrans-136
  prefs: []
  type: TYPE_PRE
  zh: '[PRE53]'
- en: '![](../Images/6c705a5b7db290b483c8c04c0f5a95cc.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6c705a5b7db290b483c8c04c0f5a95cc.png)'
- en: 'The following is the complete code to demonstrate the time series operations
    we introduced above:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是演示上述时间序列操作的完整代码：
- en: '[PRE54]'
  id: totrans-139
  prefs: []
  type: TYPE_PRE
  zh: '[PRE54]'
- en: Further Reading
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: 'Pandas is a feature-rich library with far more details than we can cover above.
    The following are some resources for you to go deeper:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: Pandas 是一个功能丰富的库，包含的细节远超我们上面所涵盖的内容。以下是一些资源，帮助你更深入地学习：
- en: API documentation
  id: totrans-142
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: API 文档
- en: '[pandas user guide](https://pandas.pydata.org/docs/user_guide/index.html#user-guide)'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[pandas 用户指南](https://pandas.pydata.org/docs/user_guide/index.html#user-guide)'
- en: '[pandas API reference](https://pandas.pydata.org/docs/reference/index.html#api)'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[pandas API 参考](https://pandas.pydata.org/docs/reference/index.html#api)'
- en: Books
  id: totrans-145
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 书籍
- en: '[Python for Data Analysis](https://www.amazon.com/dp/1491957662/), 2nd edition,
    by Wes McKinney'
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[《Python 数据分析》](https://www.amazon.com/dp/1491957662/)，第二版，作者**韦斯·麦金尼**'
- en: '**Summary**'
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**总结**'
- en: In this tutorial, you saw a brief overview of the functions provided by pandas.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，你了解了 pandas 提供的函数的简要概述。
- en: 'Specifically, you learned:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，你学到了：
- en: How to work with pandas DataFrames and Series
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用 pandas 的 DataFrames 和 Series
- en: How to manipulate DataFrames in a way similar to table operations in a relational
    database
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何以类似于关系数据库中表操作的方式操作 DataFrames
- en: How to make use of pandas to help manipulate time series data
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何利用 pandas 来帮助操作时间序列数据
