- en: How to Evaluate the Performance of PyTorch Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 如何评估PyTorch模型的性能
- en: 原文：[https://machinelearningmastery.com/how-to-evaluate-the-performance-of-pytorch-models/](https://machinelearningmastery.com/how-to-evaluate-the-performance-of-pytorch-models/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://machinelearningmastery.com/how-to-evaluate-the-performance-of-pytorch-models/](https://machinelearningmastery.com/how-to-evaluate-the-performance-of-pytorch-models/)
- en: Designing a deep learning model is sometimes an art. There are a lot of decision
    points, and it is not easy to tell what is the best. One way to come up with a
    design is by trial and error and evaluating the result on real data. Therefore,
    it is important to have a scientific method to evaluate the performance of your
    neural network and deep learning models. In fact, it is also the same method to
    compare any kind of machine learning models on a particular usage.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 设计深度学习模型有时是一门艺术。这里有许多决策点，很难判断哪种方案最好。设计的一种方法是通过试验和错误，并在实际数据上评估结果。因此，拥有科学的方法来评估神经网络和深度学习模型的性能非常重要。事实上，这也是比较任何机器学习模型在特定用途上的方法。
- en: 'In this post, you will discover the received workflow to robustly evaluate
    model performance. In the examples, we will use PyTorch to build our models, but
    the method can also be applied to other models. After completing this post, you
    will know:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，你将发现用于稳健评估模型性能的工作流程。在示例中，我们将使用PyTorch构建我们的模型，但该方法也适用于其他模型。完成这篇文章后，你将了解：
- en: How to evaluate a PyTorch model using a verification dataset
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用验证数据集评估PyTorch模型
- en: How to evaluate a PyTorch model with k-fold cross-validation
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用k折交叉验证评估PyTorch模型
- en: '**Kick-start your project** with my book [Deep Learning with PyTorch](https://machinelearningmastery.com/deep-learning-with-pytorch/).
    It provides **self-study tutorials** with **working code**.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我的书籍 [深度学习与PyTorch](https://machinelearningmastery.com/deep-learning-with-pytorch/)
    **启动你的项目**。它提供了**自学教程**和**有效代码**。
- en: Let’s get started.![](../Images/1dbc3c45767bd37c79ffc70d5105b3ec.png)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！[](../Images/1dbc3c45767bd37c79ffc70d5105b3ec.png)
- en: How to evaluate the performance of PyTorch models
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 如何评估PyTorch模型的性能
- en: Photo by [Kin Shing Lai](https://unsplash.com/photos/7qUtO7iNZ4M). Some rights
    reserved.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Kin Shing Lai](https://unsplash.com/photos/7qUtO7iNZ4M) 提供。保留部分权利。
- en: Overview
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'This chapter is in four parts; they are:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章分为四部分，它们是：
- en: Empirical Evaluation of Models
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型的经验评估
- en: Data Splitting
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据拆分
- en: Training a PyTorch Model with Validation
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用验证集训练PyTorch模型
- en: k-Fold Cross Validation
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: k折交叉验证
- en: Empirical Evaluation of Models
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 模型的经验评估
- en: In designing and configuring a deep learning model from scratch, there are a
    lot of decisions to make. This includes design decisions such as how many layers
    to use in a deep learning model, how big is each layer, and what kind of layers
    or activation functions to use. It can also be the choice of the loss function,
    optimization algorithm, number of epochs to train, and the interpretation of the
    model output. Luckily, sometimes, you can copy the structure of other people’s
    networks. Sometimes, you can just make up your choice using some heuristics. To
    tell if you made a good choice or not, the best way is to compare multiple alternatives
    by empirically evaluating them with actual data.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在从头设计和配置深度学习模型时，需要做出很多决策。这包括设计决策，如使用多少层，每层的大小，使用什么层或激活函数。这还可能包括损失函数的选择、优化算法、训练的轮次以及模型输出的解释。幸运的是，有时你可以复制其他人的网络结构。有时，你可以通过一些启发式方法来做出选择。要判断你是否做出了正确的选择，最好的方法是通过实际数据的经验评估来比较多个备选方案。
- en: Deep learning is often used on problems that have very large datasets. That
    is tens of thousands or hundreds of thousands of data samples. This provides ample
    data for testing. But you need to have a robust test strategy to estimate the
    performance of your model on unseen data. Based on that, you can have a metric
    to compare among different model configurations.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习常用于处理具有非常大数据集的问题，即数万或数十万的数据样本。这为测试提供了充足的数据。但你需要一个稳健的测试策略来估计模型在未见数据上的表现。基于此，你可以有一个指标来比较不同模型配置之间的优劣。
- en: Want to Get Started With Deep Learning with PyTorch?
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 想要开始使用PyTorch进行深度学习？
- en: Take my free email crash course now (with sample code).
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 现在就参加我的免费电子邮件速成课程（含示例代码）。
- en: Click to sign-up and also get a free PDF Ebook version of the course.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 点击注册并获取课程的免费PDF电子书版本。
- en: Data Splitting
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据拆分
- en: If you have a dataset of tens of thousands of samples or even more, you don’t
    always need to give everything to your model for training. This will unnecessarily
    increase the complexity and lengthen the training time. More is not always better.
    You may not get the best result.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你有数以万计甚至更多的样本数据集，不必总是将所有数据都提供给模型进行训练。这将不必要地增加复杂性并延长训练时间。更多并不总是更好。你可能得不到最佳结果。
- en: When you have a large amount of data, you should take a portion of it as the
    **training set** that is fed into the model for training. Another portion is kept
    as a **test set** to hold back from the training but verified with a trained or
    partially trained model as an evaluation. This step is usually called “train-test
    split.”
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 当你有大量数据时，应该将其中一部分作为**训练集**用于模型训练。另一部分作为**测试集**，在训练之外保留，但会用已训练或部分训练的模型进行验证。这一步通常称为“训练-测试分离”。
- en: 'Let’s consider the [Pima Indians Diabetes dataset](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv).
    You can load the data using NumPy:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们考虑[Pima Indians Diabetes 数据集](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv)。您可以使用
    NumPy 加载数据：
- en: '[PRE0]'
  id: totrans-26
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'There are 768 data samples. It is not a lot but is enough to demonstrate the
    split. Let’s consider the first 66% as the training set and the remaining as the
    test set. The easiest way to do so is by slicing an array:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 有 768 个数据样本。虽然不多，但足以演示分割。让我们将前 66% 视为训练集，剩余部分作为测试集。最简单的方法是通过对数组进行切片：
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The choice of 66% is arbitrary, but you do not want the training set too small.
    Sometimes you may use 70%-30% split. But if the dataset is huge, you may even
    use a 30%-70% split if 30% of training data is large enough.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 66% 的选择是任意的，但你不希望训练集太小。有时你可能会使用 70%-30% 的分割。但如果数据集很大，你甚至可以使用 30%-70% 的分割，如果训练数据的
    30% 足够大的话。
- en: If you split the data in this way, you’re suggesting the datasets are shuffled
    so that the training set and the test set are equally diverse. If you find the
    original dataset is sorted and take the test set only at the end, you may find
    you have all the test data belonging to the same class or carrying the same value
    in one of the input features. That’s not ideal.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 如果按此方式拆分数据，表明数据集已被洗牌，以使训练集和测试集同样多样化。如果发现原始数据集已排序，并且仅在最后取测试集，可能会导致所有测试数据属于同一类或在某个输入特征中具有相同值。这并不理想。
- en: 'Of course, you can call `np.random.shuffle(data)` before the split to avoid
    that. But many machine learning engineers usually use scikit-learn for this. See
    this example:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 当然，在拆分之前可以调用`np.random.shuffle(data)`来避免这种情况。但是许多机器学习工程师通常使用 scikit-learn 来实现这一点。请参阅以下示例：
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'But more commonly, it is done after you separate the input feature and output
    labels. Note that this function from scikit-learn can work not only on NumPy arrays
    but also on PyTorch tensors:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 但更常见的是，在分开输入特征和输出标签之后进行。请注意，这个来自 scikit-learn 的函数不仅可以在 NumPy 数组上工作，还可以在 PyTorch
    张量上工作：
- en: '[PRE3]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Training a PyTorch Model with Validation
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用验证训练 PyTorch 模型
- en: 'Let’s revisit the code for building and training a deep learning model on this
    dataset:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们重新审视在此数据集上构建和训练深度学习模型的代码：
- en: '[PRE4]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In this code, one batch is extracted from the training set in each iteration
    and sent to the model in the forward pass. Then you compute the gradient in the
    backward pass and update the weights.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段代码中，每次迭代从训练集中提取一个批次，并在前向传播中发送到模型。然后在反向传播中计算梯度并更新权重。
- en: While, in this case, you used binary cross entropy as the loss metric in the
    training loop, you may be more concerned with the prediction accuracy. Calculating
    accuracy is easy. You round off the output (in the range of 0 to 1) to the nearest
    integer so you can get a binary value of 0 or 1\. Then you count how much percentage
    your prediction matched the label; this gives you the accuracy.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在这种情况下，您在训练循环中使用二元交叉熵作为损失指标，但您可能更关心预测准确性。计算准确性很容易。您将输出（在 0 到 1 的范围内）四舍五入到最接近的整数，以便获得二进制值
    0 或 1。然后计算您的预测与标签匹配的百分比，这给出了准确性。
- en: 'But what is your prediction? It is `y_pred` above, which is the prediction
    by your current model on `X_batch`. Adding accuracy to the training loop becomes
    this:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 但你的预测是什么？它是上面的`y_pred`，这是您当前模型在`X_batch`上的预测。将准确性添加到训练循环变成了这样：
- en: '[PRE5]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: However, the `X_batch` and `y_batch` is used by the optimizer, and the optimizer
    will fine-tune your model so that it can predict `y_batch` from `X_batch`. And
    now you’re using accuracy to check if `y_pred` match with `y_batch`. It is like
    cheating because if your model somehow remembers the solution, it can just report
    to you the `y_pred` and get perfect accuracy without actually inferring `y_pred`
    from `X_batch`.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，`X_batch`和`y_batch`被优化器使用，优化器将微调你的模型，使其能够从`X_batch`预测`y_batch`。现在你使用准确率检查`y_pred`是否与`y_batch`匹配。这就像作弊一样，因为如果你的模型以某种方式记住了解决方案，它可以直接向你报告`y_pred`，而无需真正从`X_batch`中推断`y_pred`，并获得完美的准确率。
- en: 'Indeed, a deep learning model can be so convoluted that you cannot know if
    your model simply remembers the answer or is inferring the answer. Therefore,
    the best way is **not** to calculate accuracy from `X_batch` or anything from
    `X_train`but from something else: your test set. Let’s add an accuracy measurement
    **after** each epoch using `X_test`:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，一个深度学习模型可能复杂到你无法确定你的模型只是记住了答案还是推断了答案。因此，最好的方法是**不要**从`X_batch`或`X_train`中的任何内容计算准确率，而是从其他地方：你的测试集。让我们在每个时期结束后使用`X_test`添加准确率测量：
- en: '[PRE6]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In this case, the `acc` in the inner for-loop is just a metric showing the progress.
    Not much difference in displaying the loss metric, except it is not involved in
    the gradient descent algorithm. And you expect the accuracy to improve as the
    loss metric also improves.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，内部for循环中的`acc`只是一个显示进展的度量。与显示损失度量没有太大区别，只是它不参与梯度下降算法。你期望准确率随着损失度量的改善而提高。
- en: 'In the outer for-loop, at the end of each epoch, you calculate the accuracy
    from `X_test`. The workflow is similar: You give the test set to the model and
    ask for its prediction, then count the number of matched results with your test
    set labels. But this accuracy is the one you should care about. It should improve
    as the training progresses, but if you do not see it improve (i.e., accuracy increase)
    or even deteriorates, you have to interrupt the training as it seems to start
    overfitting. Overfitting is when the model started to remember the training set
    rather than learning to infer the prediction from it. A sign of that is the accuracy
    from the training set keeps increasing while the accuracy from the test set decreases.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在外部for循环中，每个时期结束时，你从`X_test`计算准确率。工作流程类似：你将测试集提供给模型并请求其预测，然后统计与测试集标签匹配的结果数量。但这正是你需要关注的准确率。它应该随着训练的进展而提高，但如果你没有看到它的提升（即准确率增加）甚至有所下降，你必须中断训练，因为它似乎开始过拟合。过拟合是指模型开始记住训练集而不是从中学习推断预测。一个迹象是训练集的准确率不断提高，而测试集的准确率却下降。
- en: 'The following is the complete code to implement everything above, from data
    splitting to validation using the test set:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是实现上述所有内容的完整代码，从数据拆分到使用测试集进行验证：
- en: '[PRE7]'
  id: totrans-48
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'The code above will print the following:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码将打印如下内容：
- en: '[PRE8]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: k-Fold Cross Validation
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: k折交叉验证
- en: In the above example, you calculated the accuracy from the test set. It is used
    as a **score** for the model as you progressed in the training. You want to stop
    at the point where this score is at its maximum. In fact, by merely comparing
    the score from this test set, you know your model works best after epoch 21 and
    starts to overfit afterward. Is that right?
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面的例子中，你从测试集计算了准确率。它被用作模型在训练过程中进展的**评分**。你希望在这个分数达到最大值时停止。实际上，仅仅通过比较这个测试集的分数，你就知道你的模型在第21个时期之后表现最佳，并且之后开始过拟合。对吗？
- en: If you built two models of different designs, should you just compare these
    models’ accuracy on the same test set and claim one is better than another?
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你构建了两个不同设计的模型，是否应该仅仅比较这些模型在同一测试集上的准确率，并声称一个比另一个更好？
- en: Actually, you can argue that the test set is not representative enough even
    after you have shuffled your dataset before extracting the test set. You may also
    argue that, by chance, one model fits better to this particular test set but not
    always better. To make a stronger argument on which model is better independent
    of the selection of the test set, you can try **multiple test sets** and average
    the accuracy.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，你可以认为即使在提取测试集之前已经打乱了数据集，测试集也不够具有代表性。你也可以认为，偶然间，一个模型可能更适合这个特定的测试集，但不一定总是更好。为了更强有力地论证哪个模型更好，不依赖于测试集的选择，你可以尝试**多个测试集**并计算准确率的平均值。
- en: This is what a k-fold cross validation does. It is a progress to decide on which
    **design** works better. It works by repeating the training process from scratch
    for $k$ times, each with a different composition of the training and test sets.
    Because of that, you will have $k$ models and $k$ accuracy scores from their respective
    test set. You are not only interested in the average accuracy but also the standard
    deviation. The standard deviation tells whether the accuracy score is consistent
    or if some test set is particularly good or bad in a model.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是k折交叉验证的作用。它是决定哪种**设计**效果更好的过程。它通过多次从头开始训练过程来工作，每次使用不同的训练和测试集组合。因此，您将得到$k$个模型和$k$个相应测试集的准确性分数。您不仅对平均准确率感兴趣，还对标准偏差感兴趣。标准偏差告诉您准确性分数是否一致，或者某些测试集在模型中特别好或特别差。
- en: 'Since k-fold cross validation trains the model from scratch a few times, it
    is best to wrap around the training loop in a function:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 由于k折交叉验证多次从头开始训练模型，最好将训练循环包装在函数中：
- en: '[PRE9]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: The code above is deliberately not printing anything (with `disable=True` in
    `tqdm`) to keep the screen less cluttered.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码故意不打印任何内容（使用`tqdm`中的`disable=True`）以保持屏幕整洁。
- en: 'Also from scikit-learn, you have a function for k-fold cross validation. You
    can make use of it to produce a robust estimate of model accuracy:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，在scikit-learn中，您有一个用于k折交叉验证的函数。您可以利用它来生成模型准确性的稳健估计：
- en: '[PRE10]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'Running this prints:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此命令将输出：
- en: '[PRE11]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: In scikit-learn, there are multiple k-fold cross validation functions, and the
    one used here is stratified k-fold. It assumes `y` are class labels and takes
    into account of their values such that it will provide a balanced class representation
    in the splits.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在scikit-learn中，有多个k折交叉验证函数，这里使用的是分层k折。它假设`y`是类标签，并考虑它们的值，以便在拆分中提供平衡的类表示。
- en: The code above used $k=5$ or 5 splits. It means splitting the dataset into five
    equal portions, picking one of them as the test set and combining the rest into
    a training set. There are five ways of doing that, so the for-loop above will
    have five iterations. In each iteration, you call the `model_train()` function
    and obtain the accuracy score in return. Then you save it into a list, which will
    be used to calculate the mean and standard deviation at the end.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码使用了$k=5$或5个拆分。这意味着将数据集分为五个相等的部分，选择其中一个作为测试集，将其余部分组合为训练集。有五种方法可以做到这一点，因此上述的for循环将进行五次迭代。在每次迭代中，您调用`model_train()`函数并得到准确率分数。然后将其保存到列表中，这将用于计算最终的均值和标准偏差。
- en: The `kfold` object will return to you the **indices**. Hence you do not need
    to run the train-test split in advance but use the indices provided to extract
    the training set and test set on the fly when you call the `model_train()` function.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '`kfold`对象将返回给您**索引**。因此，您无需提前运行训练-测试分割，而是在调用`model_train()`函数时使用提供的索引动态提取训练集和测试集。'
- en: The result above shows the model is moderately good, at 64% average accuracy.
    And this score is stable since the standard deviation is at 3%. This means that
    most of the time, you expect the model accuracy to be 61% to 67%. You may try
    to change the model above, such as adding or removing a layer, and see how much
    change you have in the mean and standard deviation. You may also try to increase
    the number of epochs used in training and observe the result.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的结果显示，该模型的表现适中，平均准确率为64%。由于标准偏差为3%，这意味着大部分时间，您预期模型的准确率在61%到67%之间。您可以尝试更改上述模型，例如添加或删除一层，并观察均值和标准偏差的变化。您也可以尝试增加训练中使用的时期数并观察结果。
- en: The mean and standard deviation from the k-fold cross validation is what you
    should use to benchmark a model design.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: k折交叉验证的均值和标准偏差是您应该用来评估模型设计的基准。
- en: 'Tying it all together, below is the complete code for k-fold cross validation:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 将所有内容综合起来，以下是完整的k折交叉验证代码：
- en: '[PRE12]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Summary
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In this post, you discovered the importance of having a robust way to estimate
    the performance of your deep learning models on unseen data, and you learned how
    to do that. You saw:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，您了解到在深度学习模型在未见数据上估计性能时，有一个稳健的方法的重要性，并学习了如何实现。您看到：
- en: How to split data into training and test sets using scikit-learn
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用scikit-learn将数据分割成训练集和测试集
- en: How to do k-fold cross validation with the help of scikit-learn
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在scikit-learn的帮助下进行k折交叉验证
- en: How to modify the training loop in a PyTorch model to incorporate test set validation
    and cross validation
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何修改 PyTorch 模型中的训练循环，以包括测试集验证和交叉验证
