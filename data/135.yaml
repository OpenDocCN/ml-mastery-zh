- en: Use PyTorch Deep Learning Models with scikit-learn
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 scikit-learn 的 PyTorch 深度学习模型
- en: 原文：[https://machinelearningmastery.com/use-pytorch-deep-learning-models-with-scikit-learn/](https://machinelearningmastery.com/use-pytorch-deep-learning-models-with-scikit-learn/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[原文](https://machinelearningmastery.com/use-pytorch-deep-learning-models-with-scikit-learn/)'
- en: 'The most popular deep learning libraries in Python for research and development
    are TensorFlow/Keras and PyTorch, due to their simplicity. The scikit-learn library,
    however, is the most popular library for general machine learning in Python. In
    this post, you will discover how to use deep learning models from PyTorch with
    the scikit-learn library in Python. This will allow you to leverage the power
    of the scikit-learn library for tasks like model evaluation and model hyper-parameter
    optimization. After completing this lesson you will know:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 中最受欢迎的深度学习库是 TensorFlow/Keras 和 PyTorch，由于它们的简洁性。然而，scikit-learn 库仍然是
    Python 中最受欢迎的通用机器学习库。在这篇文章中，你将发现如何将 PyTorch 的深度学习模型与 Python 中的 scikit-learn 库结合使用。这将使你能够利用
    scikit-learn 库的强大功能进行模型评估和模型超参数优化。完成本课程后，你将知道：
- en: How to wrap a PyTorch model for use with the scikit-learn machine learning library
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何包装 PyTorch 模型以便与 scikit-learn 机器学习库一起使用
- en: How to easily evaluate PyTorch models using cross-validation in scikit-learn
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用 scikit-learn 中的交叉验证轻松评估 PyTorch 模型
- en: How to tune PyTorch model hyperparameters using grid search in scikit-learn
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用 scikit-learn 中的网格搜索调整 PyTorch 模型的超参数
- en: '**Kick-start your project** with my book [Deep Learning with PyTorch](https://machinelearningmastery.com/deep-learning-with-pytorch/).
    It provides **self-study tutorials** with **working code**.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**快速启动你的项目**，请参考我的书籍 [《使用 PyTorch 的深度学习》](https://machinelearningmastery.com/deep-learning-with-pytorch/)。它提供了**自学教程**和**可运行的代码**。'
- en: Let’s get started.![](../Images/a4f0998f7e876a482d3b30020553a429.png)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！[](../Images/a4f0998f7e876a482d3b30020553a429.png)
- en: Use PyTorch Deep Learning Models with scikit-learn
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 scikit-learn 的 PyTorch 深度学习模型
- en: Photo by [Priyanka Neve](https://unsplash.com/photos/puk-xEM9CyI). Some rights
    reserved.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Priyanka Neve](https://unsplash.com/photos/puk-xEM9CyI) 提供。保留所有权利。
- en: Overview
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'This chapter is in four parts; they are:'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本章分为四部分；它们是：
- en: Overview of skorch
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: skorch 概述
- en: Evaluate Deep Learning Models with Cross-Validation
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 评估深度学习模型的交叉验证
- en: Running k-Fold Cross-validation with scikit-learn
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 scikit-learn 运行 k-折交叉验证
- en: Grid Search Deep Learning Model Parameters
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 网格搜索深度学习模型参数
- en: Overview of skorch
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: skorch 概述
- en: 'PyTorch is a popular library for deep learning in Python, but the focus of
    the library is deep learning, not all of machine learning. In fact, it strives
    for minimalism, focusing on only what you need to quickly and simply define and
    build deep learning models. The scikit-learn library in Python is built upon the
    SciPy stack for efficient numerical computation. It is a fully featured library
    for general purpose machine learning and provides many useful utilities in developing
    deep learning models. Not least of which are:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 是一个在 Python 中用于深度学习的流行库，但该库的重点是深度学习，而不是所有机器学习。实际上，它追求简约，专注于快速而简单地定义和构建深度学习模型。Python
    中的 scikit-learn 库建立在 SciPy 堆栈上，以实现高效的数值计算。它是一个功能全面的通用机器学习库，并提供许多有用的工具来开发深度学习模型。尤其包括：
- en: Evaluation of models using resampling methods like k-fold cross-validation
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用如 k-折交叉验证等重采样方法评估模型
- en: Efficient search and evaluation of model hyperparameters
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 模型超参数的高效搜索和评估
- en: Connecting multiple steps of a machine learning workflow into a pipeline
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将机器学习工作流程的多个步骤连接成一个管道
- en: PyTorch cannot work with scikit-learn directly. But thanks to the duck-typing
    nature of Python language, it is easy to adapt a PyTorch model for use with scikit-learn.
    Indeed, the `skorch` module is built for this purpose. With `skorch`, you can
    make your PyTorch model work just like a scikit-learn model. You may find it easier
    to use.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch 不能直接与 scikit-learn 一起使用。但由于 Python 语言的鸭子类型特性，适应 PyTorch 模型以与 scikit-learn
    一起使用是很容易的。事实上，`skorch` 模块就是为此目的而构建的。使用 `skorch`，你可以让你的 PyTorch 模型像 scikit-learn
    模型一样工作。你可能会觉得使用起来更方便。
- en: In the following sections, you will work through examples of using the `NeuralNetClassifier`
    wrapper for a classification neural network created in PyTorch and used in the
    scikit-learn library. The test problem is the [Sonar dataset](https://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+(Sonar,+Mines+vs.+Rocks)).
    This is a small dataset with all numerical attributes that is easy to work with.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的章节中，你将通过使用 `NeuralNetClassifier` 封装器来处理一个在 PyTorch 中创建并用于 scikit-learn
    库的分类神经网络的示例。测试问题是 [Sonar 数据集](https://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+(Sonar,+Mines+vs.+Rocks))。这是一个所有属性都是数值型的小型数据集，易于处理。
- en: 'The following examples assume you have successfully installed PyTorch, skorch,
    and scikit-learn. If you use the pip for your Python modules, you may install
    them with:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 以下示例假设你已经成功安装了 PyTorch、skorch 和 scikit-learn。如果你使用 pip 安装 Python 模块，可以用以下命令安装它们：
- en: '[PRE0]'
  id: totrans-24
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Evaluate Deep Learning Models with Cross-Validation
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用交叉验证评估深度学习模型
- en: The `NeuralNet` class, or more specialized `NeuralNetClassifier`, `NeuralNetBinaryClassifier`,
    and `NeuralNetRegressor` classes in skorch are factory wrappers for PyTorch models.
    They take an argument `model` which is a class or a function to call to get your
    model. In return, these wrapper classes allows you to specify loss function and
    optimizer, then the training loop comes for free. This is the convenience compare
    to using PyTorch directly.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '`NeuralNet` 类，或更专业的 `NeuralNetClassifier`、`NeuralNetBinaryClassifier` 和 `NeuralNetRegressor`
    类在 skorch 中是 PyTorch 模型的工厂封装器。它们接收一个参数 `model`，这个参数是一个类或一个函数，用于获取你的模型。作为回报，这些封装器类允许你指定损失函数和优化器，然后训练循环自动完成。这是与直接使用
    PyTorch 相比的便利之处。'
- en: 'Below is a simple example of training a binary classifier on the Sonar dataset:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个在 Sonar 数据集上训练二分类器的简单示例：
- en: '[PRE1]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In this model, you used `torch.nn.BCEWithLogitsLoss` as the loss function (that
    is indeed the default of `NeuralNetBinaryClassifier`). It is to combine the sigmoid
    function with binary cross entropy loss, so that you don’t need to put the sigmoid
    function at the output of the model. It is sometimes preferred to provide better
    numerical stability.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个模型中，你使用了 `torch.nn.BCEWithLogitsLoss` 作为损失函数（这确实是 `NeuralNetBinaryClassifier`
    的默认设置）。它将 sigmoid 函数与二元交叉熵损失结合在一起，这样你就不需要在模型输出端使用 sigmoid 函数。它有时被偏好以提供更好的数值稳定性。
- en: In addition, you specified the training parameters such as the number of epochs
    and batch size in the skorch wrapper. Then you just need to call `fit()` function
    with the input feature and target. The wrapper will help you initialize a model
    and train it.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你在 skorch 封装器中指定了训练参数，如训练轮数和批次大小。然后你只需调用 `fit()` 函数并提供输入特征和目标。封装器将帮助你初始化模型并训练它。
- en: 'Running the above will produce the following:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 运行上述代码将产生以下结果：
- en: '[PRE2]'
  id: totrans-32
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Note that skorch is positioned as a wrapper for PyTorch models to adapt to scikit-learn
    interface. Therefore, you should use the model as if it is a scikit-learn model.
    For example, to train your binary classification model, it is expected the target
    to be a vector rather than an $n\times 1$ matrix. And to run the model for inference,
    you should use `model.predict(X)` or `model.predict_proba(X)`. It is also why
    you should use `NeuralNetBinaryClassifier`, such that the classification-related
    scikit-learn functions are provided as model methods.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，skorch 被定位为适应 scikit-learn 接口的 PyTorch 模型封装器。因此，你应该将模型当作 scikit-learn 模型来使用。例如，要训练二分类模型，目标应该是一个向量而不是
    $n\times 1$ 矩阵。并且在进行推断时，你应该使用 `model.predict(X)` 或 `model.predict_proba(X)`。这也是你应该使用
    `NeuralNetBinaryClassifier` 的原因，这样分类相关的 scikit-learn 函数作为模型方法提供。
- en: Want to Get Started With Deep Learning with PyTorch?
  id: totrans-34
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 想要开始使用 PyTorch 深度学习吗？
- en: Take my free email crash course now (with sample code).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 立即参加我的免费电子邮件速成课程（包含示例代码）。
- en: Click to sign-up and also get a free PDF Ebook version of the course.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 点击注册并获取课程的免费 PDF 电子书版本。
- en: Running k-Fold Cross-validation with scikit-learn
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 scikit-learn 运行 k-Fold 交叉验证
- en: Using a wrapper over your PyTorch model already save you a lot of boilerplate
    code on building your own training loop. But the entire suite of machine learning
    functions from scikit-learn is the real productivity boost.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 PyTorch 模型的封装器已经为你节省了大量构建自定义训练循环的样板代码。但来自 scikit-learn 的整个机器学习函数套件才是真正的生产力提升。
- en: One example is to use the model selection functions from scikit-learn. Let’s
    say you want to evaluate this model design with k-fold cross-validation. Normally,
    it means to take a dataset, split it into $k$ portions, then run a loop to select
    one of these portion as test set and the rest as training set to train a model
    from scratch and obtain an evaluation score. It is not difficult to do but you
    need to write several lines of code to implement these.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 一个例子是使用 scikit-learn 的模型选择函数。假设你想用 k 折交叉验证评估这个模型设计。通常，这意味着将数据集分成 $k$ 部分，然后运行一个循环，将这些部分中的一个选作测试集，其余的作为训练集，从头开始训练模型并获得评估分数。这并不难，但你需要编写几行代码来实现这些功能。
- en: 'Indeed, we can make use of the k-fold and cross validation function from scikit-learn,
    as follows:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 确实，我们可以利用 scikit-learn 的 k 折交叉验证函数，如下：
- en: '[PRE3]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The parameter `verbose=False` in `NeuralNetBinaryClassifier` is to stop the
    display of progress while the model is trained, since there was a lot. The above
    code will print the validation score, as follows:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '`NeuralNetBinaryClassifier` 中的参数 `verbose=False` 是为了在模型训练时停止显示进度，因为进度很多。上述代码将打印验证分数，如下所示：'
- en: '[PRE4]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'These are the evaluation scores. Because it is a binary classification model,
    they are the average accuracy. There are five of them because it is obtained from
    a k-fold cross-validation with $k=5$, each for a different test set. Usually you
    evaluate a model with the mean and standard deviation of the cross-validation
    scores:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是评估分数。因为这是一个二分类模型，所以它们是平均准确率。因为是从 $k=5$ 的 k 折交叉验证中获得的，所以有五个，每个对应一个不同的测试集。通常你会用交叉验证分数的均值和标准差来评估模型：
- en: '[PRE5]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: which is
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 即
- en: '[PRE6]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: A good model should produce a high score (in this case, accuracy close to 1)
    and low standard deviation. A high standard deviation means the model is not very
    consistent with different test sets.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 一个好的模型应该产生高分（在这种情况下，准确率接近 1）和低标准差。高标准差意味着模型在不同测试集上的一致性较差。
- en: 'Putting everything together, the following is the complete code:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 将所有内容整合在一起，以下是完整代码：
- en: '[PRE7]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'In comparison, the following is an equivalent implementation with a neural
    network model in scikit-learn:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 相比之下，以下是使用 scikit-learn 实现的等效神经网络模型：
- en: '[PRE8]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Which you should see how skorch is to make a drop-in replacement of scikit-learn
    model with a model from PyTorch.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 你应该看到 skorch 如何使 PyTorch 模型可以替换 scikit-learn 模型。
- en: Grid Search Deep Learning Model Parameters
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 网格搜索深度学习模型参数
- en: The previous example showed how easy it is to wrap your deep learning model
    from PyTorch and use it in functions from the scikit-learn library. In this example,
    you will go a step further. The function that you specify to the model argument
    when creating the `NeuralNetBinaryClassifier` or `NeuralNetClassifier` wrapper
    can take many arguments. You can use these arguments to further customize the
    construction of the model. In addition, you know you can provide arguments to
    the `fit()` function.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的示例展示了如何轻松地将你的深度学习模型从 PyTorch 封装起来，并在 scikit-learn 库的函数中使用它。在这个示例中，你将更进一步。你在创建
    `NeuralNetBinaryClassifier` 或 `NeuralNetClassifier` 包装器时指定给模型参数的函数可以接受许多参数。你可以使用这些参数进一步自定义模型的构建。此外，你也知道可以向
    `fit()` 函数提供参数。
- en: 'In this example, you will use grid search to evaluate different configurations
    for your neural network model and report on the combination that provides the
    best estimated performance. To make it interesting, let’s modify the PyTorch model
    such that it takes a parameter to decide how deep you want it to be:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，你将使用网格搜索来评估神经网络模型的不同配置，并报告提供最佳估计性能的组合。为了增加趣味性，我们将修改 PyTorch 模型，使其接受一个参数来决定你希望模型有多深：
- en: '[PRE9]'
  id: totrans-57
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In this design, we hold the hidden layers and their activation functions in
    Python lists. Because the PyTorch components are not immediate attributes of the
    class, you will not see them in `model.parameters()`. That will be a problem on
    training. This can be mitigated by using `self.add_module()` to register the components.
    An alternative is to use `nn.ModuleList()` instead of a Python list, so that you
    provided enough clues to tell where to find the components of the model.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个设计中，我们将隐藏层及其激活函数保存在 Python 列表中。因为 PyTorch 组件不是类的直接属性，所以你不会在 `model.parameters()`
    中看到它们。这在训练时会是个问题。这可以通过使用 `self.add_module()` 来注册组件来缓解。另一种方法是使用 `nn.ModuleList()`
    代替 Python 列表，这样你就提供了足够的线索来告诉系统模型组件的位置。
- en: 'The skorch wrapper is still the same. With it, you can have a model compatible
    to scikit-learn. As you can see, there are parameters to set up the deep learning
    model as well as training parameters such as learning rate (`lr`) specified in
    the wrapper, you have many possible variations. The `GridSearchCV` function from
    scikit-learn is to provide grid search cross validation. You can provide a list
    of values for each parameter and ask scikit-learn to try out **all combinations**
    and report the best set of parameters according to the metric you specified. An
    example is as follows:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: skorch 封装器依旧保持不变。使用它，你可以获得一个兼容 scikit-learn 的模型。如你所见，封装器中有用于设置深度学习模型的参数，以及诸如学习率（`lr`）等训练参数，你可以有许多可能的变体。scikit-learn
    的 `GridSearchCV` 函数提供网格搜索交叉验证。你可以为每个参数提供一个值列表，并要求 scikit-learn 尝试**所有组合**，并根据你指定的指标报告最佳参数集。示例如下：
- en: '[PRE10]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'You passed in `model` to `GridSearchCV()`, which is a skorch wrapper. You also
    passed in `param_grid`, which specified to vary:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 你将 `model` 传递给 `GridSearchCV()`，这是一个 skorch 封装器。你还传递了 `param_grid`，指定了要变化的参数：
- en: the parameter `n_layers` in he PyTorch model (i.e., the `SonarClassifier` class),
    that controls the depth of the neural network
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch 模型中的 `n_layers` 参数（即 `SonarClassifier` 类），控制神经网络的深度。
- en: the parameter `lr` in the wrapper, that controls the learning rate at the optimizer
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 封装器中的 `lr` 参数，控制优化器中的学习率。
- en: the parameter `max_epochs` in the wrapper, that controls the number of training
    epochs to run
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 封装器中的 `max_epochs` 参数，控制训练周期的数量。
- en: Note the use of double underscore to pass on parameters to the PyTorch model.
    In fact, this allows you to configure other parameters too. For example, you can
    set up `optimizer__weight_decay` to pass on `weight_decay` parameters to the Adam
    optimizer (which is for setting up L2 regularization).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 注意使用双下划线来传递参数给 PyTorch 模型。实际上，这也允许你配置其他参数。例如，你可以设置 `optimizer__weight_decay`
    来传递 `weight_decay` 参数给 Adam 优化器（用于设置 L2 正则化）。
- en: Running this can take a while to compute because it tries all combinations,
    each evaluated with 3-fold cross validation. You do not want to run this often
    but it can be useful for you to design models.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 运行这个可能需要一段时间，因为它尝试了所有组合，每个组合都经过 3 折交叉验证。你不希望频繁运行这个，但它对于设计模型是有用的。
- en: 'After the grid search is finished, the performance and combination of configurations
    for the best model are displayed, followed by the performance of all combinations
    of parameters, as below:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 网格搜索完成后，最佳模型的性能和配置组合将显示出来，随后是所有参数组合的性能，如下所示：
- en: '[PRE11]'
  id: totrans-68
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'It gives:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 它给出的结果是：
- en: '[PRE12]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: This might take about 5 minutes to complete on your workstation executed on
    the CPU (rather than GPU). Running the example shows the results below. You can
    see that the grid search discovered that using a learning rate of 0.001 with 150
    epochs and only a single hidden layer achieved the best cross-validation score
    of approximately 65% on this problem.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在你的工作站上执行这个操作可能需要大约 5 分钟（使用 CPU 而非 GPU）。运行示例后显示了以下结果。你可以看到，网格搜索发现使用 0.001 的学习率、150
    个周期和只有一个隐藏层的组合，在这个问题上获得了大约 65% 的最佳交叉验证分数。
- en: 'In fact, you can see if you can improve the result by first standardizing input
    features. Since the wrapper allows you to use PyTorch model with scikit-learn,
    you can also use the scikit-learn’s standardizer in realtime, and create a machine
    learning pipeline:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，你可以先通过标准化输入特征来看看是否能改善结果。由于封装器允许你在 scikit-learn 中使用 PyTorch 模型，你也可以实时使用 scikit-learn
    的标准化器，并创建一个机器学习管道：
- en: '[PRE13]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The new object `pipe` you created is another scikit-learn model that works
    just like the `model` object, except a standard scaler is applied before the data
    is passed on to the neural network. Therefore you can run a grid search on this
    pipeline, with a little tweak on the way parameters are specified:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 你创建的新对象 `pipe` 是另一个 scikit-learn 模型，它的工作方式与 `model` 对象类似，只是数据在传递给神经网络之前应用了标准化器。因此，你可以在这个管道上运行网格搜索，只需稍微调整参数的指定方式：
- en: '[PRE14]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'Two key points to note here: Since PyTorch models are running on 32-bit floats
    by default but NumPy arrays are usually 64-bit floats. These data types are not
    aligned, but scikit-learn’s scaler always return you a NumPy array. Therefore
    you need to do type conversion in the middle of the pipeline, using a `FunctionTransformer`
    object.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 这里要注意两点：由于 PyTorch 模型默认运行在 32 位浮点数上，但 NumPy 数组通常是 64 位浮点数。这些数据类型不对齐，但 scikit-learn
    的缩放器总是返回一个 NumPy 数组。因此，你需要在管道中间进行类型转换，使用 `FunctionTransformer` 对象。
- en: Moreover, in a scikit-learn pipeline, each step is referred by a name, such
    as `scaler` and `sonarmodel`. Therefore, the parameters set for the pipeline need
    to carry the name as well. In the example above, we use `sonarmodel__module__n_layers`
    as a parameter for grid search. This refers to the `sonarmodel` part of the pipeline
    (which is your skorch wrapper), the `module` part therein (which is your PyTorch
    model), and its `n_layers` parameter. Note the use of double underscore for hierarchy
    separation.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在 scikit-learn 管道中，每个步骤都通过名称进行引用，例如 `scaler` 和 `sonarmodel`。因此，管道设置的参数也需要携带名称。在上述示例中，我们使用
    `sonarmodel__module__n_layers` 作为网格搜索的参数。这指的是管道中的 `sonarmodel` 部分（即你的 skorch 封装器）、其中的
    `module` 部分（即你的 PyTorch 模型）及其 `n_layers` 参数。注意使用双下划线进行层次分隔。
- en: 'Putting everything together, the following is the complete code:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 将所有内容整合在一起，以下是完整的代码：
- en: '[PRE15]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: Further Reading
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深入阅读
- en: This section provides more resources on the topic if you are looking to go deeper.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 本节提供了更多关于该主题的资源，如果你希望深入了解。
- en: Online Resources
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在线资源
- en: '[skorch documentation](https://skorch.readthedocs.io/en/latest/)'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[skorch 文档](https://skorch.readthedocs.io/en/latest/)'
- en: '[Stratified K-Folds cross-validator](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html).
    scikit-learn documentation.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[分层 K 折交叉验证器](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html)。scikit-learn
    文档。'
- en: '[Grid search cross-validator](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html).
    scikit-learn documentation.'
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[网格搜索交叉验证器](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)。scikit-learn
    文档。'
- en: '[Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html).
    scikit-learn documentation'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[管道](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)。scikit-learn
    文档'
- en: Summary
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this chapter, you discovered how to wrap your PyTorch deep learning models
    and use them in the scikit-learn general machine learning library. You learned:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，你了解了如何封装你的 PyTorch 深度学习模型并在 scikit-learn 通用机器学习库中使用它们。你学到了：
- en: Specifically how to wrap PyTorch models so that they can be used with the scikit-learn
    machine learning library.
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 具体说明如何封装 PyTorch 模型，以便可以与 scikit-learn 机器学习库一起使用。
- en: How to use a wrapped PyTorch model as part of evaluating model performance in
    scikit-learn.
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何将封装的 PyTorch 模型作为评估模型性能的一部分在 scikit-learn 中使用。
- en: How to perform hyperparameter tuning in scikit-learn using a wrapped PyTorch
    model.
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用封装的 PyTorch 模型在 scikit-learn 中进行超参数调整。
- en: You can see that using scikit-learn for standard machine learning operations
    such as model evaluation and model hyperparameter optimization can save a lot
    of time over implementing these schemes yourself. Wrapping your model allowed
    you to leverage powerful tools from scikit-learn to fit your deep learning models
    into your general machine learning process.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，使用 scikit-learn 进行标准的机器学习操作，如模型评估和模型超参数优化，可以比自己实现这些方案节省大量时间。封装你的模型使你能够利用
    scikit-learn 提供的强大工具，将你的深度学习模型融入到通用机器学习过程中。
