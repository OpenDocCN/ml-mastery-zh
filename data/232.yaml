- en: A Gentle Introduction To Partial Derivatives and Gradient Vectors
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 《偏导数和梯度向量的温和介绍》
- en: 原文：[https://machinelearningmastery.com/a-gentle-introduction-to-partial-derivatives-and-gradient-vectors/](https://machinelearningmastery.com/a-gentle-introduction-to-partial-derivatives-and-gradient-vectors/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://machinelearningmastery.com/a-gentle-introduction-to-partial-derivatives-and-gradient-vectors/](https://machinelearningmastery.com/a-gentle-introduction-to-partial-derivatives-and-gradient-vectors/)
- en: Partial derivatives and gradient vectors are used very often in machine learning
    algorithms for finding the minimum or maximum of a function. Gradient vectors
    are used in the training of neural networks, logistic regression, and many other
    classification and regression problems.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 偏导数和梯度向量在机器学习算法中非常常用，用于寻找函数的最小值或最大值。梯度向量用于神经网络的训练、逻辑回归以及许多其他分类和回归问题中。
- en: In this tutorial, you will discover partial derivatives and the gradient vector.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，你将发现偏导数和梯度向量。
- en: 'After completing this tutorial, you will know:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 完成本教程后，你将了解：
- en: Function of several variables
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多变量函数
- en: Level sets, contours and graphs of a function of two variables
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 等值线、等高线和双变量函数的图形
- en: Partial derivatives of a function of several variables
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多变量函数的偏导数
- en: Gradient vector and its meaning
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 梯度向量及其含义
- en: Let’s get started.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: '[![](../Images/eecbd965c05d3fefa4a0cefac3883a0c.png)](https://machinelearningmastery.com/wp-content/uploads/2021/07/atifgulzar.jpg)'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/eecbd965c05d3fefa4a0cefac3883a0c.png)](https://machinelearningmastery.com/wp-content/uploads/2021/07/atifgulzar.jpg)'
- en: A Gentle Introduction To Partial Derivatives and Gradient Vectors. A photo by
    Atif Gulzar, some rights reserved.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 《偏导数和梯度向量的温和介绍》。照片由Atif Gulzar提供，保留所有权利。
- en: Tutorial Overview
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 教程概述
- en: 'This tutorial is divided into three parts; they are:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程分为三个部分，它们是：
- en: Function of several variables
  id: totrans-14
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 多变量函数
- en: Level sets
  id: totrans-15
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 等值线
- en: Contours
  id: totrans-16
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 等高线
- en: Graphs
  id: totrans-17
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 图形
- en: Definition of partial derivatives
  id: totrans-18
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 偏导数的定义
- en: Gradient vector
  id: totrans-19
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 梯度向量
- en: What does the gradient vector represent
  id: totrans-20
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
  zh: 梯度向量表示什么
- en: A Function of Several Variables
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 多变量函数
- en: You can review the concept of a function and a function of several variables
    in this [tutorial](https://machinelearningmastery.com/a-gentle-introduction-to-multivariate-calculus).
     We’ll provide more details about the functions of several variables here.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以在这个 [教程](https://machinelearningmastery.com/a-gentle-introduction-to-multivariate-calculus)
    中复习函数和多变量函数的概念。我们将在这里提供更多关于多变量函数的详细信息。
- en: 'A function of several variables has the following properties:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 多变量函数具有以下属性：
- en: Its domain is a set of n-tuples given by (x_1, x_2, x_3, …, x_n)
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它的定义域是由 (x_1, x_2, x_3, …, x_n) 给出的 n 元组集
- en: Its range is a set of real numbers
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 它的范围是实数集
- en: 'For example, the following is a function of two variables (n=2):'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，以下是一个双变量函数（n=2）：
- en: f_1(x,y) = x + y
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: f_1(x,y) = x + y
- en: In the above function x and y are the independent variables. Their sum determines
    the value of the function. The domain of this function is the set of all points
    on the XY cartesian plane. The plot of this function would require plotting in
    the 3D space, with two axes for input points (x,y) and the third representing
    the values of f.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述函数中，x 和 y 是独立变量。它们的和决定了函数的值。该函数的定义域是 XY 直角坐标平面上的所有点集合。该函数的图形需要在 3D 空间中绘制，其中两个轴表示输入点
    (x,y)，第三个轴表示 f 的值。
- en: Here is another example of a function of two variables. f_2(x,y) = x**x + y**y
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 这是另一个双变量函数的示例。 f_2(x,y) = x**x + y**y
- en: To keep things simple, we’ll do examples of functions of two variables. Of course,
    in machine learning you’ll encounter functions of hundreds of variables. The concepts
    related to functions of two variables can be extended to those cases.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化问题，我们将做双变量函数的示例。当然，在机器学习中，你会遇到数百个变量的函数。与双变量函数相关的概念可以扩展到这些情况。
- en: Level Sets and Graph of a Function of Two Variables
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 双变量函数的等值线和图形
- en: The set of points in a plane, where a function f(x,y) has a constant value,
    i.e., f(x,y)=c is the level set or level curve of f.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 平面上的点集合，其中函数 f(x,y) 具有恒定值，即 f(x,y)=c，称为 f 的等值集或等值曲线。
- en: 'As an example, for function f_1, all (x,y) points that satisfy the equation
    below define a level set for f_1:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，对于函数 f_1，所有满足以下方程的 (x,y) 点定义了 f_1 的一个等值集：
- en: x + y = 1
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: x + y = 1
- en: We can see that this level set has an infinite set of points, e.g., (0,2), (1,1),
    (2, 0), etc. This level set defines a straight line in the XY plane.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，这个等值集具有无限的点集，例如 (0,2)、(1,1)、(2,0) 等。这个等值集定义了 XY 平面上的一条直线。
- en: 'In general, all level sets of f_1 define straight lines of the form (c is any
    real constant):'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，函数 f_1 的所有水平集定义了形式为直线的直线（c 为任何实数常数）：
- en: x + y = c
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: x + y = c
- en: 'Similarly, for function f_2, an example of a level set is:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，对于函数 f_2，水平集的一个示例如下：
- en: x**x + y**y = 1
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: x**x + y**y = 1
- en: 'We can see that any point that lies on a circle of radius 1 with center at
    (0,0) satisfies the above expression. Hence, this level set consists of all points
    that lie on this circle. Similarly, any level set of f_2 satisfies the following
    expression (c is any real constant >= 0):'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到，任何位于半径为 1、中心在 (0,0) 的圆上的点都满足上述表达式。因此，这个水平集由所有位于这个圆上的点组成。类似地，f_2 的任何水平集满足以下表达式（c
    为任何实数常数 >= 0）：
- en: x**x + y**y = c
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: x**x + y**y = c
- en: Hence, all level sets of f_2 are circles with center at (0,0), each level set
    having its own radius.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，f_2 的所有水平集都是中心在 (0,0) 的圆，每个水平集都有自己独特的半径。
- en: The graph of the function f(x,y) is the set of all points (x,y,f(x,y)). It is
    also called a surface z=f(x,y). The graphs of f_1 and f_2 are shown below (left
    side).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 函数 f(x,y) 的图形是所有点 (x,y,f(x,y)) 的集合。它也被称为表面 z=f(x,y)。f_1 和 f_2 的图形如下（左侧）。
- en: '[![The functions f_1 and f_2 and their corresponding contours](../Images/0f7c744e397a2f1dd31ac37d6ab75585.png)](https://machinelearningmastery.com/wp-content/uploads/2021/07/grad1.png)'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '[![函数 f_1 和 f_2 及其相应的轮廓](../Images/0f7c744e397a2f1dd31ac37d6ab75585.png)](https://machinelearningmastery.com/wp-content/uploads/2021/07/grad1.png)'
- en: The functions f_1 and f_2 and their corresponding contours
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 函数 f_1 和 f_2 及其相应的轮廓
- en: Contours of a Function of Two Variables
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 两变量函数的轮廓
- en: Suppose we have a function f(x,y) of two variables. If we cut the surface z=f(x,y)
    using a plane z=c, then we get the set of all points that satisfy f(x,y) = c.
    The contour curve is the set of points that satisfy f(x,y)=c, in the plane z=c.
    This is slightly different from the level set, where the level curve is directly
    defined in the XY plane. However, many books treat contours and level curves as
    the same.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 假设我们有一个两变量的函数 f(x,y)。如果我们用平面 z=c 切割表面 z=f(x,y)，则得到满足 f(x,y) = c 的所有点的集合。轮廓曲线是满足
    f(x,y)=c 的点在平面 z=c 中的集合。这与水平集略有不同，水平曲线直接在 XY 平面中定义。然而，许多书籍将轮廓和水平曲线视为相同的概念。
- en: The contours of both f_1 and f_2 are shown in the above figure (right side).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图形（右侧）显示了 f_1 和 f_2 的轮廓。
- en: Want to Get Started With Calculus for Machine Learning?
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 想开始学习机器学习中的微积分吗？
- en: Take my free 7-day email crash course now (with sample code).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 立即参加我的免费 7 天电子邮件速成课程（包括示例代码）。
- en: Click to sign-up and also get a free PDF Ebook version of the course.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 点击注册并获得免费 PDF 电子书版的课程。
- en: Partial Derivatives and Gradients
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 偏导数和梯度
- en: 'The partial derivative of a function f w.r.t. the variable x is denoted by
    ∂f/∂x. Its expression can be determined by differentiating f w.r.t. x. For example
    for the functions f_1 and f_2, we have:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 函数 f 关于变量 x 的偏导数表示为 ∂f/∂x。其表达式可以通过对 f 关于 x 求导来确定。例如，对于函数 f_1 和 f_2，我们有：
- en: ∂f_1/∂x = 1
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: ∂f_1/∂x = 1
- en: ∂f_2/∂x = 2x
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: ∂f_2/∂x = 2x
- en: ∂f_1/∂x represents the rate of change of f_1 w.r.t x. For any function f(x,y),
    ∂f/∂x represents the rate of change of f w.r.t variable x.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: ∂f_1/∂x 表示 f_1 关于 x 的变化率。对于任何函数 f(x,y)，∂f/∂x 表示 f 关于变量 x 的变化率。
- en: Similar is the case for ∂f/∂y. It represents the rate of change of f w.r.t y.
    You can look at the formal definition of partial derivatives in this [tutorial](https://machinelearningmastery.com/a-gentle-introduction-to-multivariate-calculus).
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 ∂f/∂y 也是类似的情况。它表示 f 关于 y 的变化率。你可以在这个 [教程](https://machinelearningmastery.com/a-gentle-introduction-to-multivariate-calculus)
    中查看偏导数的正式定义。
- en: 'When we find the partial derivatives w.r.t all independent variables, we end
    up with a vector. This vector is called the gradient vector of f denoted by ∇f(x,y).
    A general expression for the gradients of f_1 and f_2 are given by (here i,j are
    unit vectors parallel to the coordinate axis):'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 当我们求出对所有独立变量的偏导数时，我们得到一个向量。这个向量称为 f 的梯度向量，表示为 ∇f(x,y)。f_1 和 f_2 的梯度的一般表达式如下（其中
    i,j 是与坐标轴平行的单位向量）：
- en: ∇f_1(x,y) = ∂f_1/∂xi + ∂f_1/∂yj = i+j
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: ∇f_1(x,y) = ∂f_1/∂xi + ∂f_1/∂yj = i+j
- en: ∇f_2(x,y) = ∂f_2/∂xi + ∂f_2/∂yj = 2xi + 2yj
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: ∇f_2(x,y) = ∂f_2/∂xi + ∂f_2/∂yj = 2xi + 2yj
- en: From the general expression of the gradient, we can evaluate the gradient at
    different points in space. In case of f_1 the gradient vector is a constant, i.e.,
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 从梯度的一般表达式中，我们可以在空间中的不同点上评估梯度。对于 f_1，梯度向量是常数，即：
- en: i+j
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: i+j
- en: No matter where we are in the three dimensional space, the direction and magnitude
    of the gradient vector remains unchanged.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 无论我们处于三维空间的何处，梯度向量的方向和大小保持不变。
- en: 'For the function f_2, ∇f_2(x,y) changes with values of (x,y). For example,
    at (1,1) and (2,1) the gradient of f_2 is given by the following vectors:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 对于函数f_2，∇f_2(x,y) 随 (x,y) 的值变化。例如，在 (1,1) 和 (2,1) 处，f_2 的梯度由以下向量给出：
- en: ∇f_2(1,1) = 2i + 2j
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: ∇f_2(1,1) = 2i + 2j
- en: ∇f_2(2,1) = 4i + 2j
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: ∇f_2(2,1) = 4i + 2j
- en: What Does the Gradient Vector At a Point Indicate?
  id: totrans-67
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 梯度向量在某一点上表示什么？
- en: The gradient vector of a function of several variables at any point denotes
    the direction of maximum rate of change.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 多变量函数在任何点的梯度向量表示最大变化速率的方向。
- en: We can relate the gradient vector to the [tangent line](https://machinelearningmastery.com/a-gentle-introduction-to-slopes-and-tangents).
    If we are standing at a point in space and we come up with a rule that tells us
    to walk along the tangent to the contour at that point. It means wherever we are,
    we find the tangent line to the contour at that point and walk along it. If we
    walk following this rule, we’ll end up walking along the contour of f. The function’s
    value will never change as the function’s value is constant on the contour of
    f.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以将梯度向量与[切线](https://machinelearningmastery.com/a-gentle-introduction-to-slopes-and-tangents)
    联系起来。如果我们站在空间中的一个点，并制定了一个规则，告诉我们沿着该点的轮廓的切线行走。这意味着无论我们在哪里，我们都找到该点的轮廓切线，并沿着它行走。如果我们遵循这个规则，我们将沿着
    f 的轮廓行走。函数值将保持不变，因为函数值在 f 的轮廓上是恒定的。
- en: The gradient vector, on the other hand, is normal to the tangent line and points
    to the direction of maximum rate of increase. If we walk along the direction of
    the gradient we’ll start encountering the next point where the function’s value
    would be greater than the previous one.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，梯度向量垂直于切线，指向最大增速的方向。如果我们沿着梯度的方向前进，我们会遇到下一个函数值大于前一个值的点。
- en: The positive direction of the gradient indicates the direction of maximum rate
    of increase, whereas, the negative direction indicates the direction of maximum
    rate of decrease. The following figure shows the positive direction of the gradient
    vector at different points of the contours of function f_2\. The direction of
    the positive gradient is indicated by the red arrow. The tangent line to a contour
    is shown in green.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度的正方向表示最大增速的方向，而负方向则表示最大降速的方向。下图显示了函数f_2的不同轮廓点处的梯度向量的正方向。正梯度的方向由红色箭头指示。轮廓的切线以绿色显示。
- en: '[![The contours and the direction of gradient vectors](../Images/01bf957dafbfba27f7c0efcca1d3cc3c.png)](https://machinelearningmastery.com/wp-content/uploads/2021/07/grad2.png)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[![轮廓和梯度向量的方向](../Images/01bf957dafbfba27f7c0efcca1d3cc3c.png)](https://machinelearningmastery.com/wp-content/uploads/2021/07/grad2.png)'
- en: The contours and the direction of gradient vectors
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 轮廓和梯度向量的方向
- en: Why Is The Gradient Vector Important In Machine Learning?
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 为什么梯度向量在机器学习中很重要？
- en: The gradient vector is very important and used frequently in machine learning
    algorithms. In classification and regression problems, we normally define the
    mean square error function. Following the negative direction of the gradient of
    this function will lead us to finding the point where this function has a minimum
    value.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度向量在机器学习算法中非常重要且频繁使用。在分类和回归问题中，我们通常定义均方误差函数。沿着该函数梯度的负方向将使我们找到该函数具有最小值的点。
- en: Similar is the case for functions, where maximizing them leads to achieving
    maximum accuracy. In this case we’ll follow the direction of the maximum rate
    of increase of this function or the positive direction of the gradient vector.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 对于函数也是如此，最大化它们会实现最高的准确性。在这种情况下，我们将沿着该函数的最大增速方向或梯度向量的正方向前进。
- en: Extensions
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 扩展
- en: This section lists some ideas for extending the tutorial that you may wish to
    explore.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 本节列出了一些扩展教程的想法，您可能希望进行探索。
- en: Gradient descent/ gradient ascent
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 梯度下降/梯度上升
- en: Hessian matrix
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hessian矩阵
- en: Jacobian
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 雅可比矩阵
- en: If you explore any of these extensions, I’d love to know. Post your findings
    in the comments below.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您探索了这些扩展内容，我很想知道。请在下面的评论中分享您的发现。
- en: Further Reading
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: This section provides more resources on the topic if you are looking to go deeper.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 本节提供了有关该主题的更多资源，如果您希望深入了解。
- en: Tutorials
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 教程
- en: '[Derivatives](https://machinelearningmastery.com/a-gentle-introduction-to-function-derivatives)'
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[导数](https://machinelearningmastery.com/a-gentle-introduction-to-function-derivatives)'
- en: '[Slopes and tangents](https://machinelearningmastery.com/a-gentle-introduction-to-slopes-and-tangents)'
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[斜率与切线](https://machinelearningmastery.com/a-gentle-introduction-to-slopes-and-tangents)'
- en: '[Multivariate calculus](https://machinelearningmastery.com/a-gentle-introduction-to-multivariate-calculus)'
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[多变量微积分](https://machinelearningmastery.com/a-gentle-introduction-to-multivariate-calculus)'
- en: '[Gradient descent for machine learning](https://machinelearningmastery.com/gradient-descent-for-machine-learning/)'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习中的梯度下降](https://machinelearningmastery.com/gradient-descent-for-machine-learning/)'
- en: '[What is gradient in machine learning](https://machinelearningmastery.com/gradient-in-machine-learning/)'
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[机器学习中的梯度是什么](https://machinelearningmastery.com/gradient-in-machine-learning/)'
- en: Resources
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 资源
- en: Additional resources on [Calculus Books for Machine Learning](https://machinelearningmastery.com/calculus-books-for-machine-learning)
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 关于[机器学习的微积分书籍](https://machinelearningmastery.com/calculus-books-for-machine-learning)的额外资源
- en: Books
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 书籍
- en: '[Thomas’ Calculus](https://amzn.to/35Yeolv), 14th edition, 2017\. (based on
    the original works of George B. Thomas, revised by Joel Hass, Christopher Heil,
    Maurice Weir)'
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[托马斯微积分](https://amzn.to/35Yeolv)，第14版，2017年。（基于**乔治·B·托马斯**的原著，由**乔尔·哈斯**、**克里斯托弗·海尔**和**莫里斯·韦尔**修订）'
- en: '[Calculus](https://www.amazon.com/Calculus-3rd-Gilbert-Strang/dp/0980232759/ref=as_li_ss_tl?dchild=1&keywords=Gilbert+Strang+calculus&qid=1606171602&s=books&sr=1-1&linkCode=sl1&tag=inspiredalgor-20&linkId=423b93db012f7cc6bb92cb7494a3095f&language=en_US),
    3rd Edition, 2017\. (Gilbert Strang)'
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[微积分](https://www.amazon.com/Calculus-3rd-Gilbert-Strang/dp/0980232759/ref=as_li_ss_tl?dchild=1&keywords=Gilbert+Strang+calculus&qid=1606171602&s=books&sr=1-1&linkCode=sl1&tag=inspiredalgor-20&linkId=423b93db012f7cc6bb92cb7494a3095f&language=en_US)，第3版，2017年。（**吉尔伯特·斯特朗**）'
- en: '[Calculus](https://amzn.to/3kS9I52), 8th edition, 2015\. (James Stewart)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[微积分](https://amzn.to/3kS9I52)，第8版，2015年。（**詹姆斯·斯图尔特**）'
- en: Summary
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this tutorial, you discovered what are functions of several variables, partial
    derivatives and the gradient vector. Specifically, you learned:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，你了解了什么是多变量函数、偏导数和梯度向量。具体来说，你学到了：
- en: Function of several variables
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多变量函数
- en: Contours of a function of several variables
  id: totrans-100
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多变量函数的轮廓
- en: Level sets of a function of several variables
  id: totrans-101
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多变量函数的水平集
- en: Partial derivatives of a function of several variables
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多变量函数的偏导数
- en: Gradient vector and its meaning
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 梯度向量及其意义
- en: Do you have any questions?
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 你有任何问题吗？
- en: Ask your questions in the comments below and I will do my best to answer.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的评论中提问，我会尽力回答。
