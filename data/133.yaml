- en: Save and Load Your PyTorch Models
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 保存和加载你的PyTorch模型
- en: 原文：[https://machinelearningmastery.com/save-and-load-your-pytorch-models/](https://machinelearningmastery.com/save-and-load-your-pytorch-models/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://machinelearningmastery.com/save-and-load-your-pytorch-models/](https://machinelearningmastery.com/save-and-load-your-pytorch-models/)
- en: 'A deep learning model is a mathematical abstraction of data, in which a lot
    of parameters are involved. Training these parameters can take hours, days, and
    even weeks but afterward, you can make use of the result to apply on new data.
    This is called inference in machine learning. It is important to know how we can
    preserve the trained model in disk and later, load it for use in inference. In
    this post, you will discover how to save your PyTorch models to files and load
    them up again to make predictions. After reading this chapter, you will know:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习模型是数据的数学抽象，其中涉及大量参数。训练这些参数可能需要数小时、数天甚至数周，但之后，你可以利用结果在新数据上应用。这在机器学习中称为推理。了解如何将训练好的模型保存在磁盘上，并在以后加载以进行推理是很重要的。在这篇文章中，你将学习如何将PyTorch模型保存到文件中，并重新加载以进行预测。阅读完这一章后，你将知道：
- en: What are states and parameters in a PyTorch model
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch模型中的状态和参数是什么
- en: How to save model states
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何保存模型状态
- en: How to load model states
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何加载模型状态
- en: '**Kick-start your project** with my book [Deep Learning with PyTorch](https://machinelearningmastery.com/deep-learning-with-pytorch/).
    It provides **self-study tutorials** with **working code**.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**启动你的项目**，参阅我的书籍[《PyTorch深度学习》](https://machinelearningmastery.com/deep-learning-with-pytorch/)。它提供了**自学教程**和**可运行的代码**。'
- en: Let’s get started.![](../Images/b616b0be4904ab3e5846c25d2e4373fc.png)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 开始吧。![](../Images/b616b0be4904ab3e5846c25d2e4373fc.png)
- en: Save and Load Your PyTorch Models
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 保存和加载你的PyTorch模型
- en: Photo by [Joseph Chan](https://unsplash.com/photos/Wwtq9Lvk_ZE). Some rights
    reserved.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由[Joseph Chan](https://unsplash.com/photos/Wwtq9Lvk_ZE)提供。保留一些权利。
- en: Overview
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: This post is in three parts; they are
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 本文分为三部分，它们是
- en: Build an Example Model
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 构建一个示例模型
- en: What’s Inside a PyTorch Model
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: PyTorch模型内部包含什么
- en: Accessing `state_dict` of a Model
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 访问模型的`state_dict`
- en: Build an Example Model
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建一个示例模型
- en: Let’s start with a very simple model in PyTorch. It is a model based on the
    iris dataset. You will load the dataset using scikit-learn (which the targets
    are integer labels 0, 1, and 2) and train a neural network for this multiclass
    classification problem. In this model, you used log softmax as the output activation
    so you can combine with the negative log likelihood loss function. It is equivalent
    to no output activation combined with cross entropy loss function.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们从一个非常简单的PyTorch模型开始。这是一个基于鸢尾花数据集的模型。你将使用scikit-learn加载数据集（目标是整数标签0、1和2），并为这个多类分类问题训练一个神经网络。在这个模型中，你使用了log
    softmax作为输出激活函数，以便与负对数似然损失函数结合。这相当于没有输出激活函数结合交叉熵损失函数。
- en: '[PRE0]'
  id: totrans-17
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'With such a simple model and small dataset, it shouldn’t take a long time to
    finish training. Afterwards, we can confirm that this model works, by evaluating
    it with the test set:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 使用如此简单的模型和小数据集，不应该花费太长时间完成训练。之后，我们可以通过使用测试集来验证该模型是否有效：
- en: '[PRE1]'
  id: totrans-19
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: It prints, for example,
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，它会打印出
- en: '[PRE2]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Want to Get Started With Deep Learning with PyTorch?
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 想要开始使用PyTorch进行深度学习吗？
- en: Take my free email crash course now (with sample code).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 现在立即注册我的免费电子邮件速成课程（附示例代码）。
- en: Click to sign-up and also get a free PDF Ebook version of the course.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 点击注册，并获取课程的免费PDF电子书版本。
- en: What’s Inside a PyTorch Model
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PyTorch模型内部包含什么
- en: PyTorch model is an object in Python. It holds some deep learning building blocks
    such as various kinds of layers and activation functions. It also knows how to
    connect them so it can produce you an output from your input tensors. The algorithm
    of a model is fixed at the time you created it, however, it has trainable parameters
    that is supposed to be modified during training loop so the model can be more
    accurate.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch模型是Python中的一个对象。它包含一些深度学习构建块，例如各种层和激活函数。它还知道如何将它们连接起来，以便从输入张量中生成输出。模型的算法在创建时是固定的，但它有可训练的参数，这些参数在训练循环中应被修改，以使模型更加准确。
- en: You saw how to get the model parameters when you set up the optimizer for your
    training loop, namely,
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 你看到如何在设置优化器以进行训练循环时获取模型参数，即
- en: '[PRE3]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The function `model.parameters()` give you a generator that reference to each
    layers’ trainable parameters in turn in the form of PyTorch tensors. Therefore,
    it is possible for you to make a copy of them or overwrite them, for example:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 函数`model.parameters()`为你提供了一个生成器，依次引用每一层的可训练参数，形式为PyTorch张量。因此，你可以复制这些参数或覆盖它们，例如：
- en: '[PRE4]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Which the result should be exactly the same as before since you essentially
    made the two models identical by copying the parameters.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 结果应该与之前完全相同，因为你通过复制参数使两个模型变得完全相同。
- en: 'However, this is not always the case. Some models has **non-trainable parameters**.
    One example is the batch normalization layer that is common in many convolution
    neural networks. What it does is to apply normalization on tensors that produced
    by its previous layer and pass on the normalized tensor to its next layer. It
    has two parameters: The mean and standard deviation, which are learned from your
    input data during training loop but not trainable by the optimizer. Therefore
    these are not part of `model.parameters()` but equally important.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，情况并非总是如此。一些模型具有**不可训练的参数**。一个例子是许多卷积神经网络中常见的批归一化层。它的作用是在前一层产生的张量上应用归一化，并将归一化后的张量传递给下一层。它有两个参数：均值和标准差，这些参数在训练循环中从输入数据中学习，但不能被优化器训练。因此，这些参数不是`model.parameters()`的一部分，但同样重要。
- en: Accessing `state_dict` of a Model
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 访问模型的`state_dict`
- en: 'To access all parameters of a model, trainable or not, you can get it from
    `state_dict()` function. From the model above, this is what you can get:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 要访问模型的所有参数，无论是否可训练，你可以从`state_dict()`函数中获取。从上面的模型中，你可以得到以下内容：
- en: '[PRE5]'
  id: totrans-35
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The model above produces the following:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的模型产生了以下结果：
- en: '[PRE6]'
  id: totrans-37
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: It is called `state_dict` because all state variables of a model are here. It
    is an `OrderedDict` object from Python’s built-in `collections` module. All components
    from a PyTorch model has a name and so as the parameters therein. The `OrderedDict`
    object allows you to map the weights back to the parameters correctly by matching
    their names.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 它被称为`state_dict`，因为模型的所有状态变量都在这里。它是来自Python内置`collections`模块的一个`OrderedDict`对象。PyTorch模型中的所有组件都有一个名称，参数也是如此。`OrderedDict`对象允许你通过匹配名称将权重正确地映射回参数。
- en: 'This is how you should save and load the model: Fetch the model states into
    an `OrderedDict`, serialize and save it to disk. For inference, you create a model
    first (without training), and load the states. In Python, the native format for
    serialization is pickle:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是你应该如何保存和加载模型：将模型状态提取到`OrderedDict`中，序列化并保存到磁盘。在推理时，你首先创建一个模型（不进行训练），然后加载状态。在Python中，序列化的本机格式是pickle：
- en: '[PRE7]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: You know it works because the model you didn’t train produced the same result
    as the one you trained.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 你知道它有效，因为你没有训练的模型产生了与训练过的模型相同的结果。
- en: 'Indeed, the recommended way is to use the PyTorch API to save and load the
    states, instead of using pickle manually:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 确实，推荐的方式是使用PyTorch API来保存和加载状态，而不是手动使用pickle：
- en: '[PRE8]'
  id: totrans-43
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The `*.pth` file is indeed a zip file of some pickle files created by PyTorch.
    It is recommended because PyTorch can store additional information in it. Note
    that you stored only the states but not the model. You still need to create the
    model using Python code and load the states into it. If you wish to store the
    model as well, you can pass in the entire model instead of the states:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '`*.pth`文件实际上是由PyTorch创建的一些pickle文件的压缩文件。推荐这样做，因为PyTorch可以在其中存储额外的信息。请注意，你仅保存了状态而不是模型。你仍然需要使用Python代码创建模型并将状态加载到其中。如果你还希望保存模型本身，你可以传入整个模型，而不是状态：'
- en: '[PRE9]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'But remember, due to the nature of Python language, doing so does not relieve
    you from keeping the code of the model. The `newmodel` object above is an instance
    of `Multiclass` class that you defined before. When you load the model from disk,
    Python need to know in detail how this class is defined. If you run a script with
    just the line `torch.load()`, you will see the following error message:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 但请记住，由于Python语言的特性，这并不会免除你需要保存模型代码的责任。上面的`newmodel`对象是你之前定义的`Multiclass`类的一个实例。当你从磁盘加载模型时，Python需要详细知道这个类是如何定义的。如果你仅运行`torch.load()`这一行脚本，你将看到以下错误信息：
- en: '[PRE10]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: That’s why it is recommended to save only the state dict rather than the entire
    model.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是为什么推荐只保存状态字典而不是整个模型的原因。
- en: 'Putting everything together, the following is the complete code to demonstrate
    how to create a model, train it, and save to disk:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 将所有内容整合在一起，以下是展示如何创建模型、训练它并保存到磁盘的完整代码：
- en: '[PRE11]'
  id: totrans-50
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'And the following is how to load the model from disk and run it for inference:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是如何从磁盘加载模型并进行推理的步骤：
- en: '[PRE12]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: Further Readings
  id: totrans-53
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: This section provides more resources on the topic if you are looking to go deeper.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 本节提供了更多关于此主题的资源，帮助你深入了解。
- en: '[Saving and loading models](https://pytorch.org/tutorials/beginner/saving_loading_models.html)
    from PyTorch tutorial'
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[PyTorch 教程中的保存和加载模型](https://pytorch.org/tutorials/beginner/saving_loading_models.html)'
- en: Summary
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: In this post, you learned how to keep a copy of your trained PyTorch model in
    disk and how to reuse it. In particular, you learned
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，你学习了如何将训练好的 PyTorch 模型保存在磁盘中以及如何重新使用它。特别是，你学到了
- en: What are parameters and states in a PyTorch model
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 PyTorch 模型中，什么是参数和状态
- en: How to save all necessary states from a model to disk
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何将模型的所有必要状态保存到磁盘
- en: How to rebuild a working model from the saved states
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何从保存的状态重建一个可用的模型
