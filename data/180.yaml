- en: Using OpenPose with Stable Diffusion
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用稳定扩散的 OpenPose
- en: 原文：[https://machinelearningmastery.com/openpose-with-stable-diffusion/](https://machinelearningmastery.com/openpose-with-stable-diffusion/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://machinelearningmastery.com/openpose-with-stable-diffusion/](https://machinelearningmastery.com/openpose-with-stable-diffusion/)
- en: We have just learned about ControlNet. Now, let’s explore the most effective
    way to control your character based on human pose. OpenPose is a great tool that
    can detect body keypoint locations in images and video. By integrating OpenPose
    with Stable Diffusion, we can guide the AI in generating images that match specific
    poses.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 我们刚刚了解了 ControlNet。现在，让我们探索基于人体姿势控制角色的最有效方式。OpenPose 是一个强大的工具，可以在图像和视频中检测身体关键点的位置。通过将
    OpenPose 与稳定扩散集成，我们可以引导 AI 生成与特定姿势匹配的图像。
- en: 'In this post, you will learn about ControlNet’s OpenPose and how to use it
    to generate similar pose characters. Specifically, we will cover:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，您将了解 ControlNet 的 OpenPose 及如何使用它生成类似的姿势角色。具体来说，我们将涵盖：
- en: What is Openpose, and how does it work?
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Openpose 是什么，它是如何工作的？
- en: How to use ControlNet Hugging Face Spaces to generate precise images using the
    reference image.
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用 ControlNet Hugging Face Spaces 使用参考图像生成精确图像。
- en: How to set up OpenPose in Stable Diffusion WebUI and use it to create high-quality
    images.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在稳定扩散的 WebUI 中设置 OpenPose 并使用它创建高质量的图像。
- en: Various OpenPose processors focus on certain parts of the body.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同的 OpenPose 处理器专注于身体的特定部位。
- en: '**Kick-start your project** with my book [Mastering Digital Art with Stable
    Diffusion](https://machinelearningmastery.com/mastering-digital-art-with-stable-diffusion/).
    It provides **self-study tutorials** with **working code**.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**使用我的书[《稳定扩散数字艺术精通》](https://machinelearningmastery.com/mastering-digital-art-with-stable-diffusion/)**来**启动您的项目**。它提供了**自学教程**和**工作代码**。'
- en: Let’s get started.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: '![](../Images/3606e61ba6df95141b1126b5f32b458e.png)'
  id: totrans-10
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/3606e61ba6df95141b1126b5f32b458e.png)'
- en: Using OpenPose with Stable Diffusion
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 使用稳定扩散的 OpenPose
- en: Photo by [engin akyurt](https://unsplash.com/photos/brown-wooden-figurine-on-red-wooden-surface-udh1F6tuOr8).
    Some rights reserved.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由[engin akyurt](https://unsplash.com/photos/brown-wooden-figurine-on-red-wooden-surface-udh1F6tuOr8)拍摄。部分权利保留。
- en: Overview
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'This post is in four parts; they are:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这篇文章分为四个部分，它们是：
- en: What is ControlNet OpenPose?
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是 ControlNet OpenPose？
- en: ControlNet in Hugging Face Space
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Hugging Face Space 中的 ControlNet
- en: OpenPose Editor in Stable Diffusion Web UI
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在稳定扩散的 Web UI 中的 OpenPose 编辑器
- en: Image to Image Generation
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像生成
- en: What is ControlNet OpenPose?
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是 ControlNet OpenPose？
- en: OpenPose is a deep learning model to detect human pose from an image. Its output
    are the positions of several **keypoints** (such as elbows, wrists, and knees)
    of the human in the picture. The OpenPose model in ControlNet is to accept the
    keypoints as the additional conditioning to the diffusion model and produce the
    output image with human aligned with those keypoints. Once you can specify the
    precise position of keypoints, it allows you to generate realistic images of human
    poses based on a skeleton image. You can use it to create artistic photos, animations,
    or illustrations of different poses.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: OpenPose 是一种深度学习模型，用于从图像中检测人体姿势。它的输出是图片中人物的多个**关键点**（如肘部、手腕和膝盖）的位置。ControlNet
    中的 OpenPose 模型将这些关键点作为额外的条件输入到扩散模型中，并生成与这些关键点对齐的人物图像。一旦您能指定关键点的精确位置，就能够基于骨架图生成真实的人体姿势图像。您可以使用它来创建不同姿势的艺术照片、动画或插图。
- en: ControlNet in Hugging Face Spaces
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Hugging Face Spaces 中的 ControlNet
- en: 'To try out the capability of ControlNet OpenPose model, you can use the free
    online demo on Hugging Face Spaces:'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 要尝试 ControlNet OpenPose 模型的能力，您可以在 Hugging Face Spaces 的免费在线演示中使用：
- en: '[https://hf.co/spaces/hysts/ControlNet-v1-1](https://hf.co/spaces/hysts/ControlNet-v1-1)'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://hf.co/spaces/hysts/ControlNet-v1-1](https://hf.co/spaces/hysts/ControlNet-v1-1)'
- en: To start, you need to create the pose keypoints. This can be done easily by
    uploading an image and let the OpenPose model to detect them. First, you can download
    [Yogendra Singh](https://www.pexels.com/photo/dancing-man-wearing-pants-and-long-sleeved-shirt-1701194/)‘s
    photo and then upload it to the ControlNet Spaces. This ControlNet helps you to
    pin down the pose, but you still need to provide a text prompt to generate a picture.
    Let’s write the simple prompt “A woman is dancing in the rain.” and press the
    run button.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 开始时，您需要创建姿势关键点。这可以通过上传图像并让 OpenPose 模型检测它们来轻松完成。首先，您可以下载[Yogendra Singh](https://www.pexels.com/photo/dancing-man-wearing-pants-and-long-sleeved-shirt-1701194/)的照片，然后将其上传到
    ControlNet Spaces。这个 ControlNet 帮助您锚定姿势，但您仍然需要提供文本提示以生成图片。让我们写一个简单的提示：“一个女人在雨中跳舞。”，然后点击运行按钮。
- en: '![](../Images/8410b1e5c81d06b59d90f605a984a48c.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8410b1e5c81d06b59d90f605a984a48c.png)'
- en: Using OpenPose ControlNet model on Hugging Face Spaces
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在Hugging Face Spaces上使用OpenPose ControlNet模型
- en: Due to the random nature of image generation, you may want to do multiple attempts.
    You may also polish the prompt to give more details, such as the lighting, the
    scene, and the outfit that the woman is wearing. You can even expand the “Advanced
    options” panel at the bottom to provide more settings, such as negative prompts.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 由于图像生成的随机性，你可能需要进行多次尝试。你还可以优化提示，以提供更多细节，例如光照、场景和女性穿着的服装。你甚至可以展开底部的“高级选项”面板，提供更多设置，例如负面提示。
- en: '![](../Images/69642440b5561e212027d88f4db558a3.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/69642440b5561e212027d88f4db558a3.png)'
- en: Settings in the “Advanced options” panel
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: “高级选项”面板中的设置
- en: In the example above, you can see that a high quality image of a woman dancing
    in the rain from a skeleton image is generated, in the similar pose as your uploaded
    image. Below are three other generations under the same prompt, all are exceptional
    and accurately follow the pose of the reference image.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述示例中，你可以看到从骨架图像生成的高质量女性在雨中跳舞的图像，与上传的图像姿势类似。以下是三个在相同提示下生成的其他图像，所有图像都非常出色，并准确地遵循了参考图像的姿势。
- en: '![](../Images/ca2b3dbe3be2f5e251bfa3c185ac4fa6.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/ca2b3dbe3be2f5e251bfa3c185ac4fa6.png)'
- en: Other generated images from the same prompt
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 使用相同提示生成的其他图像
- en: OpenPose Editor from Stable Diffusion Web UI
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Stable Diffusion Web UI中的OpenPose编辑器
- en: You can also use the OpenPose ControlNet model from the Stable Diffusion Web
    UI. Indeed, not only you can upload an image to get the pose, you can edit the
    pose before applying to the diffusion model. In this section, you will learn how
    to set up OpenPose locally and generate images using OpenPose Editor.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 你还可以使用Stable Diffusion Web UI中的OpenPose ControlNet模型。实际上，你不仅可以上传图像以获取姿势，还可以在应用到扩散模型之前编辑姿势。在本节中，你将学习如何在本地设置OpenPose并使用OpenPose编辑器生成图像。
- en: Before you start using the OpenPose editor, you have to install it and download
    the model file.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始使用OpenPose编辑器之前，你需要先安装它并下载模型文件。
- en: Make sure you have installed the ControlNet extension, if not please check the
    previous post.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 确保你已安装ControlNet扩展，如果没有，请查看之前的帖子。
- en: 'Install OpenPose Editor extension: At the “Extensions” tab on WebUI,  click
    on “Install from URL” and enter the following URL to install:'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 安装OpenPose编辑器扩展：在WebUI的“Extensions”标签中，点击“Install from URL”并输入以下网址进行安装：
- en: https://github.com/fkunn1326/openpose-editor
  id: totrans-38
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: https://github.com/fkunn1326/openpose-editor
- en: 'Go to Hugging Face repository: [https://hf.co/lllyasviel/ControlNet-v1-1/tree/main](https://hf.co/lllyasviel/ControlNet-v1-1/tree/main)'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往Hugging Face仓库：[https://hf.co/lllyasviel/ControlNet-v1-1/tree/main](https://hf.co/lllyasviel/ControlNet-v1-1/tree/main)
- en: Download the OpenPose model “[control_v11p_sd15_openpose.pth](https://huggingface.co/lllyasviel/ControlNet-v1-1/blob/main/control_v11p_sd15_openpose.pth)”
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载OpenPose模型 “[control_v11p_sd15_openpose.pth](https://huggingface.co/lllyasviel/ControlNet-v1-1/blob/main/control_v11p_sd15_openpose.pth)”
- en: Put the model file in the the SD WebUI directory in stable-diffusion-webui/extensions/sd-webui-controlnet/models
    or stable-diffusion-webui/models/ControlNet
  id: totrans-41
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型文件放入SD WebUI目录中的stable-diffusion-webui/extensions/sd-webui-controlnet/models或stable-diffusion-webui/models/ControlNet文件夹中
- en: Now that you have everything set up and a new tab named “OpenPose Editor” is
    added to the Web UI. Navigate to the “OpenPose Editor” tab and adjust the canvas
    width and height to your preference. Next, you can start modifying the skeleton
    image on the right using your mouse. It’s a straightforward process.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你已经完成了所有设置，并且Web UI中添加了一个名为“OpenPose Editor”的新标签。导航到“OpenPose Editor”标签，并根据你的喜好调整画布的宽度和高度。接下来，你可以开始使用鼠标修改右侧的骨架图像。这是一个简单的过程。
- en: 'Let’s try to create a picture of a man carrying a large gun. You can make changes
    to the skeleton image to make it looks like the following:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试创建一张男人拿着大枪的图片。你可以对骨架图像进行修改，使其看起来像下面的样子：
- en: '![](../Images/f457dd5e4e12f3425c110256c1693677.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f457dd5e4e12f3425c110256c1693677.png)'
- en: Creating a pose with the OpenPose Editor
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 使用OpenPose编辑器创建姿势
- en: Then, click on the “Send to text2img” button. It will take you to text2img with
    the skeleton image added to the ControlNet panel.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，点击“Send to text2img”按钮。这将带你进入text2img界面，并将骨架图像添加到ControlNet面板中。
- en: '![](../Images/2c06ba12b0b0c0354ef90c988b663830.png)'
  id: totrans-47
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2c06ba12b0b0c0354ef90c988b663830.png)'
- en: The created pose on the ControlNet panel
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: ControlNet面板上创建的姿势
- en: Then, select “Enable” for this ControlNet model and make sure the “OpenPose”
    option is checked. You can also check “Low VRAM” and “Pixel Perfect”. The former
    is useful if your computer does not have enough memory on the GPU and the latter
    is to ask the ControlNet model to use the optimal resolution to match the output.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，为该 ControlNet 模型选择“启用”，确保选中“OpenPose”选项。您还可以选中“低 VRAM”和“像素完美”。前者适用于 GPU
    内存不足的计算机，后者是为了使 ControlNet 模型使用最佳分辨率以匹配输出。
- en: Next, you set up the positive and negative prompt, make changes to the size
    of the output image, the sampling method, and sampling steps. For example, the
    positive prompt can be
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，设置正面和负面提示，调整输出图像大小、采样方法和采样步骤。例如，正面提示可以是
- en: detailed, masterpiece, best quality, Astounding, Enchanting, Striking, tom clancy’s
    the division, man_holding_gun, us_marine, beach background
  id: totrans-51
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 详细，杰作，最佳质量，令人惊叹，迷人，引人注目，汤姆克兰西的分裂，持枪的人，美国海军陆战队员，海滩背景
- en: and the negative prompt can be
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 负面提示可以是
- en: worst quality, low quality, lowres, monochrome, greyscale, multiple views, comic,
    sketch, bad anatomy, deformed, disfigured, watermark, multiple_views, mutation
    hands, watermark, bad facial
  id: totrans-53
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 最差质量，低质量，低分辨率，单色，灰度，多视角，漫画，素描，解剖不良，畸形，变形，水印，多视角，变异手部，水印，面部不佳
- en: The image below, using size 912×512 and sampler DDIM for 30 steps, turned out
    to be perfectly matching the similar pose, with good details.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的图像，使用尺寸为 912×512 和 DDIM 采样器进行 30 步，结果完全匹配相似的姿势，并且有很好的细节。
- en: '![](../Images/18199b4bcb421afb2ac7c46dedaa3345.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/18199b4bcb421afb2ac7c46dedaa3345.png)'
- en: Output using OpenPose ControlNet model
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 OpenPose ControlNet 模型生成的输出
- en: Image to Image Generation
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 图像生成
- en: If you tried the ControlNet model in the Web UI, you should notice there are
    multiple OpenPose preprocessors. In the following, let’s explore some of them
    to focus on the face and upper body.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在 Web UI 中尝试了 ControlNet 模型，您应该注意到有多个 OpenPose 预处理器。接下来，让我们探索其中一些，重点放在面部和上半身。
- en: 'We will use [the photo by Andrea Piacquadio](https://www.pexels.com/photo/woman-in-white-blazer-holding-tablet-computer-789822/)
    from Pexels.com as a reference image. In the Web UI, let’s switch to the “img2img”
    tab and upload the reference image. Then at the ControlNet panel, enable and select
    “OpenPose” as the control type. By default in img2img, you will share the reference
    image with ControlNet. Next, change the Preprocessor to “openpose_face” in the
    ControNet panel, as follows:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将使用 [Andrea Piacquadio 的照片](https://www.pexels.com/photo/woman-in-white-blazer-holding-tablet-computer-789822/)
    作为参考图像。在 Web UI 中，切换到“img2img”选项卡并上传参考图像。然后在 ControlNet 面板中，启用并选择“OpenPose”作为控制类型。在
    img2img 中，默认情况下将与 ControlNet 共享参考图像。接下来，在 ControNet 面板中将预处理器改为“openpose_face”，如下所示：
- en: '![](../Images/c3c92ab6adea486406ccc31de9e89e94.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c3c92ab6adea486406ccc31de9e89e94.png)'
- en: Using “openpose_face” as the preprocessor
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 使用“openpose_face”作为预处理器
- en: 'Afterward, set the positive prompt to match the style of the reference image
    and generate the image. Instead of a picture holding a tablet, let’s make the
    woman holding a phone:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，将正面提示设置为与参考图像风格相匹配，并生成图像。不再是拿着平板电脑的图片，让我们让这位女士拿着手机：
- en: detailed, best quality, Astounding, Enchanting, Striking, new_york, buildings,
    city, phone on the ear
  id: totrans-63
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 详细，最佳质量，令人惊叹，迷人，引人注目，纽约，建筑，城市，手机放在耳边
- en: 'Below is what you might get:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是可能获得的结果：
- en: '![](../Images/0cea84197b9246661d5f40ff6962ee8a.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0cea84197b9246661d5f40ff6962ee8a.png)'
- en: Image generated with img2img
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 img2img 生成的图像
- en: We got a high quality result with the similar pose. You have to play around
    the prompt to match the pose. The preprocessor used here is “openpose_face” which
    means the pose as well as the face. Therefore, the generated picture matched the
    reference in the limb positions as well as facial expression.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 我们通过类似的姿势获得了高质量的结果。您需要调整提示来匹配这个姿势。这里使用的预处理器是“openpose_face”，意味着不仅匹配姿势还包括面部表情。因此，生成的图片不仅在肢体位置上与参考图像匹配，而且在面部表情上也是如此。
- en: Let’s change the Preprocessor to “openpose_faceonly” to focus on facial features
    only. In this way, only the keypoints on the face are recognized and no information
    about the body pose will be applied from the ControlNet model. Now, set the prompt
    to
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们将预处理器更改为“openpose_faceonly”，只专注于面部特征。这样，只有面部关键点被识别，不会从 ControlNet 模型应用有关身体姿势的信息。现在，将提示设置为
- en: detailed, best quality, Astounding, Enchanting, Striking, new_york, buildings,
    city
  id: totrans-69
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 详细，最佳质量，令人惊叹，迷人，引人注目，纽约，建筑，城市
- en: 'An improved result is generated accurately by following each keyword in the
    prompt, but the body pose is vastly different from the previous:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 按照提示中的每个关键词生成了一个更准确的结果，但身体姿势与之前的姿势有很大不同：
- en: '![](../Images/c8d056c474f104ed7845ca78c61509c7.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c8d056c474f104ed7845ca78c61509c7.png)'
- en: Image generated with the ControlNet provided only the facial keypoints
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 ControlNet 仅提供面部关键点生成的图像
- en: To understand why this is the case, you can check the output image from the
    **preprocessor**, as follows. The top image was generated using the “openpose_face”
    preprocessor, while the bottom image was generated using “openpose_faceonly”.
    Similarly, you can understand the output of various preprocessors by analyzing
    both skeleton structures.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解为什么会这样，你可以检查**预处理器**的输出图像。上面的图像是使用“openpose_face”预处理器生成的，而下面的图像是使用“openpose_faceonly”生成的。同样，你可以通过分析这两种骨架结构来了解各种预处理器的输出。
- en: '![](../Images/6a8ce4fcfff7bd56d07814d7370cbbc3.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6a8ce4fcfff7bd56d07814d7370cbbc3.png)'
- en: Keypoints generated from different OpenPose preprocessors
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 从不同 OpenPose 预处理器生成的关键点
- en: Further Readings
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: This section provides more resources on the topic if you are looking to go deeper.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 本节提供了更多资源，如果你希望深入了解这一主题。
- en: '[OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields](https://arxiv.org/abs/1812.08008)
    by Cao et al (2019)'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenPose: 实时多人 2D 姿态估计使用部件关联场](https://arxiv.org/abs/1812.08008) 作者 Cao 等（2019）'
- en: '[OpenPose](https://github.com/CMU-Perceptual-Computing-Lab/openpose) on GitHub'
  id: totrans-79
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenPose](https://github.com/CMU-Perceptual-Computing-Lab/openpose) 在 GitHub
    上'
- en: '[Controlnet – Human Pose Version](https://huggingface.co/lllyasviel/sd-controlnet-openpose)
    on Hugging Face'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Controlnet – 人体姿态版本](https://huggingface.co/lllyasviel/sd-controlnet-openpose)
    在 Hugging Face 上'
- en: '[Openpose Controlnets (V1.1): Using poses and generating new ones](https://civitai.com/articles/157/openpose-controlnets-v11-using-poses-and-generating-new-ones)'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Openpose Controlnets (V1.1): 使用姿势和生成新姿势](https://civitai.com/articles/157/openpose-controlnets-v11-using-poses-and-generating-new-ones)'
- en: Summary
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this post, we delved deeper into the world of ControlNet OpenPose and how
    we can use it to get precise results. Specifically, we covered:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们深入探讨了 ControlNet OpenPose 的世界以及如何利用它获得精准的结果。具体来说，我们讨论了：
- en: What is OpenPose, and how can it generate images immediately without setting
    up anything?
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是 OpenPose，它如何在不设置任何东西的情况下立即生成图像？
- en: How to use Stable Diffusion WebUI and OpenPose Editor to generate an image of
    a custom pose by modifying the prompt and skeleton image.
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用 Stable Diffusion WebUI 和 OpenPose 编辑器通过修改提示和骨架图像生成自定义姿势的图像。
- en: Multiple OpenPose preprocessors to generate the image using full-face and face-only
    preprocessors in Stable Diffusion WebUI.
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 多种 OpenPose 预处理器，用于在 Stable Diffusion WebUI 中生成全脸和仅脸部的图像。
