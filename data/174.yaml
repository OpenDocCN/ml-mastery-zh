- en: Training Stable Diffusion with Dreambooth
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 Dreambooth 训练稳定扩散
- en: 原文：[https://machinelearningmastery.com/training-stable-diffusion-with-dreambooth/](https://machinelearningmastery.com/training-stable-diffusion-with-dreambooth/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://machinelearningmastery.com/training-stable-diffusion-with-dreambooth/](https://machinelearningmastery.com/training-stable-diffusion-with-dreambooth/)
- en: 'Stable Diffusion is trained on LAION-5B, a large-scale dataset comprising billions
    of general image-text pairs. However, it falls short of comprehending specific
    subjects and their generation in various contexts (often blurry, obscure, or nonsensical).
    To address this problem, fine-tuning the model for specific use cases becomes
    crucial. There are two important fine-tuning techniques for stable Diffusion:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: Stable Diffusion 是在 LAION-5B 上训练的，这是一个包含数十亿通用图像文本对的大规模数据集。然而，在理解特定主题及其生成在不同语境中方面存在不足（通常是模糊的、模糊的或无意义的）。为了解决这个问题，对稳定扩散进行特定用例的微调变得至关重要。对于稳定扩散有两种重要的微调技术：
- en: 'Textual inversion: This technique focuses on retraining the text embeddings
    of a model to inject a word as a subject.'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 文本反转：这种技术专注于重新训练模型的文本嵌入，将一个词注入为主题。
- en: 'DreamBooth: Unlike textual inversion, DreamBooth involves the retraining of
    the entire model, tailored specifically to the subject, thereby enabling better
    personalization.'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DreamBooth：与文本反转不同，DreamBooth 涉及重新训练整个模型，专门针对主题进行优化，从而实现更好的个性化。
- en: 'In this post, you will explore the following concepts:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，您将探索以下概念：
- en: Fine-tuning challenges and recommended settings in DreamBooth
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DreamBooth 中的微调挑战和推荐设置
- en: Stable Diffusion fine-tuning with DreamBooth – Example
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 DreamBooth 进行稳定扩散微调的示例
- en: Tips to use Dreambooth in Stable Diffusion effectively
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有效使用 Dreambooth 在稳定扩散中的提示
- en: '**Kick-start your project** with my book [Mastering Digital Art with Stable
    Diffusion](https://machinelearningmastery.com/mastering-digital-art-with-stable-diffusion/).
    It provides **self-study tutorials** with **working code**.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**启动你的项目**，使用我的书籍 [掌握稳定扩散数字艺术](https://machinelearningmastery.com/mastering-digital-art-with-stable-diffusion/)。它提供了
    **自学教程** 和 **工作代码**。'
- en: Let’s get started
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧
- en: '![](../Images/f22bad9034f63a4c6f3fe080e6b0b1fe.png)'
  id: totrans-11
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f22bad9034f63a4c6f3fe080e6b0b1fe.png)'
- en: Training Stable Diffusion with DreamBooth
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 DreamBooth 训练稳定扩散
- en: Photo by [Sasha Freemind](https://unsplash.com/photos/woman-standing-on-grass-field-frq5Q6Ne9k4).
    Some rights reserved.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 摄影师 [Sasha Freemind](https://unsplash.com/photos/woman-standing-on-grass-field-frq5Q6Ne9k4)。部分权利保留。
- en: Overview
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'This post is in five parts; they are:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本文分为五部分；它们是：
- en: What is DreamBooth?
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是 DreamBooth？
- en: Fine-Tuning Challenges
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 微调挑战
- en: Workflow of Fine-Tuning with DreamBooth
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 DreamBooth 进行微调的工作流程
- en: Using Your Trained Model
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用您训练过的模型
- en: Tips to Use DreamBooth Effectively
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 DreamBooth 效果的技巧
- en: What is DreamBooth?
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是 DreamBooth？
- en: DreamBooth is a significant leap in generative AI particularly, Text2Img models.
    It is a specialized technique introduced by a group of Google researchers, to
    fine-tune pre-trained large Text2Img models such as Stable Diffusion towards specific
    subjects, characters, or objects. So now you can inject a custom object or a concept
    into the model for a more personalized and diverse generation. Here’s how Google
    researchers put it
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: DreamBooth 是生成 AI 中的重大飞跃，特别是 Text2Img 模型。它是谷歌研究人员引入的一种专门技术，用于微调预训练的大型 Text2Img
    模型，例如 Stable Diffusion，以特定的主题、字符或对象。现在你可以向模型注入自定义对象或概念，以获得更个性化和多样化的生成结果。这是谷歌研究人员的表述方式
- en: It’s like a photo booth, but once the subject is captured, it can be synthesized
    wherever your dreams take you.
  id: totrans-23
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 它就像一个照相亭，但一旦捕捉到主题，它可以在你的梦中合成。
- en: DreamBooth offers a range of exciting use cases across various fields primarily
    focused on enhancing image generation. This includes
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: DreamBooth 在各个领域提供了一系列令人兴奋的用例，主要集中在增强图像生成方面。这包括
- en: '**Personalization:** Users can create images of loved ones, pets, or specific
    objects, making them suitable for gifting, social media, and personalized merchandise.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**个性化：** 用户可以创建所爱之人、宠物或特定对象的图像，适合作为礼物、社交媒体和个性化商品。'
- en: '**Art and Commercial Purposes:** Artists and designers can train the model
    with their artwork to generate diverse artistic images and visualizations. It’s
    also beneficial for commercial purposes, allowing tailored image generation for
    branding and marketing needs.'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**艺术和商业用途：** 艺术家和设计师可以用他们的艺术作品训练模型，生成多样化的艺术图像和视觉化效果。这对于商业用途也很有益，可以根据品牌和营销需求进行定制图像生成。'
- en: '**Research and Experimentation:** DreamBooth is a powerful tool for researchers.
    It enables exploring deep learning models, domain-specific applications, and controlled
    experiments. By fine-tuning models, researchers can push the boundaries of generative
    AI and gain new insights into its potential.'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**研究与实验：** DreamBooth 是一个强大的研究工具。它使探索深度学习模型、领域特定应用和受控实验成为可能。通过微调模型，研究人员可以推动生成式
    AI 的边界，并获得对其潜力的新见解。'
- en: 'With just a few images of your subject, along with its class name during training
    and a specially tailored prompt during inference, you can generate personalized
    outputs. Let’s dive into the DreamBooth fine-tuning process:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 只需提供几张你主题的图像，加上训练期间的类别名称和推理期间特别定制的提示，你就可以生成个性化的输出。让我们深入了解 DreamBooth 微调过程：
- en: Create a fine-tuning image dataset
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 创建微调图像数据集
- en: Include a few (3-5) high-quality and representative images of your subject.
    The model will learn to get accustomed to the subject based on the training data
    so it needs to be carefully designed. Further details are discussed in the fine-tuning
    section.
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 包含几张（3-5 张）高质量和具有代表性的主题图像。模型将根据训练数据学习如何适应主题，因此需要仔细设计。有关更多详细信息，请参见微调部分。
- en: Bind a unique identifier and class name
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 绑定唯一标识符和类别名称
- en: The subject must be associated with a rare token not frequently used in the
    text model’s vocabulary. The model will recognize the subject through this unique
    identifier. To maintain the original essence of the subject, you also need to
    provide a class name (which the model already knows) during training. For example,
    you can associate a personal pet dog with an identifier “[V]” and a class name
    “dog,” so when prompted “a [V] dog sitting,” the model will recognize the pet
    dog’s identifier when generating a dog image.
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 主题必须与文本模型词汇表中不常用的稀有标记关联。模型将通过这个唯一标识符识别主题。为了保持主题的原始本质，你还需要在训练期间提供一个类别名称（模型已经知道）。例如，你可以将个人宠物狗与标识符
    “[V]” 和类别名称 “dog” 关联，以便当提示 “a [V] dog sitting” 时，模型在生成狗图像时会识别出宠物狗的标识符。
- en: '![](../Images/392d2351304ef91063b51ed21e8936a2.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/392d2351304ef91063b51ed21e8936a2.png)'
- en: Fine-tuning a model. Image from [DreamBooth](https://dreambooth.github.io/)
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 微调模型。图像来自 [DreamBooth](https://dreambooth.github.io/)
- en: The first criterion above is important for obvious reasons in image generation.
    The second criterion is also important because you are not training Stable Diffusion
    from scratch but fine-tuning the existing model to adapt to your dataset. The
    model already learned what a dog is. It is easier to learn that your token is
    a variation of a dog than to unlearn a word (i.e., reassign the meaning of a word
    to a totally different concept) or to learn a new word from scratch (e.g., learn
    what a dog is from a model that never saw any animal).
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 上述第一个标准在图像生成中因显而易见的原因而重要。第二个标准也很重要，因为你不是从头开始训练 Stable Diffusion，而是对现有模型进行微调以适应你的数据集。模型已经学会了什么是狗。让模型学习你的标记是狗的变种比让模型忘记一个词（即将一个词的意义重新分配给一个完全不同的概念）或从头开始学习一个新词（例如，从一个从未见过任何动物的模型中学习狗是什么）要容易。
- en: Fine-Tuning Challenges
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 微调挑战
- en: 'To fine-tune a Stable Diffusion model means restarting the training from an
    existing model known to work. This particular type of training has some challenges:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 微调一个 Stable Diffusion 模型意味着从一个已知有效的现有模型开始重新训练。这种特定类型的训练有一些挑战：
- en: Overfitting
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 过拟合
- en: Overfitting occurs when the model memorizes training data too closely, forgetting
    how to generalize. It starts performing well only on training data but flops on
    new data. Since you only provide a handful of images to Dreambooth, it’s likely
    to overfit quickly.
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 过拟合发生在模型过于紧密地记忆训练数据时，从而忘记如何进行泛化。它开始只对训练数据表现良好，但对新数据表现不佳。由于你只提供了少量图像给 Dreambooth，它可能会迅速发生过拟合。
- en: Language drift
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 语言漂移
- en: Language drift is a common occurrence in fine-tuning language models and extends
    its impact to Txt2Img models. During fine-tuning, models might lose vital information
    on the diverse representations of subjects within a class. This drift causes models
    to struggle to generate varied subjects within the same category, affecting the
    richness and diversity of outputs.
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 语言漂移是在微调语言模型时常见的现象，并且这种影响扩展到 Txt2Img 模型。在微调期间，模型可能会丧失有关类别内不同表现形式的重要信息。这种漂移导致模型在生成同一类别中的多样化主题时出现困难，从而影响输出的丰富性和多样性。
- en: 'Here are a few DreamBooth settings, and by carefully adjusting these, you can
    make the model more adaptable to generate diverse outputs while also reducing
    the risk of overfitting and language drift:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这里有几个DreamBooth设置，通过仔细调整这些设置，您可以使模型更适应生成多样化的输出，同时还减少过拟合和语言漂移的风险：
- en: Optimizing learning rate and training steps
  id: totrans-43
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 优化学习率和训练步骤
- en: Tuning the learning rate, training steps, and batch size is crucial to overcome
    overfitting. A high learning rate and many training steps cause overfitting (affecting
    diversity). A small learning rate and fewer training steps will underfit the model
    (failing to capture the subject). Therefore, starting with a lower learning rate
    and progressively increasing training steps until generation seems satisfactory
    is suggested.
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 调整学习率、训练步骤和批量大小是克服过拟合的关键。高学习率和许多训练步骤会导致过拟合（影响多样性）。小学习率和较少的训练步骤将导致模型拟合不足（未能捕捉主题）。因此，建议从较低的学习率开始，并逐步增加训练步骤，直到生成看起来令人满意为止。
- en: Prior-preservation loss
  id: totrans-45
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 先前保留损失
- en: This is done by generating new samples (around 200 to 300) of the same class
    along with the subject’s images and then adding these to our training image set.
    These additional images are generated by the stable diffusion model itself via
    a class prompt.
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过生成相同类别的新样本（大约200到300个）以及主题图像，然后将这些添加到我们的训练图像集中来完成。这些额外的图像是通过一个类提示由稳定扩散模型本身生成的。
- en: GPU-efficient techniques
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: GPU高效技术
- en: Techniques like 8bit-Adam (supports quantization), fp16 mixed precision training
    (reduces the precision of gradient calculation to 16-bit float), and gradient
    accumulation (computes gradients in small steps rather than for entire batch)
    can help optimize memory utilization and speed up training.
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 诸如8bit-Adam（支持量化）、fp16混合精度训练（将梯度计算的精度降低到16位浮点数）和梯度累积（分步计算梯度而不是整个批量）等技术可以帮助优化内存利用和加快训练速度。
- en: Workflow of Fine-Tuning with DreamBooth
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DreamBooth微调工作流程
- en: We’re ready to start the fine-tuning process and use a simplified version of
    a diffuser-based DreamBooth training script, as below. With the above-mentioned
    GPU efficient techniques, you can run this script on a Tesla T4 GPU provided in
    the Google Colab Notebook.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我们已经准备好开始微调过程，并使用基于扩散器的DreamBooth训练脚本的简化版本，如下所示。借助上述GPU高效技术，您可以在Google Colab笔记本中的Tesla
    T4 GPU上运行此脚本。
- en: 'Before starting, you should set up the environment. In a notebook cell, you
    use the following to run shell commands:'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始之前，您应该设置环境。在笔记本单元格中，您可以使用以下内容来运行shell命令：
- en: '[PRE0]'
  id: totrans-52
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'In the above, the training script downloaded is named `train_dreambooth.py`.
    A conversion script is also downloaded to process the training output. Some packages
    are installed in the Python environment. To verify it works, you can run these
    imports in a new cell to make sure no error is triggered:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述中，下载的训练脚本名为`train_dreambooth.py`。还下载了一个转换脚本来处理训练输出。一些包已安装在Python环境中。为了验证其是否正常工作，您可以在新的单元格中运行这些导入语句，以确保没有触发任何错误：
- en: '[PRE1]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Training a Stable Diffusion model is resource-hungry. It is better to leverage
    some online resources to store the model. The script assumes you signed up for
    a Hugging Face account and obtained the API tokens. Please provide your access
    token within the designated field labeled as `HUGGINGFACE_TOKEN` for the script
    to work, i.e.,
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 训练稳定扩散模型需要大量资源。最好利用一些在线资源来存储模型。脚本假定您已注册了Hugging Face账户并获得了API令牌。请在标记为`HUGGINGFACE_TOKEN`的指定字段中提供您的访问令牌，以使脚本正常工作，即，
- en: '[PRE2]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Let’s specify our base model and output directory where the model gets saved.
    We’ll pass these variables when launching the script.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们指定我们的基础模型和输出目录，模型将在其中保存。我们将在启动脚本时传递这些变量。
- en: '[PRE3]'
  id: totrans-58
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Now is the most crucial part of getting satisfactory and consistent results
    from DreamBooth. It’s important to use high-quality images that represent your
    subject. Note that the model will learn artifacts such as low resolution or motion
    blur within the training set. Here’s what should be considered while creating
    the dataset:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 现在是从DreamBooth中获得满意和一致结果的最关键部分。重要的是使用代表您主题的高质量图像。请注意，模型将从训练集中学习到低分辨率或运动模糊等工件。在创建数据集时应考虑以下几点：
- en: 'Dataset size: As these models can overfit quickly, it’s better to include 10
    to 120 samples of your subject. Crop them and resize them to 512×512 pixels'
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集大小：由于这些模型可能很快过拟合，最好包括10到120个主题样本。将它们裁剪并调整大小为512×512像素
- en: 'Image diversity: Pick consistent samples of what you want exactly, and try
    including images from different angles. For diversity, you may need to include
    background scenes of people, landscapes, or animals/objects as well. Also, remove
    unwanted objects inside (e.g., watermarks, people cut off by the edge). Avoid
    using images with a plain or transparent background.'
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 图像多样性：选择一致的样本，并尝试包括不同角度的图像。为了多样性，你可能需要包含背景场景，如人物、风景或动物/物体。此外，移除内部的多余物体（例如，水印、被边缘剪裁的人物）。避免使用背景单一或透明的图像。
- en: 'Before you upload the images to the Colab notebook, let’s run the following
    cell:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在你将图像上传到Colab笔记本之前，让我们运行以下单元格：
- en: '[PRE4]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: After running this cell, the path mapped with `instance_data_dir` above is created
    as a directory. The images you prepared should be uploaded to the directory above
    using the File icon on the side panel of Colab notebook.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 运行此单元格后，映射到`instance_data_dir`的路径会被创建为一个目录。你准备的图像应通过Colab笔记本侧边面板上的文件图标上传到上述目录。
- en: The `instance_prompt` is an example. You should update this to how you want
    to name your images. Using a new token (such as “zwx” above) as a unique identifier
    is encouraged. But the `class_prompt` should use only well-understood words to
    highlight the image.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '`instance_prompt` 是一个示例。你应根据你希望为图像命名的方式进行更新。建议使用新的令牌（例如上述“zwx”）作为唯一标识符。但`class_prompt`应仅使用易于理解的词语来突出图像。'
- en: 'In this example, we’re fine-tuning Stable Diffusion on Husky dogs, and we have
    provided 7 instance images. You can try something similar. After this cell, your
    directory structure may look like the following:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个示例中，我们正在对Husky犬进行Stable Diffusion微调，我们提供了7张实例图像。你可以尝试类似的操作。在此单元格之后，你的目录结构可能如下所示：
- en: '![](../Images/1c4886b2f339915d81fa10b0637e0f3b.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1c4886b2f339915d81fa10b0637e0f3b.png)'
- en: Directory as seen from the side panel of Colab Notebook containing the training
    images
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 从Colab笔记本侧边面板中查看的目录，其中包含训练图像
- en: Now you’re ready to start the training. The following table lists the best flags
    based on computational requirements. The limiting factor is usually the memory
    available on the GPU.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你准备好开始训练了。以下表格列出了根据计算要求的最佳标志。限制因素通常是GPU上的内存。
- en: '![](../Images/a3541f181cb248ef0c76432b87dc34ec.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a3541f181cb248ef0c76432b87dc34ec.png)'
- en: Recommended flags for training
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 训练的推荐标志
- en: 'Training is to execute the `diffusers`-provided training script. Here are some
    parameters you may consider:'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 训练是执行`diffusers`提供的训练脚本。这里是一些你可能考虑的参数：
- en: '`--use_8bit_adam` enables full precision and quantization support'
  id: totrans-73
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--use_8bit_adam` 启用完全精度和量化支持'
- en: '`--train_text_encoder` enables text-encoder fine-tuning'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--train_text_encoder` 启用文本编码器微调'
- en: '`--with_prior_preservation` enables prior preservation loss'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--with_prior_preservation` 启用先验保持损失'
- en: '`--prior_loss_weight` controls the strength of prior preservation'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--prior_loss_weight` 控制先验保持的强度'
- en: 'Creating and running the following as a cell on Colab notebook will do the
    training:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在Colab笔记本上创建并运行以下单元格将完成训练：
- en: '[PRE5]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Patiently wait for this script to complete. Then you can run the following
    to convert it into a format we can use:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 耐心等待此脚本完成。然后你可以运行以下命令，将其转换为我们可以使用的格式：
- en: '[PRE6]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: The above will create the file `model.ckpt` under the directory as assigned
    to `WEIGHTS_DIR` (i.e., the latest checkpoint directory). This output file will
    be compatible with the Stable Diffusion Web UI by Automatic1111\. If `fp16` is
    assigned to `True`, it takes only half the space (i.e., 2GB), which is usually
    recommended.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 上述操作将在指定给`WEIGHTS_DIR`（即最新检查点目录）的目录下创建文件`model.ckpt`。该输出文件将与Automatic1111提供的Stable
    Diffusion Web UI兼容。如果`fp16`设置为`True`，则只占用一半的空间（即2GB），通常推荐使用。
- en: Using Your Trained Model
  id: totrans-82
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用你训练好的模型
- en: 'The created model is just like any other Stable Diffusion model weight file.
    You can load it into the WebUI. You can also load it with your Python code, like
    the cell as follows:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 创建的模型就像任何其他Stable Diffusion模型权重文件一样。你可以将其加载到WebUI中。你也可以使用Python代码加载它，如下单元格所示：
- en: '[PRE7]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Let’s try with four samples:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试四个样本：
- en: '[PRE8]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This is what the generated images look like:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是生成图像的样子：
- en: '![](../Images/84f5ac64212dbe75595e50f22b7b6700.png)![](../Images/853a1e2140c4f69eb9fd3ed6e3c42313.png)![](../Images/549b8899412a17161470a4c37d8ffc76.png)![](../Images/003094259564e256edc06f67c50ca8c2.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/84f5ac64212dbe75595e50f22b7b6700.png)![](../Images/853a1e2140c4f69eb9fd3ed6e3c42313.png)![](../Images/549b8899412a17161470a4c37d8ffc76.png)![](../Images/003094259564e256edc06f67c50ca8c2.png)'
- en: That’s it!
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 就这样！
- en: Tips to Use DreamBooth Effectively
  id: totrans-90
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 有效使用DreamBooth的提示
- en: If you’re fine-tuning the model for faces, prior preservation is crucial. Faces
    require harder training as DreamBooth needs more training steps and a lower learning
    rate for fine-tuning on faces.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您正在为面部微调模型，先前的保留至关重要。面部需要更严格的训练，因为梦幻亭在面部微调时需要更多的训练步骤和更低的学习率。
- en: A scheduler like DDIM (preferred), PNDM, and LMS Discrete can help mitigate
    model overfitting. You should try using schedulers when the outputs seem noisy
    or lack sharpness or details.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 像DDIM（首选）、PNDM和LMS Discrete这样的调度器可以帮助减轻模型的过拟合。当输出看起来嘈杂或缺乏锐度或细节时，您应该尝试使用调度器。
- en: In addition to U-Net training, training the text encoder can significantly enhance
    output quality (especially on faces), but it will cost memory; at least a 24GB
    GPU may be required. You can also optimize using the above-discussed GPU-efficient
    techniques.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 除了U-Net训练外，训练文本编码器可以显著提升输出质量（特别是在面部），但会消耗内存；至少需要一个24GB的GPU。您也可以使用上述讨论的高效GPU技术进行优化。
- en: Further Readings
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: This section provides more resources on the topic if you want to go deeper.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想深入了解此主题，本节提供了更多资源。
- en: 'LAION-5B dataset: [https://laion.ai/blog/laion-5b/](https://laion.ai/blog/laion-5b/)'
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LAION-5B 数据集：[https://laion.ai/blog/laion-5b/](https://laion.ai/blog/laion-5b/)
- en: '[Countering Language Drift via Visual Grounding](https://arxiv.org/abs/1909.04499),
    by Lee et al (2019)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[通过视觉基础对抗语言漂移](https://arxiv.org/abs/1909.04499)，Lee等人（2019）'
- en: '[DreamBooth](https://dreambooth.github.io/)'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[梦幻亭](https://dreambooth.github.io/)'
- en: '[DreamBooth training example from diffusers](https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/README.md)'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[来自扩散器的梦幻亭训练示例](https://github.com/huggingface/diffusers/blob/main/examples/dreambooth/README.md)'
- en: Summary
  id: totrans-100
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: Now that you’ve explored DreamBooth, it’s a powerful tool for refining Stable
    Diffusion models for personalized content. However, it faces challenges like overfitting
    due to fewer images and language drift. To make the most of DreamBooth, you have
    also seen a few optimization methods. Remember, success with DreamBooth depends
    on careful dataset preparation and precise parameter tuning. For deeper insights,
    refer to the detailed DreamBooth training guide.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 现在您已经探索了梦幻亭，它是用于个性化内容的稳定扩散模型的强大工具。然而，由于图像较少和语言漂移，它面临着过拟合等挑战。为了充分利用梦幻亭，您还看到了一些优化方法。请记住，成功使用梦幻亭取决于仔细的数据集准备和精确的参数调整。有关更深入的见解，请参考详细的梦幻亭训练指南。
