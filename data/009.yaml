- en: Prompt Engineering for Effective Interaction with ChatGPT
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 提示工程以实现与ChatGPT的有效互动
- en: 原文：[https://machinelearningmastery.com/prompt-engineering-for-effective-interaction-with-chatgpt/](https://machinelearningmastery.com/prompt-engineering-for-effective-interaction-with-chatgpt/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://machinelearningmastery.com/prompt-engineering-for-effective-interaction-with-chatgpt/](https://machinelearningmastery.com/prompt-engineering-for-effective-interaction-with-chatgpt/)
- en: With the explosion in popularity of generative AI in general and ChatGPT in
    particular, prompting has become an increasingly important skill for those in
    the world of AI. Crafting a prompt, the mechanism of interacting with a large
    language model (LLM) such as ChatGPT, is not the simple syntactic undertaking
    it would first appear to be. After the novelty of the first interchanges with
    ChatGPT, it became clear that practice and consideration would be needed for prompt
    mastery. As a result, developing processes to create the most useful prompts possible
    – known as prompt engineering – has become a coveted expertise in LLM circles
    and beyond.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 随着生成式AI普及的爆炸性增长，尤其是ChatGPT，提示工程已成为AI领域中越来越重要的技能。构建提示，即与大型语言模型（LLM）如ChatGPT互动的机制，并不像最初看起来那么简单。经过与ChatGPT的首次互动后，很明显需要实践和考虑来掌握提示。因此，开发创建最有用提示的过程——即提示工程——已成为LLM圈子及其他领域的**抢手**专业。
- en: In this post, you will learn about prompt engineering. In particular,
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，你将了解提示工程。具体而言，
- en: How to provide information in the prompt for the greatest impact on the responses
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在提示中提供信息，以最大程度地影响回应
- en: What are personas, positive and negative prompts, zero-shot prompts, and so
    on
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是角色、正向和负向提示、零-shot提示等
- en: How to use prompts iteratively to leverage the conversational nature of ChatGPT
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何迭代使用提示以利用ChatGPT的对话性质
- en: '**Get started and apply ChatGPT** with my book [Maximizing Productivity with
    ChatGPT](https://machinelearningmastery.com/productivity-with-chatgpt/). It provides
    **real-world use cases** and **prompt examples** designed to get you using ChatGPT
    quickly.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**开始使用ChatGPT**，请参考我的书籍[《Maximizing Productivity with ChatGPT》](https://machinelearningmastery.com/productivity-with-chatgpt/)。它提供了**真实世界的使用案例**和**提示示例**，旨在帮助你快速使用ChatGPT。'
- en: Let’s get started.![](../Images/0c0a7871dfbd68bedb3d8f8947355ded.png)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！[](../Images/0c0a7871dfbd68bedb3d8f8947355ded.png)
- en: Prompt Engineering for Effective Interaction with ChatGPT
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程以实现与ChatGPT的有效互动
- en: Picture generated by Adrian Tam using Stable Diffusion. Some rights reserved.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由Adrian Tam使用Stable Diffusion生成。保留部分权利。
- en: Overview
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: This post is divided into three parts; they are
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本文分为三个部分，它们是
- en: Principles of Prompting
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提示原则
- en: Basic Prompt Engineering
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基本提示工程
- en: Advanced Prompt Engineering Strategies
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 高级提示工程策略
- en: Collaborative Power Tips
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 协作性技巧
- en: Principles of Prompting
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提示原则
- en: Prompt engineering is the most crucial aspect of utilizing LLMs effectively
    and is a powerful tool for customizing the interactions with ChatGPT. It involves
    crafting clear and specific instructions or queries to elicit the desired responses
    from the language model. By carefully constructing prompts, users can guide ChatGPT’s
    output toward their intended goals and ensure more accurate and useful responses.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 提示工程是有效利用LLM的**关键方面**，也是定制与ChatGPT互动的**强大工具**。它涉及到制定清晰而具体的指示或查询，以引出语言模型所需的回应。通过精心构建提示，用户可以引导ChatGPT的输出朝向他们的**最终目标**，并确保回应更准确、更有用。
- en: There are several foundational techniques to remember in the process of prompt
    optimization for ChatGPT.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在优化ChatGPT提示的过程中，有几个基础技巧需要记住。
- en: First, providing explicit instructions at the beginning of the prompt helps
    set the context and define the task for the model. Specifying the format or type
    of the expected answer is also beneficial. Additionally, you can enhance the interaction
    by incorporating system messages or role-playing techniques in the prompt.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，在提示的开始提供明确的指示有助于设定上下文并定义模型的任务。指定预期答案的格式或类型也很有益。此外，通过在提示中加入系统消息或角色扮演技巧，可以增强互动。
- en: 'Below is an example prompt with the above techniques:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个包含上述技巧的示例提示：
- en: I would like you to generate 10 quick-prep dinner meal ideas for recipe blogs,
    with each idea including a title and a one sentence description of the meal. These
    blogs will be written for an audience of parents looking for easy-to-prepare family
    meals. Output the results as a bulleted list.
  id: totrans-22
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我希望你为食谱博客生成 10 个快速准备的晚餐创意，每个创意包括一个标题和一段关于餐点的描述。这些博客将针对寻找易于准备的家庭餐点的父母群体。将结果以项目符号列表的形式输出。
- en: 'Compare that prompt with the following:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 将这个提示与以下内容进行比较：
- en: Write 10 recipe blogs.
  id: totrans-24
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 写 10 篇食谱博客。
- en: Intuitively, the former will garner more useful results.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 直观上，前者将获得更有用的结果。
- en: Remember that you can improve the quality and relevance of the model’s responses
    by iteratively refining and experiment with prompts, creating more productive
    conversations. Don’t be afraid to test out potential prompts on ChatGPT directly.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，你可以通过不断改进和实验提示来提高模型回答的质量和相关性，从而创造出更有成效的对话。不要害怕直接在 ChatGPT 上测试潜在的提示。
- en: Basic Prompt Engineering
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 基础提示工程
- en: Now that you know what a basic prompt should look like, let’s dive into some
    basic prompt engineering considerations in more detail.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 现在你知道了基本提示应该是什么样的，我们来详细讨论一些基本的提示工程考虑因素。
- en: Prompt Wording
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示措辞
- en: A prompt’s wording is paramount, as it guides the LLM in generating the desired
    output. It’s important to phrase the question or statement in a way that ChatGPT
    understands and can respond to accurately.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 提示的措辞至关重要，因为它指导 LLM 生成所需的输出。将问题或陈述表述成 ChatGPT 能够理解并准确回应的方式非常重要。
- en: For example, if a user is not an expert in an area and does not know the right
    term to phrase a question, ChatGPT may experience limitations on the answers they
    provide. It is similar to searching on the web without knowing the correct keyword.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果用户在某个领域不是专家，并且不知道如何用正确的术语提出问题，ChatGPT 可能会在回答时遇到限制。这就类似于在不知道正确关键词的情况下在网上搜索。
- en: While it may be evident that additional information could be used to create
    better prompts, it may be less obvious that being overly verbose in general is
    not necessarily an optimal strategy. It’s best to think of prompt wording not
    as a separate technique but as a connecting thread through all other techniques.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然使用额外的信息来创建更好的提示可能很明显，但一般来说，过于冗长并不一定是最佳策略可能不那么明显。最好将提示的措辞视为不是一种独立的技巧，而是贯穿所有其他技巧的连接线。
- en: Succinctness
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 简洁性
- en: Succinctness in a prompt is important for clarity and precision. A well-crafted
    prompt should be concise and to the point, providing enough information for ChatGPT
    to understand the user’s intent without being overly verbose. However, ensuring
    the prompt is not too brief is vital, which may lead to ambiguity or misunderstanding.
    This balance between not enough and too much can be tricky to strike. Practice
    is probably the best way to master this skill.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 提示的简洁性对清晰度和准确性非常重要。一个精心制作的提示应当简明扼要，提供足够的信息以便 ChatGPT 理解用户的意图，同时避免过于冗长。然而，确保提示不过于简短也是至关重要的，因为这可能会导致歧义或误解。在不够和过多之间找到平衡可能会很棘手。练习可能是掌握这一技能的最佳方法。
- en: Wording and succinctness in the prompt are important because it is for specificity.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 提示中的措辞和简洁性非常重要，因为它关系到具体性。
- en: Roles and Goals
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 角色与目标
- en: 'In prompt engineering, roles are personas assigned for the LLM and the intended
    audience. For example, if one is interested in having ChatGPT write an outline
    for a blog post on machine learning classification metrics, explicitly stating
    that the LLM is to act as an expert machine learning practitioner and that its
    intended audience is data science newcomers would certainly help provide a fruitful
    response. Whether this should be stated in a conversational language (“*You are
    to act as a real estate agent with 10 years experience in the Phoenix area*“)
    or in a more formal manner (“*Author: expert Phoenix real estate agent; Audience:
    inexperienced home buyers*“) can be experimented within a given scenario.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在提示工程中，角色是分配给 LLM 和预期受众的人物角色。例如，如果希望 ChatGPT 为一篇关于机器学习分类指标的博客文章写一个大纲，明确指出 LLM
    需作为机器学习专家，并且目标受众是数据科学新手，肯定会帮助提供有价值的回答。无论是以对话语言（“*你要充当一位在凤凰城有 10 年经验的房地产经纪人*”）还是以更正式的方式（“*作者：专家级凤凰城房地产经纪人；受众：经验不足的购房者*”）表述，这都可以在特定场景中进行实验。
- en: Goals are intimately connected to roles. Explicitly stating the goal of a prompt-guided
    interaction is not only a good idea but also necessary. Without it, how would
    ChatGPT have any inkling of what output to generate?
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 目标与角色紧密相关。明确说明提示引导互动的目标不仅是个好主意，而且是必要的。没有目标，ChatGPT如何知道生成什么输出？
- en: 'Below is a competent prompt that has considered both roles and goals:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一个考虑了角色和目标的有效提示：
- en: You are to act as a real estate agent with 10 years experience in the Phoenix
    area. Your goal is to produce a one paragraph summary of each of the top 5 family
    neighborhoods in the Phoenix metropolitan area. The intended audience is inexperienced
    home buyers.
  id: totrans-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你将充当一名在凤凰城地区有10年经验的房地产经纪人。你的目标是为凤凰城大都市区的前五个家庭社区各提供一个段落的总结。目标受众是缺乏经验的购房者。
- en: Along with the explicitly stated roles and goals, note the relative specificity
    of the example prompt above.
  id: totrans-41
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 除了明确列出的角色和目标外，还请注意上述示例提示的相对具体性。
- en: Positive and Negative Prompting
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 积极与消极提示
- en: Positive and negative prompting is another set of framing methods to guide the
    model’s output. Positive prompts (“*do this*“) encourage the model to include
    specific types of output and generate certain types of responses. Negative prompts
    (“*don’t do this*“), on the other hand, discourage the model from including specific
    types of output and generating certain types of responses. Using positive and
    negative prompts can greatly influence the direction and quality of the model’s
    output.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 积极和消极提示是另一组引导模型输出的框架方法。积极提示（“*做这个*”）鼓励模型包含特定类型的输出并生成某些类型的响应。消极提示（“*不要做这个*”）则阻止模型包含特定类型的输出和生成某些类型的响应。使用积极和消极提示可以大大影响模型输出的方向和质量。
- en: 'Consider the following example prompt:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 请考虑以下示例提示：
- en: You are to act as a real estate agent with 10 years experience in the Phoenix
    area. Your goal is to produce a one paragraph summary of each of the top 5 family
    neighborhoods in the Phoenix metropolitan area. The intended audience is inexperienced
    home buyers.
  id: totrans-45
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你将充当一名在凤凰城地区有10年经验的房地产经纪人。你的目标是为凤凰城大都市区的前五个家庭社区各提供一个段落的总结。目标受众是缺乏经验的购房者。
- en: 'The framing of the above prompt is positive in nature, providing guidance on
    what ChatGPT should generate. Let’s add some wording to discourage certain output,
    be it in content or format. An example of negative prompting geared toward content
    guidance could be the addition of the following to our above example:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 上述提示的框架性质是积极的，提供了有关ChatGPT应该生成什么的指导。让我们添加一些措辞以阻止某些输出，无论是内容还是格式。例如，针对内容指导的消极提示可以是将以下内容添加到上述示例中：
- en: Do not include any neighborhoods within 5 miles of downtown or adjacent to the
    airport.
  id: totrans-47
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 不要包括位于市中心5英里范围内或紧邻机场的任何社区。
- en: This additional constraint should be helpful in ChatGPT’s understanding of what
    output it should generate.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 这个额外的约束应有助于ChatGPT理解应该生成什么样的输出。
- en: Advanced Prompt Engineering Strategies
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 高级提示工程策略
- en: Let’s look at a selection of more advanced prompt engineering strategies. While
    the previous section provided some general guidelines for interactions with LLMs,
    you can turn to a variety of contemporary strategies that are commonplace in the
    prompt engineer’s toolkit for the ability to interact with ChatGPT in a more complex
    manner.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看看一些更高级的提示工程策略。虽然前一节提供了一些与LLM交互的通用指南，但你可以参考各种现代策略，这些策略在提示工程师的工具包中很常见，能够以更复杂的方式与ChatGPT进行互动。
- en: Input/Output Prompting
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 输入/输出提示
- en: The input/output prompting strategy involves defining the input that the user
    provides to the LLM and the output that the LLM is to generate in response. This
    strategy is fundamental to prompt engineering as it directly influences the quality
    and relevance of the ChatGPT’s response.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 输入/输出提示策略涉及定义用户提供给LLM的输入以及LLM应生成的输出。这一策略是提示工程的基础，因为它直接影响ChatGPT响应的质量和相关性。
- en: For instance, the user might provide an input prompt asking ChatGPT to generate
    a Python script for a specific task, and the desired output would be the generated
    script.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，用户可能会提供一个输入提示，请求ChatGPT生成一个特定任务的Python脚本，期望的输出就是生成的脚本。
- en: 'Below is an example of the most basic strategy: provide a single input and
    desire a single output.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是最基本策略的一个示例：提供一个输入并期望得到一个输出。
- en: 'Generate a Python script that takes a single mandatory command line argument
    ([project]) and performs the following tasks:'
  id: totrans-55
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 生成一个Python脚本，该脚本接受一个必需的命令行参数（[project]），并执行以下任务：
- en: – creates a new folder named [project]
  id: totrans-56
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: – 创建一个名为[project]的新文件夹
- en: – creates a file within the new folder named [project].py
  id: totrans-57
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: – 在新文件夹中创建一个名为[project].py的文件
- en: – writes a simple Python script file header to the [project].py file
  id: totrans-58
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: – 向[project].py文件中写入一个简单的Python脚本文件头
- en: Zero-Shot Prompting
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 零-Shot提示
- en: 'The zero-shot strategy involves the LLM generating an answer without any examples
    or context. This strategy can be useful when the user wants a quick answer without
    providing additional detail, or when the topic is so general that examples would
    artificially limit the response. For example:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 零-shot策略涉及LLM在没有任何示例或背景的情况下生成答案。当用户希望快速得到答案而不提供额外细节，或者当话题过于广泛以至于示例会人为限制回应时，这种策略可能会很有用。例如：
- en: Generate 10 possible names for my new dog.
  id: totrans-61
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 为我的新狗生成10个可能的名字。
- en: One-Shot Prompting
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 单-Shot提示
- en: 'The one-shot strategy involves the LLM generating an answer based on a single
    example or piece of context provided by the user. This strategy can guide ChatGPT’s
    response and ensure it aligns with the user’s intent. The idea here would be that
    one example would provide more guidance to the model than none. For example:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 单-shot策略涉及LLM根据用户提供的单个示例或背景生成答案。这种策略可以指导ChatGPT的回应，并确保其与用户的意图一致。这里的想法是，一个示例将为模型提供比没有示例更多的指导。例如：
- en: Generate 10 possible names for my new dog.
  id: totrans-64
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 为我的新狗生成10个可能的名字。
- en: A dog name that I like is Banana.
  id: totrans-65
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我喜欢的一个狗名字是香蕉。
- en: Few-Shot Prompting
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Few-Shot提示
- en: 'The few-shot strategy involves the LLM generating an answer based on a few
    examples or pieces of context provided by the user. This strategy can guide ChatGPT’s
    response and ensure it aligns with the user’s intent. The idea here would be that
    several examples would provide more guidance to the model than one. For example:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: Few-Shot策略涉及LLM根据用户提供的几个示例或背景生成答案。这种策略可以指导ChatGPT的回应，并确保其与用户的意图一致。这里的想法是，多个示例将为模型提供比一个示例更多的指导。例如：
- en: Generate 10 possible names for my new dog.
  id: totrans-68
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 为我的新狗生成10个可能的名字。
- en: 'Dog names that I like include:'
  id: totrans-69
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我喜欢的狗名字包括：
- en: – Banana
  id: totrans-70
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: – 香蕉
- en: – Kiwi
  id: totrans-71
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: – 猕猴桃
- en: – Pineapple
  id: totrans-72
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: – 菠萝
- en: – Coconut
  id: totrans-73
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: – 椰子
- en: As you can guess, the more examples the prompt included, the closer the generated
    output conforms to what is desired. With zero-shot, there may be no fruit names
    suggested; with one-shot, there may be several; and with few-shot, the suggestions
    may consist entirely of fruit-themed names.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你可以猜到的，提示中包含的示例越多，生成的输出越符合所需结果。使用零-shot，可能不会建议任何水果名称；使用单-shot，可能会有几个；而使用few-shot，建议可能完全是水果主题的名称。
- en: Chain-of-Thought Prompting
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 思维链提示
- en: The chain-of-thought strategy involves providing the LLM with a few examples
    that help to refine the original question and ensure a more accurate and comprehensive
    answer. Chain-of-thought prompts are so-called because they include a few chain-of-thought
    examples in the prompting. It is differentiated from the X-shot prompting techniques
    as chain-of-thought prompts are structured to encourage critical thinking, and
    are designed to help uncover new insights or approaches that ChatGPT may not have
    otherwise considered.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 思维链策略涉及向大型语言模型（LLM）提供一些示例，以帮助细化原始问题，并确保更准确和全面的答案。思维链提示之所以被称为思维链，是因为它们包含了一些思维链示例。与X-shot提示技术不同，思维链提示的结构旨在鼓励批判性思维，并旨在帮助发现ChatGPT可能未曾考虑的新见解或方法。
- en: The technique also encourages the LLM to output its critical reasoning. The
    calling card of chain-of-thought prompting is the phrase “Let’s think step by
    step” which is generally appended to the end of a prompt, which research suggests
    is enough to improve generated results.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 该技术还鼓励LLM输出其批判性推理。思维链提示的标志性短语是“让我们一步一步来思考”，这个短语通常附加在提示的末尾，研究表明，这足以改善生成的结果。
- en: 'Consider the following one-shot prompt example:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 请考虑以下单例提示示例：
- en: 'Q: Joe has 20 eggs. He buys 2 more cartons of eggs. Each carton contains 12
    eggs. How many eggs does Joe have now?'
  id: totrans-79
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 'Q: 乔有20个鸡蛋。他又买了2盒鸡蛋。每盒含12个鸡蛋。乔现在有多少个鸡蛋？'
- en: 'A: The answer is 44.'
  id: totrans-80
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 'A: 答案是44。'
- en: ''
  id: totrans-81
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Q: Farmer John had 93 chickens. If he sold 20 to Farmer Bill and bought twice
    that number more, how many chickens does Farmer John have now?'
  id: totrans-82
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 'Q: 农夫约翰有93只鸡。如果他卖给农夫比尔20只鸡，然后又买了两倍的数量，那么农夫约翰现在有多少只鸡？'
- en: 'And consider ChatGPT’s incorrect output response:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 并考虑 ChatGPT 的错误输出回应：
- en: The answer is 73.
  id: totrans-84
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 答案是73。
- en: 'Now let’s look at the following chain of thought prompt, which is written to
    encourage critical thinking by the LLM:'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们看看以下思维链提示，该提示旨在通过 LLM 鼓励批判性思维：
- en: 'Q: Joe has 20 eggs. He buys 2 more cartons of eggs. Each carton contains 12
    eggs. How many eggs does Joe have now? Let’s think step by step.'
  id: totrans-86
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 问：乔有20个鸡蛋。他买了2盒鸡蛋。每盒包含12个鸡蛋。乔现在有多少个鸡蛋？让我们一步一步地思考。
- en: 'A: Joe started with 20 eggs. 2 cartons of 12 eggs is 24 eggs. 20 + 24 = 44\.
    Therefore, Joe has 44 eggs, and the answer is 44.'
  id: totrans-87
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 答：乔一开始有20个鸡蛋。2盒12个鸡蛋就是24个鸡蛋。20 + 24 = 44。因此，乔现在有44个鸡蛋，答案是44。
- en: ''
  id: totrans-88
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Q: Farmer John had 93 chickens. If he sold 20 to Farmer Bill and bought twice
    that number more, how many chickens does Farmer John have now? Let’s think step
    by step.'
  id: totrans-89
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 问：农夫约翰有93只鸡。如果他将20只鸡卖给了农夫比尔，并且又买了两倍数量的鸡，那么农夫约翰现在有多少只鸡？让我们一步一步来思考。
- en: 'ChatGPT’s response is different this time:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 这次 ChatGPT 的回应有所不同：
- en: 'A: Farmer John sold 20 chickens to Farmer Bill, so he was left with 93 – 20
    = 73 chickens. He then bought twice the number of chickens he sold, so he bought
    2 * 20 = 40 chickens. Adding these newly bought chickens to his remaining stick,
    Farmer John now has 73 + 40 = 113 chickens.'
  id: totrans-91
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 答：农夫约翰把20只鸡卖给了农夫比尔，所以他剩下了93 - 20 = 73只鸡。他然后买了两倍数量的鸡，所以他买了2 * 20 = 40只鸡。将这些新买的鸡加到他剩下的鸡中，农夫约翰现在有73
    + 40 = 113只鸡。
- en: By providing an example of the critical thinking process needed to solve this
    problem, and coaching it to think step by step, ChatGPT could apply the same reasoning
    to our question and come up with the right answer this time.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 通过提供解决这个问题所需的批判性思维过程的示例，并指导它一步一步地思考，ChatGPT 可以将相同的推理应用到我们的问题上，并这次给出正确的答案。
- en: Self-Criticism
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自我批评
- en: The self-criticism strategy involves prompting the LLM to assess its output
    for potential inaccuracies or improvement areas. This strategy can ensure the
    information provided by ChatGPT is as accurate as possible. It can aid users in
    debugging their prompts and determining why they are not getting results that
    meet expectations.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 自我批评策略涉及提示语言模型（LLM）评估其输出以发现潜在的不准确性或改进领域。这种策略可以确保 ChatGPT 提供的信息尽可能准确。它可以帮助用户调试他们的提示，并确定为什么他们没有得到符合预期的结果。
- en: 'An example of such a prompt is as follows:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 这样的提示示例如下：
- en: Please re-read your above response. Do you see any issues or mistakes with your
    response? If so, please identify these issues or mistakes and make the necessary
    edits.
  id: totrans-96
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 请重新阅读你上面的回复。你看到回复中有任何问题或错误吗？如果有，请识别这些问题或错误并进行必要的编辑。
- en: 'This example pertains to coaching ChatGPT to use self-criticism for debugging
    its buggy code:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 这个例子涉及教 ChatGPT 使用自我批评来调试其有问题的代码：
- en: Look at the code you have just generated. Currently it does not run. Are you
    able to see any syntax errors or flow control mistakes that you are able to rectify?
    If so, please identify the section of problematic code and re-generate it.
  id: totrans-98
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 看看你刚刚生成的代码。目前它无法运行。你能看到任何语法错误或流程控制错误吗？如果有，请识别问题代码的部分并重新生成。
- en: Harnessing ChatGPT’s self-healing abilities is a prompt engineering technique
    you must not overlook.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 利用 ChatGPT 的自我修复能力是一种你不能忽视的提示工程技术。
- en: Iterative
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 迭代
- en: The iterative or expansive strategy involves prompting the LLM with follow-up
    prompts based on the output of an initial prompt. This involves iterating on the
    results by asking further questions or making additional requests from each successive
    response.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 迭代或扩展策略涉及根据初始提示的输出用后续提示来提示 LLM。这包括通过询问进一步的问题或从每个连续的回应中提出额外的要求来迭代结果。
- en: 'For example, consider having ChatGPT assist in creating an outline for a book
    you are writing. The first prompt could like this:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，考虑让 ChatGPT 协助创建你正在写的书的提纲。第一个提示可能是这样的：
- en: I am writing a book on time travel theories. I have not settled on a specific
    topic. Generate 5 specific topic suggestions for such a book. For each suggestion,
    provide a title and one paragraph of description of what the book would cover.
    The book will be aimed at casual readers.
  id: totrans-103
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我正在写一本关于时间旅行理论的书。我还没有确定一个具体的主题。请为这本书生成5个具体的主题建议。对于每个建议，请提供一个标题和一段描述书籍内容的段落。这本书将面向普通读者。
- en: 'Now, suppose one of the suggested topics is as follows:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，假设其中一个建议的主题如下：
- en: 'Title: “Temporal Paradoxes: Navigating the Complexities of Time Travel”'
  id: totrans-105
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 标题：“时间悖论：穿越时间旅行的复杂性”
- en: ''
  id: totrans-106
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Description: “Temporal Paradoxes” delves into the mind-bending intricacies
    of time travel paradoxes, exploring the fascinating conundrums they present. This
    book explores various paradoxes such as the Bootstrap Paradox, the Predestination
    Paradox, and the Information Paradox, among others. …'
  id: totrans-107
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 描述：“时间悖论”深入探讨了时间旅行悖论的心智迷宫，探索了它们提出的迷人难题。本书探讨了各种悖论，例如引导悖论、宿命悖论和信息悖论等。…
- en: 'You could then iterate on this using a follow-up prompt:'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用后续提示进行迭代：
- en: 'I will write the book you suggested, “Temporal Paradoxes: Navigating the Complexities
    of Time Travel”. Generate a chapter outline for this book, including sections
    and subsections.'
  id: totrans-109
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我将写你建议的书籍，“时间悖论：穿越时间旅行的复杂性”。为这本书生成章节大纲，包括章节和小节。
- en: 'A possible output excerpt is below:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 下面是一个可能的输出摘录：
- en: Introduction
  id: totrans-111
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 引言
- en: – Defining temporal paradoxes
  id: totrans-112
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: – 定义时间悖论
- en: – Significance of temporal paradoxes in time travel narratives
  id: totrans-113
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: – 时间悖论在时间旅行叙事中的重要性
- en: – Overview of the chapter structure
  id: totrans-114
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: – 章节结构概览
- en: ''
  id: totrans-115
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Chapter 1: The Bootstrap Paradox'
  id: totrans-116
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 第 1 章：引导悖论
- en: 1.1 The essence of the Bootstrap Paradox
  id: totrans-117
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 1.1 引导悖论的本质
- en: – Explaining the concept and its origin
  id: totrans-118
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: – 解释概念及其起源
- en: – Key examples from literature, film, and real-life anecdotes
  id: totrans-119
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: – 文学、电影和真实生活轶事中的关键例子
- en: …
  id: totrans-120
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: …
- en: 'This iteration can then continue. Further prompting could be:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这个迭代可以继续。进一步的提示可能是：
- en: Let’s flesh out the introduction. Generate a two paragraph summary of what each
    of the chapter’s sections will cover. The chapter outline for the introduction
    is below.
  id: totrans-122
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 让我们充实引言部分。生成两段总结，概述每个章节部分将涵盖的内容。引言的章节大纲如下。
- en: – – –
  id: totrans-123
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: – – –
- en: Introduction
  id: totrans-124
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 引言
- en: – Defining temporal paradoxes
  id: totrans-125
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: – 定义时间悖论
- en: – Significance of temporal paradoxes in time travel narratives
  id: totrans-126
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: – 时间悖论在时间旅行叙事中的重要性
- en: – Overview of the chapter structure
  id: totrans-127
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: – 章节结构概览
- en: 'You could see how further iteration could continue in this example. A similar
    iteration could be used to have ChatGPT generate code: starting with an overview,
    iterating on the overview to generate modules, generating on the modules to generate
    functions, and finally generate the code within functions. Just as breaking big
    problems into smaller, more manageable problems is generally a prescription for
    success with humans, ChatGPT excels at completing larger tasks in more approachable
    chunks.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到进一步迭代如何在这个例子中继续。类似的迭代可以用来让 ChatGPT 生成代码：从概述开始，迭代概述以生成模块，生成模块以生成函数，最后在函数内生成代码。就像将大问题拆分成更小、更易处理的问题通常是成功的处方一样，ChatGPT
    擅长在更易处理的块中完成较大的任务。
- en: Collaborative Power Tips
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 协作力量提示
- en: The best way to look at ChatGPT is as a junior assistant, be that a research
    assistant, coding assistant, problem-solving assistant, or whatever assistant
    you require. Recognizing and fostering this collaborative atmosphere can lead
    to further success. Here are a few quick tips for promoting this collaboration.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 看待 ChatGPT 的最佳方式是作为一个初级助手，无论是研究助手、编码助手、解决问题助手，还是你需要的任何助手。认识到并促进这种协作氛围可以带来更大的成功。以下是一些促进这种协作的快速提示。
- en: Prompting for Prompts
  id: totrans-131
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 提示生成提示
- en: 'One way to improve your prompt crafting is to get ChatGPT involved. A prompt
    like this could lead to beneficial results:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 改进提示编写的一种方法是让 ChatGPT 参与进来。这样的提示可能会产生有益的结果：
- en: What prompt could I use right now to further help you in this task?
  id: totrans-133
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 目前我可以使用什么提示来进一步帮助你完成这项任务？
- en: ChatGPT should then generate suggestions for useful prompts that you could use
    on it to strengthen its further responses.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: ChatGPT 然后应生成有用的提示建议，以加强其进一步的响应。
- en: Model-Guided Prompting
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型引导提示
- en: Model-guided prompting involves instructing the LLM to prompt you for the information
    needed to complete a requested task. This is similar to telling someone, “ask
    me what you need to know.”
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 模型引导提示涉及指导 LLM 提示你所需的信息，以完成请求的任务。这类似于告诉某人：“问我你需要知道什么。”
- en: I would like you to write a Python program to manage my client information,
    which is stored in a Google Sheet. Please ask me whatever questions you need answers
    to in order to undertake this assignment.
  id: totrans-137
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 我希望你编写一个 Python 程序来管理存储在 Google 表格中的客户信息。请问我需要回答哪些问题以完成这项任务？
- en: Leaving it to ChatGPT to decide what information it needs to perform a task
    can benefit, as it takes out some guesswork and discourages hallucination. Of
    course, a poorly crafted prompt for model-guided prompting could leave you fielding
    a number of unrelated questions from ChatGPT, so the initial prompt still needs
    to be thoughtfully written.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 让ChatGPT决定执行任务所需的信息可能会带来好处，因为这减少了一些猜测，并且能避免幻觉。当然，如果模型指导提示的提示编写得不好，可能会让你接到ChatGPT提出的许多不相关的问题，因此初始提示仍需要经过深思熟虑的编写。
- en: Conclusion
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: Once you become comfortable with the prompt engineering strategies laid out
    here, you can search out other more complex, high-performance approaches. Some
    of these strategies include tree of thoughts, reflexion, and self-consistency,
    among others. Additional strategies are being developed regularly; no doubt that
    between the time this was written and when you are reading it, there have been
    some interesting developments on this front.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦你对这里提出的提示工程策略感到舒适，你可以探索其他更复杂、更高效的方法。其中一些策略包括思想树、反思和自我一致性等。额外的策略也在不断发展；毫无疑问，从这篇文章写作时到你阅读时，这方面已经有了一些有趣的发展。
- en: Remember, the point of prompt engineering is to convey your intentions and desires
    to ChatGPT in a way that can be clearly and unambiguously understood by the LLM,
    so that it can act upon the request in such a way that produces the desired output
    as closely as possible. If you keep this in mind, move forward with the presented
    strategies, and hone your prompt engineering skills through regular practice,
    you will find ChatGPT to be a genuinely useful junior assistant, willing and able
    to help whenever you need it.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 记住，提示工程的关键在于将你的意图和愿望以一种可以被LLM清晰且明确理解的方式传达给ChatGPT，以便它能够根据请求采取行动，尽可能地产生所需的输出。如果你牢记这一点，按照所提供的策略前进，并通过定期实践磨练你的提示工程技能，你会发现ChatGPT确实是一个有用的初级助手，随时愿意并能够在你需要时提供帮助。
- en: Just so long as you ask it properly.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 只要你正确地提出问题即可。
