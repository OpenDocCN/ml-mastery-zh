# 逐步介绍提示工程

> 原文：[`machinelearningmastery.com/a-gentle-introduction-to-prompt-engineering/`](https://machinelearningmastery.com/a-gentle-introduction-to-prompt-engineering/)

ChatGPT 是 OpenAI 提供的服务，是一个对话型的大型语言模型。它非常普及，并且被发现非常有用。在幕后，它是一个大型语言模型。不同于其他从你提供的引导句生成连续文本的 LLM，ChatGPT 允许你提问或提供指令，模型将以对话形式回应。为了使 ChatGPT 正确回应，你必须与模型互动。这种技术称为提示工程。

在这篇文章中，你将了解 ChatGPT 作为 LLM 的特点，并学习提示工程。特别是，

+   ChatGPT 中 LLM 的输入上下文是什么

+   ChatGPT 如何与输入互动

+   如何提供合适的提示以获得所需的结果

**开始使用 ChatGPT**，可以参考我的书籍 [《利用 ChatGPT 提高生产力》](https://machinelearningmastery.com/productivity-with-chatgpt/)。这本书提供了**实际应用案例**和**提示示例**，旨在帮助您迅速上手 ChatGPT。

让我们开始吧。 ![](img/2e078534971f7abc10aac092ee5fb660.png)

逐步介绍提示工程

图片由作者使用 Stable Diffusion 生成。保留部分权利。

## 概述

本文分为三部分：

+   理解 ChatGPT

+   上下文工程

+   提示工程建议

## 理解 ChatGPT

ChatGPT 是一个对话型的大型语言模型。语言模型可以根据引导文本生成词汇。对话型的大型语言模型是一种自然变体。如果你读过戏剧，比如莎士比亚所写的例子，你会注意到对话是多个人之间的对话：

> Abr. 你对我们挑衅吗，先生？
> 
> Sam. 我咬自己的拇指，先生。
> 
> Abr. 你对我们挑衅吗，先生？
> 
> Sam. 如果我说——是吗？法律在我们这边吗？
> 
> Gre. 不。
> 
> Sam. 不，先生，我并没有对您挑衅；我只是咬自己的拇指，先生。

如果你将对话的前四行输入到语言模型中，可以合理地期待它会生成第五行。由于模型从大量文本中学习，剧本的格式只是它理解的一种风格。由于模型能够理解上下文，它的回答应该与前文自然衔接，就像聊天中的恰当回应一样。

## 上下文工程

当使用 LLM 生成文本时，上下文在确定输出中起着至关重要的作用。对于 ChatGPT，上下文来自于之前的对话。为了确保 ChatGPT 以期望的方式回应，必须仔细构建输入以提供必要的提示。

虽然 ChatGPT 是一个强大的语言模型，但它确实有其局限性。尽管它从训练数据中获得了一些基本的“常识”，但可能无法展示详细的逻辑推理。例如，如果你问 ChatGPT“提供有关机器学习的信息”，它可能会回答很长，但不一定质量很高。不过，如果你问，“告诉我使用机器学习解决图像分类问题的优缺点”，你更有可能获得优质的结果，因为：

+   你给出了一个具体的范围，即图像分类问题。

+   你请求了特定格式的回答，即优缺点。

类似的情况是你问一个复杂的问题，例如以下数学应用题：

> 为了准备复活节，史密斯太太去了商店，买了 10 只每只 5 美元的玩具兔子。巧克力蛋比兔子便宜 1 美元，史密斯太太买了 15 个。史密斯太太花了多少钱？

更新版的 ChatGPT 可能能做对，但这类问题如果大型语言模型立即尝试给出答案，容易出错。原因是当你尝试生成简短答案时，上下文需要更多线索以保持逻辑正确。然而，当 LLM 尝试逐步展示逻辑时，很容易算对。因此，有人建议你不要问 ChatGPT“史密斯太太花了多少钱”，而是“详细解释史密斯太太花了多少钱的步骤”。这些是强迫 ChatGPT 进行逻辑推理的线索。例如，以下是你可能观察到的回答：

> 要计算史密斯太太花了多少钱，我们需要分别确定玩具兔子和巧克力蛋的费用，然后将它们加在一起。
> 
> 史密斯太太以每只 5 美元的价格买了 10 只玩具兔子，所以兔子的总费用是 10 * 5 美元 = 50 美元。
> 
> 每个巧克力蛋比玩具兔子便宜 1 美元，因此每个巧克力蛋的费用是 5 美元 - 1 美元 = 4 美元。
> 
> 史密斯太太买了 15 个巧克力蛋，所以巧克力蛋的总费用是 15 * 4 美元 = 60 美元。
> 
> 最后，为了找出史密斯太太花费的总金额，我们将兔子的费用和巧克力蛋的费用相加：50 美元 + 60 美元 = 110 美元。
> 
> 因此，史密斯太太总共花了 110 美元。

你可以看到 LLM 如何给出正确的答案。LLM 不能进行心算，逻辑能力有限（因为它是通过文本训练的，它学习的内容只限于单句话所表达的）。如果有更复杂的逻辑，你必须确保模型逐步进行。这称为**思维链**。

## 提示工程的建议

以下是一些构建上下文的想法，以使 ChatGPT 或其他 LLM 产生有用的输出：

+   与其让模型随意发挥，不如通过提供详细的什么、在哪里、何时、为什么、谁以及如何来设置提示中的场景和范围。

+   在提示中分配一个角色，例如，“作为一名计算机科学教授，解释什么是机器学习”，而不是仅仅“解释什么是机器学习”，可以使回答更具学术性。

+   你可以通过请求“向 5 岁孩子解释”、“用类比解释”、“做出令人信服的陈述”或“用 3 到 5 点说明”来控制输出风格。

+   为了鼓励模型以思维链的方式回应，请在请求的结尾加上“分步骤解决此问题”。

+   你可以通过说“参考以下信息”，然后提供你希望模型处理的材料，来向模型提供额外的信息。

+   因为之前的对话构建了上下文，所以以“忽略所有之前的指令”开头的提示可以使模型从头开始。

+   使提示直接明了是至关重要的，因为这样推断出的上下文可以更准确地反映你的意图。

## 总结

在这篇文章中，你了解了提示如何驱动大型语言模型，特别是 ChatGPT 的输出。具体来说，你学到了。

+   提示如何设置上下文，以便模型可以在该上下文内生成输出。

+   大型语言模型（LLMs）存在局限；你需要在提示中提供正确的指导，以生成准确的输出。

+   提供具体、详细的提示可以帮助获得正确的输出。
