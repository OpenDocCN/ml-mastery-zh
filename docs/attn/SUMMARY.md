+   [注意力机制](README.md)
+   [对注意力研究的总体概述](a-birds-eye-view-of-research-on-attention.md)
+   [BERT 简介](a-brief-introduction-to-bert.md)
+   [变压器模型位置编码的温和介绍，第一部分](a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1.md)
+   [[注意力机制架构之旅](https://machinelearningmastery.com/a-tour-of-attention-based-architectures/)](a-tour-of-attention-based-architectures.md)
+   [向 Keras 中的循环神经网络添加自定义注意力层](adding-a-custom-attention-layer-to-recurrent-neural-network-in-keras.md)
+   [循环神经网络及其数学基础介绍](an-introduction-to-recurrent-neural-networks-and-the-math-that-powers-them.md)
+   [变换器模型与注意力机制速成课程。12 天内构建一个神经机器翻译器](building-transformer-models-with-attention-crash-course-build-a-neural-machine-translator-in-12-days.md)
+   [如何在 TensorFlow 和 Keras 中从头实现多头注意力机制](how-to-implement-multi-head-attention-from-scratch-in-tensorflow-and-keras.md)
+   [如何在 TensorFlow 和 Keras 中从零开始实现缩放点积注意力](how-to-implement-scaled-dot-product-attention-from-scratch-in-tensorflow-and-keras.md)
+   [在 TensorFlow 和 Keras 中从零开始实现 Transformer 解码器](implementing-the-transformer-decoder-from-scratch-in-tensorflow-and-keras.md)
+   [在 TensorFlow 和 Keras 中从头开始实现 Transformer 编码器](implementing-the-transformer-encoder-from-scratch-in-tensorflow-and-keras.md)
+   [推断 Transformer 模型](inferencing-the-transformer-model.md)
+   [结合 Transformer 编码器和解码器及掩码](joining-the-transformer-encoder-and-decoder-and-masking.md)
+   [绘制 Transformer 模型的训练和验证损失曲线](plotting-the-training-and-validation-loss-curves-for-the-transformer-model.md)
+   [从头开始了解注意力机制](the-attention-mechanism-from-scratch.md)
+   [Bahdanau 注意力机制](the-bahdanau-attention-mechanism.md)
+   [Luong 注意力机制](the-luong-attention-mechanism.md)
+   [Transformer 注意力机制](the-transformer-attention-mechanism.md)
+   [Transformer 模型](the-transformer-model.md)
+   [Keras 中的变压器位置编码层，第二部分](the-transformer-positional-encoding-layer-in-keras-part-2.md)
+   [视觉 Transformer 模型](the-vision-transformer-model.md)
+   [训练 Transformer 模型](training-the-transformer-model.md)
+   [在 Keras 中理解简单的递归神经网络](understanding-simple-recurrent-neural-networks-in-keras.md)
+   [使用 ChatGPT 作为你的编程助手](using-chatgpt-as-your-programming-assistant.md)
+   [使用 ChatGPT 的自然语言理解能力](using-the-natural-language-understanding-capability-of-chatgpt.md)
+   [什么是注意力？](what-is-attention.md)