- en: Deep Learning with PyTorch (9-Day Mini-Course)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用PyTorch进行深度学习（9天迷你课程）
- en: 原文：[https://machinelearningmastery.com/deep-learning-with-pytorch-9-day-mini-course/](https://machinelearningmastery.com/deep-learning-with-pytorch-9-day-mini-course/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://machinelearningmastery.com/deep-learning-with-pytorch-9-day-mini-course/](https://machinelearningmastery.com/deep-learning-with-pytorch-9-day-mini-course/)
- en: Deep learning is a fascinating field of study and the techniques are achieving
    world class results in a range of challenging machine learning problems. It can
    be hard to get started in deep learning.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是一个迷人的研究领域，其技术在一系列具有挑战性的机器学习问题上取得了世界级的成果。开始深入学习深度学习可能有些困难。
- en: '**Which library should you use and which techniques should you focus on?**'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '**你应该使用哪个库，以及应该专注于哪些技术？**'
- en: In this 9-part crash course you will discover applied deep learning in Python
    with the easy to use and powerful PyTorch library. This mini-course is intended
    for practitioners that are already comfortable with programming in Python and
    knows the basic concept of machine learning. Let’s get started.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个由9部分组成的速成课程中，你将会使用易于使用且强大的PyTorch库发现Python中的应用深度学习。这个迷你课程旨在为已经熟悉Python编程且了解基本机器学习概念的实践者提供帮助。让我们开始吧。
- en: This is a long and useful post. You might want to print it out.
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一篇长而实用的文章。你可能想要打印出来。
- en: Let’s get started.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: '![](../Images/9471c948e144cb14d6168d40fad1bcbb.png)'
  id: totrans-7
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9471c948e144cb14d6168d40fad1bcbb.png)'
- en: Deep Learning with PyTorch (9-day Mini-Course)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 使用PyTorch进行深度学习（9天迷你课程）
- en: Photo by [Cosmin Georgian](https://unsplash.com/photos/people-near-pagoda-under-white-and-blue-sky-gd3ysFyrsTQ).
    Some rights reserved.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由[Cosmin Georgian](https://unsplash.com/photos/people-near-pagoda-under-white-and-blue-sky-gd3ysFyrsTQ)拍摄。部分权利保留。
- en: Who Is This Mini-Course For?
  id: totrans-10
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 这个迷你课程适合谁？
- en: Before we get started, let’s make sure you are in the right place. The list
    below provides some general guidelines as to who this course was designed for.
    Don’t panic if you don’t match these points exactly, you might just need to brush
    up in one area or another to keep up.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，让我们确保你在正确的地方。下面的列表提供了一些关于这门课程设计对象的一般指导方针。如果你不完全符合这些点，不要惊慌，你可能只需要在某个领域或另一个领域进行一些复习以跟上节奏。
- en: '**Developers that know how to write a little code**. This means that it is
    not a big deal for you to get things done with Python and know how to setup the
    ecosystem on your workstation (a prerequisite). It does not mean you’re a wizard
    coder, but it does mean you’re not afraid to install packages and write scripts.'
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**知道如何写一点代码的开发者**。这意味着对于你来说，用Python完成任务并在工作站上设置生态系统并不是什么大问题（这是一个先决条件）。这并不意味着你是编程巫师，但确实意味着你不怕安装软件包和编写脚本。'
- en: '**Developers that know a little machine learning**. This means you know about
    the basics of machine learning like cross-validation, some algorithms and the
    bias-variance trade-off. It does not mean that you are a machine learning PhD,
    just that you know the landmarks or know where to look them up.'
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**了解一点机器学习的开发者**。这意味着你了解机器学习的基础知识，如交叉验证、一些算法和偏差-方差权衡。这并不意味着你是机器学习博士，只是说你知道里程碑或知道在哪里查找它们。'
- en: This mini-course is not a textbook on Deep Learning.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 这个迷你课程不是一本深度学习的教科书。
- en: It will take you from a developer that knows a little machine learning in Python
    to a developer who can get results and bring the power of Deep Learning to your
    own projects.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 它将带领你从一个在Python中略懂机器学习的开发者，变成一个能够产生结果并将深度学习的力量引入自己项目的开发者。
- en: Mini-Course Overview
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 迷你课程概述
- en: This mini-course is divided into 9 parts.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 这个迷你课程分为9部分。
- en: Each lesson was designed to take the average developer about 30 minutes. You
    might finish some much sooner and other you may choose to go deeper and spend
    more time.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 每一课设计为一般开发者约30分钟完成。有些课可能会更快完成，有些你可能会选择深入学习，花更多时间。
- en: You can complete each part as quickly or as slowly as you like. A comfortable
    schedule may be to complete one lesson per day over nine days. Highly recommended.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以根据自己的节奏完成每一部分。一个舒适的时间表可能是每天完成一课，共九天。强烈推荐。
- en: 'The topics you will cover over the next 9 lessons are as follows:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的9课中，您将学习以下主题：
- en: '**Lesson 1**: Introduction to PyTorch.'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第1课**: PyTorch简介'
- en: '**Lesson 2**: Build Your First Multilayer Perceptron Model'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第2课**: 构建你的第一个多层感知器模型'
- en: '**Lesson 3**: Training a PyTorch Model'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第3课**: 训练一个PyTorch模型'
- en: '**Lesson 4**: Using a PyTorch Model for Inference'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第4课**: 使用PyTorch模型进行推断'
- en: '**Lesson 5**: Loading Data from Torchvision'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第5课**: 从Torchvision加载数据'
- en: '**Lesson 6**: Using PyTorch DataLoader'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第6课**: 使用PyTorch DataLoader'
- en: '**Lesson 7**: Convolutional Neural Network'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第7课**：卷积神经网络'
- en: '**Lesson 8**: Train an Image Classifier'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第8课**：训练图像分类器'
- en: '**Lesson 9**: Train with GPU'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第9课**：使用GPU训练'
- en: This is going to be a lot of fun.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这将会非常有趣。
- en: You’re going to have to do some work though, a little reading, a little research
    and a little programming. You want to learn deep learning right?
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 你需要做一些工作，包括一点阅读、一些研究和一点编程。你想学习深度学习，对吧？
- en: '**Post your results in the comments**; I’ll cheer you on!'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**在评论中发布你的结果**；我会为你加油！'
- en: Hang in there; don’t give up.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 坚持下去，别放弃。
- en: 'Lesson 01: Introduction to PyTorch'
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第01课：PyTorch简介
- en: PyTorch is a Python library for deep learning computing created and released
    by Facebook. It has its root from an earlier library Torch 7 but completely rewritten.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch是由Facebook创建和发布的一个用于深度学习计算的Python库。它源自早期的库Torch 7，但完全重写了。
- en: It is one of the two most popular deep learning libraries. PyTorch is a complete
    library that has the capability to train a deep learning model as well as run
    a model in inference mode, and supports using GPU for faster training and inference.
    It is a platform that we cannot ignore.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最受欢迎的两个深度学习库之一。PyTorch是一个完整的库，具备训练深度学习模型的能力，同时支持在推理模式下运行模型，并支持使用GPU以加速训练和推理。它是一个我们不能忽视的平台。
- en: In this lesson your goal is to install PyTorch become familiar with the syntax
    of the symbolic expressions used in PyTorch programs.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在本课中，你的目标是安装PyTorch，并熟悉PyTorch程序中使用的符号表达式的语法。
- en: For example, you can install PyTorch using `pip`. The latest version of PyTorch
    at the time of writing is 2.0\. There are PyTorch prebuilt for each platform,
    including Windows, Linux, and macOS. With a working Python environment, `pip`
    should take care of that for you to provide you the latest version in your platform.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，你可以使用`pip`安装PyTorch。在撰写本文时，PyTorch的最新版本是2.0。PyTorch为每个平台提供了预构建版本，包括Windows、Linux和macOS。只要有一个有效的Python环境，`pip`会为你处理这些，以提供你平台上的最新版本。
- en: Besides PyTorch, there is also the `torchvision` library that is commonly used
    together with PyTorch. It provides a lot of useful functions to help computer
    vision projects.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 除了PyTorch，还有`torchvision`库，它通常与PyTorch一起使用。它提供了许多有用的函数来帮助计算机视觉项目。
- en: '[PRE0]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'A small example of a PyTorch program that you can use as a starting point is
    listed below:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 一个可以作为起点的小示例PyTorch程序如下所示：
- en: '[PRE1]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Learn more about PyTorch on the [PyTorch homepage](https://www.pytorch.org/).
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在[PyTorch主页](https://www.pytorch.org/)上了解更多关于PyTorch的信息。
- en: Your Task
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你的任务
- en: 'Repeat the above code to make sure you have PyTorch correctly installed. You
    can also check your PyTorch version by running the following lines of Python code:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 重复以上代码以确保你已正确安装PyTorch。你还可以通过运行以下Python代码行来检查你的PyTorch版本：
- en: '[PRE2]'
  id: totrans-46
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: In the next lesson, you will use PyTorch to build a neural network model.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一课中，你将使用PyTorch构建一个神经网络模型。
- en: 'Lesson 02: Build Your First Multilayer Perceptron Model'
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第02课：构建你的第一个多层感知器模型
- en: Deep learning is about building large scale neural networks. The simplest form
    of neural network is called multilayer perceptron model. The building block for
    neural networks are artificial neurons or perceptrons. These are simple computational
    units that have weighted input signals and produce an output signal using an activation
    function.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是构建大规模神经网络的过程。神经网络的最简单形式称为多层感知器模型。神经网络的构建块是人工神经元或感知器。这些是简单的计算单元，具有加权输入信号，并使用激活函数产生输出信号。
- en: Perceptrons are arranged into networks. A row of perceptrons is called a layer
    and one network can have multiple layers. The architecture of the perceptrons
    in the network is often called the network topology. Once configured, the neural
    network needs to be trained on your dataset. The classical and still preferred
    training algorithm for neural networks is called stochastic gradient descent.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 感知器被排列成网络。一排感知器被称为一个层，一个网络可以有多个层。网络中感知器的架构通常称为网络拓扑。一旦配置完成，神经网络需要在你的数据集上进行训练。经典且仍然首选的神经网络训练算法称为随机梯度下降。
- en: '![Model of a Simple Neuron](../Images/c8f8094f52ec2ce1580e555f70538bf9.png)'
  id: totrans-51
  prefs: []
  type: TYPE_IMG
  zh: '![简单神经元模型](../Images/c8f8094f52ec2ce1580e555f70538bf9.png)'
- en: Model of a Simple Neuron
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 简单神经元模型
- en: PyTorch allows you to develop and evaluate deep learning models in very few
    lines of code.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: PyTorch允许你用极少的代码行开发和评估深度学习模型。
- en: In the following, your goal is to develop your first neural network using PyTorch.
    Use a standard binary (two-class) classification dataset from the UCI Machine
    Learning Repository, like the [Pima Indians dataset](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 在接下来的内容中，你的目标是使用PyTorch开发你的第一个神经网络。使用来自UCI机器学习库的标准二分类数据集，如[Pima Indians 数据集](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv)。
- en: 'To keep things simple, the network model is just a few layers of **fully-connected**
    perceptrons. In this particular model, the dataset has 12 inputs or **predictors**
    and the output is a single value of 0 or 1\. Therefore, the network model should
    have 12 inputs (at the first layer) and 1 output (at the last layer). Your first
    model would be built as follows:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 为了保持简单，网络模型仅由几层**全连接**感知机组成。在这个特定模型中，数据集有12个输入或**预测变量**，输出是一个0或1的单一值。因此，网络模型应有12个输入（在第一层）和1个输出（在最后一层）。你的第一个模型将按如下方式构建：
- en: '[PRE3]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This is a network with 3 fully-connected layers. Each layer is created in PyTorch
    using the `nn.Linear(x, y)` syntax which the first argument is the number of input
    to the layer and the second is the number of output. Between each layer, a rectified
    linear activation is used, but at the output, sigmoid activation is applied such
    that the output value is between 0 and 1\. This is a typical network. A deep learning
    model is to have a lot of such layers in a model.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个包含3层全连接层的网络。每一层都是使用`nn.Linear(x, y)`语法在PyTorch中创建的，其中第一个参数是输入到该层的数量，第二个参数是输出的数量。在每一层之间，使用了修正线性激活函数，但在输出层，应用了sigmoid激活函数，使得输出值介于0和1之间。这是一个典型的网络。深度学习模型通常会在模型中包含许多这样的层。
- en: Your Task
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你的任务
- en: Repeat the above code and observe the printed model output. Try to add another
    layer that outputs 20 values after the first `Linear` layer above. What should
    you change to the line of `nn.Linear(12, 8)` to accommodate this addition?
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 重复上述代码并观察打印的模型输出。尝试在上述第一个`Linear`层之后添加另一个输出20个值的层。你应该如何修改`nn.Linear(12, 8)`这一行以适应这个添加的层？
- en: In the next lesson, you will see how to train this model.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一课中，你将看到如何训练这个模型。
- en: 'Lesson 03: Training a PyTorch Model'
  id: totrans-61
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '课程 03: 训练一个 PyTorch 模型'
- en: 'Building a neural network in PyTorch does not tell how you should train the
    model for a particular job. In fact, there are many variations in this aspect
    as described by the **hyperparameters**. In PyTorch, or all deep learning models
    in general, you need to decide the following on how to train a model:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在PyTorch中构建神经网络并没有说明你应该如何为特定任务训练模型。实际上，在这方面有很多变种，这些变种由**超参数**描述。在PyTorch或所有深度学习模型中，你需要决定以下内容来训练模型：
- en: What is the dataset, specifically how the input and target looks like
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据集是什么，特别是输入和目标的样子如何？
- en: What is the loss function to evaluate the goodness of fit of the model to the
    data
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是评估模型拟合数据优度的损失函数？
- en: What is the optimization algorithm to train the model, and the parameters to
    the optimization algorithm such as learning rate and number of
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用于训练模型的优化算法是什么，以及优化算法的参数如学习率和次数是什么？
- en: iterations to train
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 训练的迭代次数
- en: In the previous lesson, the Pima Indian dataset is used and all the input are
    numbers. This would be the simplest case as you are not required to do any preprocessing
    of the data since neural networks can readily handle numbers.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一课中，使用了Pima Indians数据集，并且所有输入都是数字。这将是最简单的情况，因为你不需要对数据进行任何预处理，因为神经网络可以直接处理数字。
- en: Since it is a binary classification problem, the loss function should be binary
    cross entropy. It means that the target of the model output is 0 or 1 for the
    classification result. But in reality the model may output anything in between.
    The closer it is to the target value, the better (i.e., lower **loss**).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这是一个二分类问题，因此损失函数应该是二元交叉熵。这意味着模型输出的目标值是0或1，用于分类结果。但在实际中，模型可能输出介于两者之间的任何值。离目标值越近越好（即，**损失**越低）。
- en: Gradient descent is the algorithm to optimize neural networks. There are many
    variations of gradient descent and Adam is one of the most used.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度下降是优化神经网络的算法。梯度下降有许多变种，而Adam是最常用的算法之一。
- en: 'Implementing all the above, together with the model built in the previous lesson,
    the following is the code of the training process:'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 实现上述所有内容，加上在上一课中构建的模型，以下是训练过程的代码：
- en: '[PRE4]'
  id: totrans-71
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: The for-loop above is to get a **batch** of data and feed into the model. Then
    observe the model’s output and calculate the loss function. Based on the loss
    function, the optimizer will fine-tune the model for one step, so it can match
    better to the training data. After a number of update steps, the model should
    be close enough to the training data that it can predict the target at a high
    accuracy.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 上述的 for 循环用于获取一个**批次**的数据并将其输入到模型中。然后观察模型的输出并计算损失函数。根据损失函数，优化器将对模型进行一步微调，以便更好地匹配训练数据。经过若干次更新步骤后，模型应该足够接近训练数据，以便能够以较高的准确率预测目标。
- en: Your Task
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你的任务
- en: Run the training loop above and observe how the loss decreases as the training
    loop proceeds.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 运行上述训练循环，并观察随着训练循环的进行，损失如何减少。
- en: In the next lesson, you will see how use the trained model.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一课中，你将看到如何使用训练好的模型。
- en: 'Lesson 04: Using a PyTorch Model for Inference'
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 课程 04：使用 PyTorch 模型进行推断
- en: A trained neural network model is a model that remembered how the input and
    target related. Then, this model can predict the target given another input.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 一个训练好的神经网络模型是一个记住了输入和目标之间关系的模型。然后，该模型可以在给定另一个输入的情况下预测目标。
- en: 'In PyTorch, a trained model can behave just like a function. Assume you have
    the model trained in the previous lesson, you can simply use it as follows:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在 PyTorch 中，一个训练好的模型可以像函数一样运行。假设你已经在前一课中训练了这个模型，你可以简单地如下使用它：
- en: '[PRE5]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'But in fact, the better way of running inference is the following:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 但实际上，更好的推断方法是如下：
- en: '[PRE6]'
  id: totrans-81
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: Some model will behave differently between training and inference. The line
    of `model.eval()` is to signal the model that the intention is to run the model
    for inference. The line `with torch.no_grad()`  is to create a context for running
    the model, such that PyTorch knows calculating the gradient is not required. This
    can consume less resources.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 一些模型在训练和推断之间表现不同。`model.eval()` 这一行是为了告诉模型意图是进行推断。`with torch.no_grad()` 这一行是为了创建一个运行模型的上下文，以便
    PyTorch 知道计算梯度是不必要的。这可以减少资源消耗。
- en: 'This is also how you can evaluate the model. The model outputs a sigmoid value,
    which is between 0 and 1\. You can interpret the value by rounding off the value
    to the closest integer (i.e., Boolean label). Comparing how often the prediction
    after round off match the target, you can assign an accuracy percentage to the
    model, as follows:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 这也是你可以评估模型的方式。模型输出一个 sigmoid 值，该值在 0 和 1 之间。你可以通过将值四舍五入到最接近的整数（即布尔标签）来解释这个值。通过比较四舍五入后的预测与目标匹配的频率，你可以为模型分配一个准确率百分比，如下：
- en: '[PRE7]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Your Task
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你的任务
- en: Run the above code and see what is the accuracy you get. You should achieve
    roughly 75%.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 运行上述代码，看看你得到的准确率是多少。你应该大致达到 75%。
- en: In the next lesson, you will learn about torchvision.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一课中，你将学习关于 torchvision 的内容。
- en: 'Lesson 05: Loading Data from Torchvision'
  id: totrans-88
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 课程 05：从 Torchvision 加载数据
- en: Torchvision is a sister library to PyTorch. In this library, there are functions
    specialized for image and computer vision. As you can expect, there are functions
    to help you read images or adjust the contrast. But probably most important is
    to provide an easy interface to get some image datasets.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: Torchvision 是 PyTorch 的姊妹库。在这个库中，有专门用于图像和计算机视觉的函数。正如你所期望的，有帮助你读取图像或调整对比度的函数。但可能最重要的是提供一个易于获取一些图像数据集的接口。
- en: In the next lesson, you will build a deep learning model to classify small images.
    This is a model that allows your computer to see what’s on an image. As you saw
    in the previous lessons, it is important to have the dataset to train the model.
    The dataset you’re going to use is CIFAR-10\. It is a dataset of 10 different
    objects. There is a larger dataset called CIFAR-100, too.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一课中，你将构建一个深度学习模型来分类小图像。这是一个使计算机能够识别图像内容的模型。正如你在前面的课程中看到的，拥有数据集来训练模型是非常重要的。你将要使用的数据集是
    CIFAR-10。它是一个包含 10 种不同物体的数据集。还有一个更大的数据集叫做 CIFAR-100。
- en: 'The CIFAR-10 dataset can be downloaded from the Internet. But if you have torchvision
    installed, you just need to do the following:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: CIFAR-10 数据集可以从互联网下载。但是如果你已经安装了 torchvision，你只需执行以下操作：
- en: '[PRE8]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'The `torchvision.datasets.CIFAR10` function helps you to download the CIFAR-10
    dataset to a local directory. The dataset is divided into training set and test
    set. Therefore the two lines above is to get both of them. Then you plot the first
    24 images from the downloaded dataset. Each image in the dataset is 32×32 pixels
    picture of one of the following: airplane, automobile, bird, cat, deer, dog, frog,
    horse, ship, or truck.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '`torchvision.datasets.CIFAR10` 函数帮助你将 CIFAR-10 数据集下载到本地目录。数据集分为训练集和测试集。因此，上面的两行代码是为了获取它们。然后你绘制从下载的数据集中获得的前
    24 张图像。数据集中的每张图像是 32×32 像素的以下任意一种：飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船或卡车。'
- en: Your Task
  id: totrans-94
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你的任务
- en: Based on the code above, can you find a way to count how many images in total
    in the training set and test set, respectively?
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 根据上述代码，你能找到一种方法来分别计算训练集和测试集中总共有多少张图像吗？
- en: In the next lesson, you will learn how to use PyTorch DataLoader.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一课中，你将学习如何使用 PyTorch DataLoader。
- en: 'Lesson 06: Using PyTorch DataLoader'
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 课程 06：使用 PyTorch DataLoader
- en: The CIFAR-10 image from the previous lesson is indeed in the format of numpy
    array. But for consumption by a PyTorch model, it needs to be in PyTorch tensors.
    It is not difficult to convert a numpy array into PyTorch tensor but in the training
    loop, you still need to divide the dataset in batches. The PyTorch DataLoader
    can help you make this process smoother.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 上一课中的 CIFAR-10 图像确实是 numpy 数组格式。但为了供 PyTorch 模型使用，它需要是 PyTorch 张量。将 numpy 数组转换为
    PyTorch 张量并不难，但在训练循环中，你仍然需要将数据集划分为批次。PyTorch DataLoader 可以帮助你使这个过程更加顺畅。
- en: 'Back to the CIFAR-10 dataset as loaded in the previous lesson, you can do the
    following for the identical effect:'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 返回到上一课中加载的 CIFAR-10 数据集，你可以做以下操作以实现相同的效果：
- en: '[PRE9]'
  id: totrans-100
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: In this code, `trainset` is created with `transform` argument so that the data
    is converted into PyTorch tensor when it is extracted. This is performed in `DataLoader`
    the lines following it. The `DataLoader` object is a Python iterable, which you
    can extract the input (which are images) and target (which are integer class labels).
    In this case, you set the batch size to 24 and iterate for the first batch. Then
    you show each image in the batch.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 在这段代码中，`trainset` 是通过 `transform` 参数创建的，这样数据在提取时会转换为 PyTorch 张量。这是在 `DataLoader`
    后续的行中执行的。`DataLoader` 对象是一个 Python 可迭代对象，你可以提取输入（即图像）和目标（即整数类别标签）。在这种情况下，你将批量大小设置为
    24，并迭代第一个批次。然后你展示批次中的每张图像。
- en: Your Task
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你的任务
- en: Run the code above and compare with the matplotlib output you generated in the
    previous lesson. You should see the output are different. Why? There is an argument
    in the `DataLoader` lines caused the difference. Can you identify which one?
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 运行上面的代码，并与你在上一课中生成的 matplotlib 输出进行比较。你应该会看到输出不同。为什么？在`DataLoader`行中有一个参数导致了这个差异。你能找出是哪一个吗？
- en: In the next lesson, you will learn how to build a deep learning model to classify
    the images from CIFAR-10 dataset.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一课中，你将学习如何构建深度学习模型来分类 CIFAR-10 数据集中的图像。
- en: 'Lesson 07: Convolutional Neural Network'
  id: totrans-105
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 课程 07：卷积神经网络
- en: Images are 2D structures. You can easily convert them into 1D vectors by flattening
    it and build a neural network model to classify them. But it is known that preserving
    the 2D structure would be more appropriate because the classification is about
    what’s in the image, which is **translation invariant**.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 图像是二维结构。你可以通过将其展开为一维向量来轻松地转换它们，并构建神经网络模型对其进行分类。但已知保留二维结构更为合适，因为分类涉及的是图像中的内容，这具有**平移不变性**。
- en: 'The standard way for image processing neural network is to use convolutional
    layers. A neural network that uses convolutional layers is called a convolutional
    neural network. An example is as follows:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 处理图像的神经网络标准方法是使用卷积层。使用卷积层的神经网络称为卷积神经网络。示例如下：
- en: '[PRE10]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: In the above, we used `Conv2d` layers several times, as well as `ReLU` activation.
    The convolutional layers are to learn and extract **features** from image. More
    convolutional layers you add, the network can learn more high-level features.
    Eventually, you would use a pooling layer (`MaxPool2d` above) to group the extracted
    features, flatten them into a vector, then pass it on to a multilayer perceptron
    network for final classification. This is the usual structure of an image classification
    model.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述内容中，我们使用了多次 `Conv2d` 层以及 `ReLU` 激活。卷积层用于学习和提取图像的 **特征**。你添加的卷积层越多，网络可以学习到更多的高级特征。最终，你会使用一个池化层（上面的
    `MaxPool2d`）来对提取的特征进行分组，将它们展平为一个向量，然后传递给一个多层感知机网络进行最终分类。这是图像分类模型的常见结构。
- en: Your Task
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你的任务
- en: Run the above code to make sure you can correctly create a model. You didn’t
    specify the input image size in the model but indeed it is fixed to 32×32 pixels
    in RGB (i.e., 3 color channels). Where is this fixed in the network?
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 运行上述代码以确保你可以正确创建一个模型。你没有在模型中指定输入图像的大小，但它实际上被固定为 32×32 像素的 RGB（即 3 个颜色通道）。这一固定设置在网络中在哪里？
- en: In the next lesson, you will use the DataLoader in the previous lesson to train
    the model above.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一课中，你将使用上一课中的 DataLoader 来训练上述模型。
- en: 'Lesson 08: Train an Image Classifier'
  id: totrans-113
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 课程 08：训练图像分类器
- en: 'Together with the DataLoader created for CIFAR-10 dataset, you can train the
    convolutional neural network in the previous lesson with the following training
    loop:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 配合为 CIFAR-10 数据集创建的 DataLoader，你可以使用以下训练循环来训练前一课中的卷积神经网络：
- en: '[PRE11]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This will take a while to run, and you should see the model produced can achieve
    no less than 70% accuracy.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 这将需要一些时间运行，你应该看到模型能够达到至少 70% 的准确率。
- en: This model is a multiclass classification network. The output is not one, but
    many scores, one for each class. We consider the higher score the more confident
    the model thinks the image belongs to a class. The loss function used is therefore
    **cross-entropy**, the multiclass version of binary cross-entropy.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 这个模型是一个多类别分类网络。输出不是一个，而是多个分数，每个类别一个。我们认为分数越高，模型越有信心图像属于某个类别。因此，使用的损失函数是 **交叉熵**，即多类别版本的二元交叉熵。
- en: In the training loop above, you should see quite many elements you learned in
    the previous lessons. Including switching between training and inference mode
    in the model, using `torch.no_grad()` context, and calculation of the accuracy.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述训练循环中，你应该会看到许多你在前面课程中学到的元素，包括在模型中切换训练模式和推理模式，使用 `torch.no_grad()` 上下文，以及准确率的计算。
- en: Your Task
  id: totrans-119
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你的任务
- en: Read the code above to make sure you understand what it does. Run this code
    to observe the accuracy increase as the training proceeds. What is the final accuracy
    you achieved?
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 阅读上述代码以确保你理解它的作用。运行此代码以观察随着训练的进行准确率的提高。你最终达到了什么准确率？
- en: In the next lesson, you will learn how to use GPU to speed up the training of
    the same model.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一课中，你将学习如何使用 GPU 加速同一模型的训练。
- en: 'Lesson 09: Train with GPU'
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 课程 09：使用 GPU 进行训练
- en: The model training you did in the previous lesson should take a while. If you
    have a supported GPU, you can speed up the training a lot.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 你在上一课中进行的模型训练应该需要一段时间。如果你有支持的 GPU，你可以大大加快训练速度。
- en: The way to use GPU in PyTorch is to send the model and data to GPU before execution.
    Then you have an option to send back the result from GPU, or perform the evaluation
    in GPU directly.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 在 PyTorch 中使用 GPU 的方法是先将模型和数据发送到 GPU，然后可以选择将结果从 GPU 发送回 CPU，或者直接在 GPU 上进行评估。
- en: 'It is not difficult to modify the code from the previous lesson to use GPU.
    Below is what it should be done:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 修改上一课的代码以使用 GPU 并不困难。下面是需要做的内容：
- en: '[PRE12]'
  id: totrans-126
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: 'The changes made are the following: You check if GPU is available and set the
    `device` accordingly. Then the model is sent to the device. When the input (i.e.,
    a batch of images) is pass on to the model, it should be sent to the corresponding
    device first. Since the model output will also be there, the loss calculation
    or the accuracy calculation should also have the target sent to the GPU first.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 所做的更改如下：你检查 GPU 是否可用并相应地设置 `device`。然后将模型发送到该设备。当输入（即一批图像）传递到模型时，它也应该首先发送到相应的设备。由于模型输出也会在那里，因此损失计算或准确率计算也应将目标首先发送到
    GPU。
- en: Your Task
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你的任务
- en: You can see the running PyTorch in CPU and in GPU are mostly the same. Try compare
    the two if you can access to a GPU. How much faster you can observe?
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到，在 CPU 和 GPU 上运行 PyTorch 的方式大致相同。如果你可以访问到 GPU，尝试比较这两者的速度。你能观察到快了多少？
- en: This was the final lesson.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 这是最后一课。
- en: The End! (*Look How Far You Have Come*)
  id: totrans-131
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结束！（*看看你走了多远*）
- en: You made it. Well done!
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 你做到了。做得好！
- en: Take a moment and look back at how far you have come.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 花点时间回顾一下你走过的路程。
- en: You discovered PyTorch as a deep learning library in Python
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你发现了 PyTorch 作为一个 Python 中的深度学习库。
- en: You built your first neural network using PyTorch and learned how to do classification
    with a neural network
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你使用 PyTorch 构建了你的第一个神经网络，并学习了如何用神经网络进行分类。
- en: You learned key components in deep learning, including loss function, optimizer,
    training loop, and evaluation
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你学习了深度学习的关键组成部分，包括损失函数、优化器、训练循环和评估。
- en: Finally, you took the next step and learned about and developed convolutional
    neural networks for computer vision tasks
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最后，你迈出了下一步，学习了关于卷积神经网络以及如何用于计算机视觉任务。
- en: Summary
  id: totrans-138
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: '**How did you do with the mini-course?**'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '**你在迷你课程中表现如何？**'
- en: Did you enjoy this crash course?
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 你喜欢这个速成课程吗？
- en: '**Do you have any questions? Were there any sticking points?**'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '**你有任何问题吗？有没有什么难点？**'
- en: Let me know. Leave a comment below.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 让我知道。请在下面留言。
