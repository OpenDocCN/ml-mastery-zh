["```py\nclass MyClass:\n    <statements>\n```", "```py\nx = MyClass()\n```", "```py\nclass Dog:\n\tfamily = \"Canine\"\n\n\tdef __init__(self, name, breed):\n\t\tself.name = name\n\t\tself.breed = breed\n```", "```py\ndog1 = Dog(\"Lassie\", \"Rough Collie\")\n```", "```py\nprint(dog1.name)\n```", "```py\nLassie\n```", "```py\nclass Dog:\n\tfamily = \"Canine\"\n\n\tdef __init__(self, name, breed):\n\t\tself.name = name\n\t\tself.breed = breed\n\n\tdef info(self):\n\t\tprint(self.name, \"is a female\", self.breed)\n```", "```py\nclass Dog:\n\tfamily = \"Canine\"\n\n\tdef __init__(self, name, breed):\n\t\tself.name = name\n\t\tself.breed = breed\n\t\tself.tricks = []\n\n\tdef add_tricks(self, x):\n\t\tself.tricks.append(x)\n\n\tdef info(self, x):\n\t\tself.add_tricks(x)\n\t\tprint(self.name, \"is a female\", self.breed, \"that\", self.tricks[0])\n```", "```py\ndog1 = Dog(\"Lassie\", \"Rough Collie\")\ndog1.info(\"barks on command\")\n```", "```py\nLassie is a female Rough Collie that barks on command\n```", "```py\nclass SubClass(BaseClass):\n    <statements>\n```", "```py\nclass SubClass(BaseClass1, BaseClass2, BaseClass3):\n    <statements>\n```", "```py\nimport tensorflow.keras as keras\n\nclass EpochCallback(keras.callbacks.Callback):\n    def on_epoch_begin(self, epoch, logs=None):\n        print(\"Starting epoch {}\".format(epoch + 1))\n\n    def on_epoch_end(self, epoch, logs=None):\n        print(\"Finished epoch {}\".format(epoch + 1))\n```", "```py\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten\n\ndef simple_model():\n    model = Sequential()\n    model.add(Flatten(input_shape=(28, 28)))\n    model.add(Dense(128, activation=\"relu\"))\n    model.add(Dense(10, activation=\"softmax\"))\n\n    model.compile(loss=\"categorical_crossentropy\",\n                  optimizer=\"sgd\",\n                  metrics=[\"accuracy\"])\n    return model\n```", "```py\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.utils import to_categorical\n\n# Loading the MNIST training and testing data splits\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\n\n# Pre-processing the training data\nx_train = x_train / 255.0\nx_train = x_train.reshape(60000, 28, 28, 1)\ny_train_cat = to_categorical(y_train, 10)\n```", "```py\nmodel = simple_model()\n\nmodel.fit(x_train,\n          y_train_cat,\n          batch_size=32,\n          epochs=5,\n          callbacks=[EpochCallback()],\n          verbose=0)\n```", "```py\nStarting epoch 1\nFinished epoch 1\nStarting epoch 2\nFinished epoch 2\nStarting epoch 3\nFinished epoch 3\nStarting epoch 4\nFinished epoch 4\nStarting epoch 5\nFinished epoch 5\n```", "```py\nimport numpy as np\n\nclass CheckpointCallback(keras.callbacks.Callback):\n\n    def __init__(self):\n        super(CheckpointCallback, self).__init__()\n        self.best_weights = None\n\n    def on_train_begin(self, logs=None):\n        self.best_loss = np.Inf\n\n    def on_epoch_end(self, epoch, logs=None):\n        current_loss = logs.get(\"loss\")\n        print(\"Current loss is {}\".format(current_loss))\n        if np.less(current_loss, self.best_loss):\n            self.best_loss = current_loss\n            self.best_weights = self.model.get_weights()\n            print(\"Storing the model weights at epoch {} \\n\".format(epoch + 1))\n```", "```py\nmodel = simple_model()\n\nmodel.fit(x_train,\n          y_train_cat,\n          batch_size=32,\n          epochs=5,\n          callbacks=[EpochCallback(), CheckpointCallback()],\n          verbose=0)\n```", "```py\nStarting epoch 1\nFinished epoch 1\nCurrent loss is 0.6327750086784363\nStoring the model weights at epoch 1\n\nStarting epoch 2\nFinished epoch 2\nCurrent loss is 0.3391888439655304\nStoring the model weights at epoch 2\n\nStarting epoch 3\nFinished epoch 3\nCurrent loss is 0.29216915369033813\nStoring the model weights at epoch 3\n\nStarting epoch 4\nFinished epoch 4\nCurrent loss is 0.2625095248222351\nStoring the model weights at epoch 4\n\nStarting epoch 5\nFinished epoch 5\nCurrent loss is 0.23906977474689484\nStoring the model weights at epoch 5\n```", "```py\nclass BinaryTruePositives(tf.keras.metrics.Metric):\n\n  def __init__(self, name='binary_true_positives', **kwargs):\n    super(BinaryTruePositives, self).__init__(name=name, **kwargs)\n    self.true_positives = self.add_weight(name='tp', initializer='zeros')\n\n  def update_state(self, y_true, y_pred, sample_weight=None):\n    y_true = tf.cast(y_true, tf.bool)\n    y_pred = tf.cast(y_pred, tf.bool)\n\n    values = tf.logical_and(tf.equal(y_true, True), tf.equal(y_pred, True))\n    values = tf.cast(values, self.dtype)\n    if sample_weight is not None:\n      sample_weight = tf.cast(sample_weight, self.dtype)\n      values = tf.multiply(values, sample_weight)\n    self.true_positives.assign_add(tf.reduce_sum(values))\n\n  def result(self):\n    return self.true_positives\n\n  def reset_states(self):\n    self.true_positives.assign(0)\n\nm = BinaryTruePositives()\nm.update_state([0, 1, 1, 1], [0, 1, 0, 0])\nprint('Intermediate result:', float(m.result()))\n\nm.update_state([1, 1, 1, 1], [0, 1, 1, 0])\nprint('Final result:', float(m.result()))\n```"]