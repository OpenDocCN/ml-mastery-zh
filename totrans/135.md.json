["```py\npip install torch skorch scikit-learn\n```", "```py\nimport copy\n\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\n\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.preprocessing import LabelEncoder\nfrom skorch import NeuralNetBinaryClassifier\n\n# Read data\ndata = pd.read_csv(\"sonar.csv\", header=None)\nX = data.iloc[:, 0:60]\ny = data.iloc[:, 60]\n\n# Binary encoding of labels\nencoder = LabelEncoder()\nencoder.fit(y)\ny = encoder.transform(y)\n\n# Convert to 2D PyTorch tensors\nX = torch.tensor(X.values, dtype=torch.float32)\ny = torch.tensor(y, dtype=torch.float32)\n\n# Define the model\nclass SonarClassifier(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layer1 = nn.Linear(60, 60)\n        self.act1 = nn.ReLU()\n        self.layer2 = nn.Linear(60, 60)\n        self.act2 = nn.ReLU()\n        self.layer3 = nn.Linear(60, 60)\n        self.act3 = nn.ReLU()\n        self.output = nn.Linear(60, 1)\n\n    def forward(self, x):\n        x = self.act1(self.layer1(x))\n        x = self.act2(self.layer2(x))\n        x = self.act3(self.layer3(x))\n        x = self.output(x)\n        return x\n\n# create the skorch wrapper\nmodel = NeuralNetBinaryClassifier(\n    SonarClassifier,\n    criterion=torch.nn.BCEWithLogitsLoss,\n    optimizer=torch.optim.Adam,\n    lr=0.0001,\n    max_epochs=150,\n    batch_size=10\n)\n\n# run\nmodel.fit(X, y)\n```", "```py\n  epoch    train_loss    valid_acc    valid_loss     dur\n-------  ------------  -----------  ------------  ------\n      1        0.6952       0.5476        0.6921  0.0135\n      2        0.6930       0.5476        0.6920  0.0114\n      3        0.6925       0.5476        0.6919  0.0104\n      4        0.6922       0.5238        0.6918  0.0118\n      5        0.6919       0.5238        0.6917  0.0112\n...\n    146        0.2942       0.4524        0.9425  0.0115\n    147        0.2920       0.4524        0.9465  0.0123\n    148        0.2899       0.4524        0.9495  0.0112\n    149        0.2879       0.4524        0.9544  0.0121\n    150        0.2859       0.4524        0.9583  0.0118\n```", "```py\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\n\nmodel = NeuralNetBinaryClassifier(\n    SonarClassifier,\n    criterion=torch.nn.BCEWithLogitsLoss,\n    optimizer=torch.optim.Adam,\n    lr=0.0001,\n    max_epochs=150,\n    batch_size=10,\n    verbose=False\n)\n\nkfold = StratifiedKFold(n_splits=5, shuffle=True)\nresults = cross_val_score(model, X, y, cv=kfold)\nprint(results)\n```", "```py\n[0.76190476 0.76190476 0.78571429 0.75609756 0.75609756]\n```", "```py\nprint(\"mean = %.3f; std = %.3f\" % (results.mean(), results.std()))\n```", "```py\nmean = 0.764; std = 0.011\n```", "```py\nimport copy\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.preprocessing import LabelEncoder\nfrom skorch import NeuralNetBinaryClassifier\nfrom sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score\n\n# Read data\ndata = pd.read_csv(\"sonar.csv\", header=None)\nX = data.iloc[:, 0:60]\ny = data.iloc[:, 60]\n\n# Binary encoding of labels\nencoder = LabelEncoder()\nencoder.fit(y)\ny = encoder.transform(y)\n\n# Convert to 2D PyTorch tensors\nX = torch.tensor(X.values, dtype=torch.float32)\ny = torch.tensor(y, dtype=torch.float32)\n\n# Define the model\nclass SonarClassifier(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.layer1 = nn.Linear(60, 60)\n        self.act1 = nn.ReLU()\n        self.layer2 = nn.Linear(60, 60)\n        self.act2 = nn.ReLU()\n        self.layer3 = nn.Linear(60, 60)\n        self.act3 = nn.ReLU()\n        self.output = nn.Linear(60, 1)\n\n    def forward(self, x):\n        x = self.act1(self.layer1(x))\n        x = self.act2(self.layer2(x))\n        x = self.act3(self.layer3(x))\n        x = self.output(x)\n        return x\n\n# create the skorch wrapper\nmodel = NeuralNetBinaryClassifier(\n    SonarClassifier,\n    criterion=torch.nn.BCEWithLogitsLoss,\n    optimizer=torch.optim.Adam,\n    lr=0.0001,\n    max_epochs=150,\n    batch_size=10,\n    verbose=False\n)\n\n# k-fold\nkfold = StratifiedKFold(n_splits=5, shuffle=True)\nresults = cross_val_score(model, X, y, cv=kfold)\nprint(\"mean = %.3f; std = %.3f\" % (results.mean(), results.std()))\n```", "```py\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.neural_network import MLPClassifier\nimport numpy as np\n\n# load dataset\ndata = pd.read_csv(\"sonar.csv\", header=None)\n# split into input (X) and output (Y) variables, in numpy arrays\nX = data.iloc[:, 0:60].values\ny = data.iloc[:, 60].values\n\n# binary encoding of labels\nencoder = LabelEncoder()\nencoder.fit(y)\ny = encoder.transform(y)\n\n# create model\nmodel = MLPClassifier(hidden_layer_sizes=(60,60,60), activation='relu',\n                      max_iter=150, batch_size=10, verbose=False)\n\n# evaluate using 10-fold cross validation\nkfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\nresults = cross_val_score(model, X, y, cv=kfold)\nprint(\"mean = %.3f; std = %.3f\" % (results.mean(), results.std()))\n```", "```py\nclass SonarClassifier(nn.Module):\n    def __init__(self, n_layers=3):\n        super().__init__()\n        self.layers = []\n        self.acts = []\n        for i in range(n_layers):\n            self.layers.append(nn.Linear(60, 60))\n            self.acts.append(nn.ReLU())\n            self.add_module(f\"layer{i}\", self.layers[-1])\n            self.add_module(f\"act{i}\", self.acts[-1])\n        self.output = nn.Linear(60, 1)\n\n    def forward(self, x):\n        for layer, act in zip(self.layers, self.acts):\n            x = act(layer(x))\n        x = self.output(x)\n        return x\n```", "```py\nfrom sklearn.model_selection import GridSearchCV\n\nmodel = NeuralNetBinaryClassifier(\n    SonarClassifier,\n    criterion=torch.nn.BCEWithLogitsLoss,\n    optimizer=torch.optim.Adam,\n    lr=0.0001,\n    max_epochs=150,\n    batch_size=10,\n    verbose=False\n)\n\nparam_grid = {\n    'module__n_layers': [1, 3, 5], \n    'lr': [0.1, 0.01, 0.001, 0.0001],\n    'max_epochs': [100, 150],\n}\n\ngrid_search = GridSearchCV(model, param_grid, scoring='accuracy', verbose=1, cv=3)\nresult = grid_search.fit(X, y)\n```", "```py\nprint(\"Best: %f using %s\" % (result.best_score_, result.best_params_))\nmeans = result.cv_results_['mean_test_score']\nstds = result.cv_results_['std_test_score']\nparams = result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n```", "```py\nBest: 0.649551 using {'lr': 0.001, 'max_epochs': 150, 'module__n_layers': 1}\n0.533678 (0.003611) with: {'lr': 0.1, 'max_epochs': 100, 'module__n_layers': 1}\n0.533678 (0.003611) with: {'lr': 0.1, 'max_epochs': 100, 'module__n_layers': 3}\n0.533678 (0.003611) with: {'lr': 0.1, 'max_epochs': 100, 'module__n_layers': 5}\n0.533678 (0.003611) with: {'lr': 0.1, 'max_epochs': 150, 'module__n_layers': 1}\n0.533678 (0.003611) with: {'lr': 0.1, 'max_epochs': 150, 'module__n_layers': 3}\n0.533678 (0.003611) with: {'lr': 0.1, 'max_epochs': 150, 'module__n_layers': 5}\n0.644651 (0.062160) with: {'lr': 0.01, 'max_epochs': 100, 'module__n_layers': 1}\n0.567495 (0.049728) with: {'lr': 0.01, 'max_epochs': 100, 'module__n_layers': 3}\n0.533678 (0.003611) with: {'lr': 0.01, 'max_epochs': 100, 'module__n_layers': 5}\n0.615804 (0.061966) with: {'lr': 0.01, 'max_epochs': 150, 'module__n_layers': 1}\n0.620290 (0.078243) with: {'lr': 0.01, 'max_epochs': 150, 'module__n_layers': 3}\n0.533678 (0.003611) with: {'lr': 0.01, 'max_epochs': 150, 'module__n_layers': 5}\n0.635335 (0.108412) with: {'lr': 0.001, 'max_epochs': 100, 'module__n_layers': 1}\n0.582126 (0.058072) with: {'lr': 0.001, 'max_epochs': 100, 'module__n_layers': 3}\n0.563423 (0.136916) with: {'lr': 0.001, 'max_epochs': 100, 'module__n_layers': 5}\n0.649551 (0.075676) with: {'lr': 0.001, 'max_epochs': 150, 'module__n_layers': 1}\n0.558178 (0.071443) with: {'lr': 0.001, 'max_epochs': 150, 'module__n_layers': 3}\n0.567909 (0.088623) with: {'lr': 0.001, 'max_epochs': 150, 'module__n_layers': 5}\n0.557971 (0.041416) with: {'lr': 0.0001, 'max_epochs': 100, 'module__n_layers': 1}\n0.587026 (0.079951) with: {'lr': 0.0001, 'max_epochs': 100, 'module__n_layers': 3}\n0.606349 (0.092394) with: {'lr': 0.0001, 'max_epochs': 100, 'module__n_layers': 5}\n0.563147 (0.099652) with: {'lr': 0.0001, 'max_epochs': 150, 'module__n_layers': 1}\n0.534023 (0.057187) with: {'lr': 0.0001, 'max_epochs': 150, 'module__n_layers': 3}\n0.634921 (0.057235) with: {'lr': 0.0001, 'max_epochs': 150, 'module__n_layers': 5}\n```", "```py\nfrom sklearn.pipeline import Pipeline, FunctionTransformer\nfrom sklearn.preprocessing import StandardScaler\n\npipe = Pipeline([\n    ('scaler', StandardScaler()),\n    ('float32', FunctionTransformer(func=lambda X: torch.tensor(X, dtype=torch.float32),\n                                    validate=False)),\n    ('sonarmodel', model.initialize()),\n])\n```", "```py\nparam_grid = {\n    'sonarmodel__module__n_layers': [1, 3, 5], \n    'sonarmodel__lr': [0.1, 0.01, 0.001, 0.0001],\n    'sonarmodel__max_epochs': [100, 150],\n}\n\ngrid_search = GridSearchCV(pipe, param_grid, scoring='accuracy', verbose=1, cv=3)\nresult = grid_search.fit(X, y)\nprint(\"Best: %f using %s\" % (result.best_score_, result.best_params_))\nmeans = result.cv_results_['mean_test_score']\nstds = result.cv_results_['std_test_score']\nparams = result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n```", "```py\nimport copy\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split, cross_val_score\nfrom sklearn.pipeline import Pipeline, FunctionTransformer\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom skorch import NeuralNetBinaryClassifier\n\n# Read data\ndata = pd.read_csv(\"sonar.csv\", header=None)\nX = data.iloc[:, 0:60]\ny = data.iloc[:, 60]\n\n# Binary encoding of labels\nencoder = LabelEncoder()\nencoder.fit(y)\ny = encoder.transform(y)\n\n# Convert to 2D PyTorch tensors\nX = torch.tensor(X.values, dtype=torch.float32)\ny = torch.tensor(y, dtype=torch.float32)\n\nclass SonarClassifier(nn.Module):\n    def __init__(self, n_layers=3):\n        super().__init__()\n        self.layers = []\n        self.acts = []\n        for i in range(n_layers):\n            self.layers.append(nn.Linear(60, 60))\n            self.acts.append(nn.ReLU())\n            self.add_module(f\"layer{i}\", self.layers[-1])\n            self.add_module(f\"act{i}\", self.acts[-1])\n        self.output = nn.Linear(60, 1)\n\n    def forward(self, x):\n        for layer, act in zip(self.layers, self.acts):\n            x = act(layer(x))\n        x = self.output(x)\n        return x\n\nmodel = NeuralNetBinaryClassifier(\n    SonarClassifier,\n    criterion=torch.nn.BCEWithLogitsLoss,\n    optimizer=torch.optim.Adam,\n    lr=0.0001,\n    max_epochs=150,\n    batch_size=10,\n    verbose=False\n)\n\npipe = Pipeline([\n    ('scaler', StandardScaler()),\n    ('float32', FunctionTransformer(func=lambda X: torch.tensor(X, dtype=torch.float32),\n                                    validate=False)),\n    ('sonarmodel', model.initialize()),\n])\n\nparam_grid = {\n    'sonarmodel__module__n_layers': [1, 3, 5], \n    'sonarmodel__lr': [0.1, 0.01, 0.001, 0.0001],\n    'sonarmodel__max_epochs': [100, 150],\n}\n\ngrid_search = GridSearchCV(pipe, param_grid, scoring='accuracy', verbose=1, cv=3)\nresult = grid_search.fit(X, y)\nprint(\"Best: %f using %s\" % (result.best_score_, result.best_params_))\nmeans = result.cv_results_['mean_test_score']\nstds = result.cv_results_['std_test_score']\nparams = result.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n```"]