["```py\nfloat fsquare(float x)\n{\n    return x * x;\n};\n\nint isquare(int x)\n{\n    return x * x;\n};\n```", "```py\ndef square(x):\n    return x * x\n```", "```py\n# evaluate a perceptron model on the dataset\nfrom numpy import mean\nfrom numpy import std\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.linear_model import Perceptron\n# define dataset\nX, y = make_classification(n_samples=1000, n_features=10, n_informative=10, n_redundant=0, random_state=1)\n# define model\nmodel = Perceptron()\n# define model evaluation method\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n# evaluate model\nscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n# summarize result\nprint('Mean Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n```", "```py\n# MLP for Pima Indians Dataset with 10-fold cross validation via sklearn\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.datasets import load_diabetes\nimport numpy\n\n# Function to create model, required for KerasClassifier\ndef create_model():\n\t# create model\n\tmodel = Sequential()\n\tmodel.add(Dense(12, input_dim=8, activation='relu'))\n\tmodel.add(Dense(8, activation='relu'))\n\tmodel.add(Dense(1, activation='sigmoid'))\n\t# Compile model\n\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\treturn model\n\n# fix random seed for reproducibility\nseed = 7\nnumpy.random.seed(seed)\n# load pima indians dataset\ndataset = numpy.loadtxt(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv\", delimiter=\",\")\n# split into input (X) and output (Y) variables\nX = dataset[:,0:8]\nY = dataset[:,8]\n# create model\nmodel = KerasClassifier(build_fn=create_model, epochs=150, batch_size=10, verbose=0)\n# evaluate using 10-fold cross validation\nkfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\nresults = cross_val_score(model, X, Y, cv=kfold)\nprint(results.mean())\n```", "```py\nmodel = create_model()\n```", "```py\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nimport numpy as np\nimport pandas as pd\n\ndata = [266.0,145.9,183.1,119.3,180.3,168.5,231.8,224.5,192.8,122.9,336.5,185.9,\n        194.3,149.5,210.1,273.3,191.4,287.0,226.0,303.6,289.9,421.6,264.5,342.3,\n        339.7,440.4,315.9,439.3,401.3,437.4,575.5,407.6,682.0,475.3,581.3,646.9]\nmodel = SARIMAX(y, order=(5,1,0))\nres = model.fit(disp=False)\nprint(\"AIC = \", res.aic)\n\ndata = np.array(data)\nmodel = SARIMAX(y, order=(5,1,0))\nres = model.fit(disp=False)\nprint(\"AIC = \", res.aic)\n\ndata = pd.Series(data)\nmodel = SARIMAX(y, order=(5,1,0))\nres = model.fit(disp=False)\nprint(\"AIC = \", res.aic)\n```", "```py\nfrom math import sqrt\n\ndef quadratic(a,b,c):\n    discrim = b*b - 4*a*c\n    x = -b/(2*a)\n    y = sqrt(discrim)/(2*a)\n    return x-y, x+y\n```", "```py\na = 1\n\ndef f(x):\n    a = 2 * x\n    return a\n\nb = f(3)\nprint(a, b)\n```", "```py\n1 6\n```", "```py\na = 1\n\ndef f(x):\n    global a\n    a = 2 * x\n    return a\n\nb = f(3)\nprint(a, b)\n```", "```py\n6 6\n```", "```py\na = 1\n\ndef f(x):\n    a = x\n    def g(x):\n        return a * x\n    return g(3)\n\nb = f(2)\nprint(b)\n```", "```py\n6\n```", "```py\nimport numpy as np\n\ndef datagen(X, y, batch_size, sampling_rate=0.7):\n    \"\"\"A generator to produce samples from input numpy arrays X and y\n    \"\"\"\n    # Select rows from arrays X and y randomly\n    indexing = np.random.random(len(X)) < sampling_rate\n    Xsam, ysam = X[indexing], y[indexing]\n\n    # Actual logic to generate batches\n    def _gen(batch_size):\n        while True:\n            Xbatch, ybatch = [], []\n            for _ in range(batch_size):\n                i = np.random.randint(len(Xsam))\n                Xbatch.append(Xsam[i])\n                ybatch.append(ysam[i])\n            yield np.array(Xbatch), np.array(ybatch)\n\n    # Create and return a generator\n    return _gen(batch_size)\n```", "```py\nX = np.random.random((100,3))\ny = np.random.random(100)\n\ngen1 = datagen(X, y, 3)\ngen2 = datagen(X, y, 4)\nprint(next(gen1))\nprint(next(gen2))\n```", "```py\n(array([[0.89702235, 0.97516228, 0.08893787],\n       [0.26395301, 0.37674529, 0.1439478 ],\n       [0.24859104, 0.17448628, 0.41182877]]), array([0.2821138 , 0.87590954, 0.96646776]))\n(array([[0.62199772, 0.01442743, 0.4897467 ],\n       [0.41129379, 0.24600387, 0.53640666],\n       [0.02417213, 0.27637708, 0.65571031],\n       [0.15107433, 0.11331674, 0.67000849]]), array([0.91559533, 0.84886957, 0.30451455, 0.5144225 ]))\n```", "```py\nimport numpy as np\n\nX = np.random.random((100,3))\nprint(type(X))\nprint(isinstance(X, np.ndarray))\n```", "```py\n<class 'numpy.ndarray'>\nTrue\n```", "```py\nimport pandas as pd\nimport numpy as np\n\ndef datagen(X, y, batch_size, sampling_rate=0.7):\n    \"\"\"A generator to produce samples from input numpy arrays X and y\n    \"\"\"\n    # Select rows from arrays X and y randomly\n    indexing = np.random.random(len(X)) < sampling_rate\n    Xsam, ysam = X[indexing], y[indexing]\n\n    # Actual logic to generate batches\n    def _gen(batch_size):\n        while True:\n            Xbatch, ybatch = [], []\n            for _ in range(batch_size):\n                i = np.random.randint(len(Xsam))\n                Xbatch.append(Xsam[i])\n                ybatch.append(ysam[i])\n            yield np.array(Xbatch), np.array(ybatch)\n\n    # Create and return a generator\n    return _gen(batch_size)\n\nX = pd.DataFrame(np.random.random((100,3)))\ny = pd.DataFrame(np.random.random(100))\n\ngen3 = datagen(X, y, 3)\nprint(next(gen3))\n```", "```py\n> /Users/MLM/ducktype.py(1)<module>()\n-> import pandas as pd\n(Pdb) c\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.9/site-packages/pandas/core/indexes/range.py\", line 385, in get_loc\n    return self._range.index(new_key)\nValueError: 1 is not in range\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/usr/local/Cellar/python@3.9/3.9.9/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pdb.py\", line 1723, in main\n    pdb._runscript(mainpyfile)\n  File \"/usr/local/Cellar/python@3.9/3.9.9/Frameworks/Python.framework/Versions/3.9/lib/python3.9/pdb.py\", line 1583, in _runscript\n    self.run(statement)\n  File \"/usr/local/Cellar/python@3.9/3.9.9/Frameworks/Python.framework/Versions/3.9/lib/python3.9/bdb.py\", line 580, in run\n    exec(cmd, globals, locals)\n  File \"<string>\", line 1, in <module>\n  File \"/Users/MLM/ducktype.py\", line 1, in <module>\n    import pandas as pd\n  File \"/Users/MLM/ducktype.py\", line 18, in _gen\n    ybatch.append(ysam[i])\n  File \"/usr/local/lib/python3.9/site-packages/pandas/core/frame.py\", line 3458, in __getitem__\n    indexer = self.columns.get_loc(key)\n  File \"/usr/local/lib/python3.9/site-packages/pandas/core/indexes/range.py\", line 387, in get_loc\n    raise KeyError(key) from err\nKeyError: 1\nUncaught exception. Entering post mortem debugging\nRunning 'cont' or 'step' will restart the program\n> /usr/local/lib/python3.9/site-packages/pandas/core/indexes/range.py(387)get_loc()\n-> raise KeyError(key) from err\n(Pdb)\n```", "```py\n(Pdb) up\n> /usr/local/lib/python3.9/site-packages/pandas/core/frame.py(3458)__getitem__()\n-> indexer = self.columns.get_loc(key)\n(Pdb) up\n> /Users/MLM/ducktype.py(18)_gen()\n-> ybatch.append(ysam[i])\n(Pdb) type(ysam)\n<class 'pandas.core.frame.DataFrame'>\n```", "```py\n(Pdb) dir(ysam)\n['T', '_AXIS_LEN', '_AXIS_ORDERS', '_AXIS_REVERSED', '_AXIS_TO_AXIS_NUMBER', \n...\n'iat', 'idxmax', 'idxmin', 'iloc', 'index', 'infer_objects', 'info', 'insert',\n'interpolate', 'isin', 'isna', 'isnull', 'items', 'iteritems', 'iterrows',\n'itertuples', 'join', 'keys', 'kurt', 'kurtosis', 'last', 'last_valid_index',\n...\n'transform', 'transpose', 'truediv', 'truncate', 'tz_convert', 'tz_localize',\n'unstack', 'update', 'value_counts', 'values', 'var', 'where', 'xs']\n(Pdb)\n```", "```py\n(Pdb) ysam.iloc[i]\n0    0.83794\nName: 2, dtype: float64\n(Pdb)\n```", "```py\n(Pdb) dir()\n['Xbatch', 'Xsam', '_', 'batch_size', 'i', 'ybatch', 'ysam']\n(Pdb) up\n> /Users/MLM/ducktype.py(1)<module>()\n-> import pandas as pd\n(Pdb) dir()\n['X', '__builtins__', '__file__', '__name__', 'datagen', 'gen3', 'np', 'pd', 'y']\n(Pdb)\n```", "```py\n(Pdb) locals()\n{'batch_size': 3, 'Xbatch': ...,\n 'ybatch': ..., '_': 0, 'i': 1, 'Xsam': ...,\n 'ysam': ...}\n(Pdb)\n```", "```py\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense\n\nmodel = Sequential([\n    Dense(5, input_shape=(3,)),\n    Dense(1)\n])\n\nhas_loss = \"loss\" in dir(model)\nprint(\"Before compile, loss function defined:\", has_loss)\n\nmodel.compile()\nhas_loss = \"loss\" in dir(model)\nprint(\"After compile, loss function defined:\", has_loss)\n```", "```py\nBefore compile, loss function defined: False\nAfter compile, loss function defined: True\n```"]