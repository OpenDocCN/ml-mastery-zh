- en: Generate Realistic Faces in Stable Diffusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://machinelearningmastery.com/generate-realistic-faces/](https://machinelearningmastery.com/generate-realistic-faces/)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Stable Diffusion’s latest models are very good at generating hyper-realistic
    images, but they can struggle with accurately generating human faces. We can experiment
    with prompts, but to get seamless, photorealistic results for faces, we may need
    to try new methodologies and models.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this post, we will explore various techniques and models for generating
    highly realistic human faces with Stable Diffusion. Specifically, we will learn
    how to:'
  prefs: []
  type: TYPE_NORMAL
- en: Generate realistic images using WebUI and advanced settings.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use Stable Diffusion XL for photorealistic results.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Download and use a fine-tuned model trained on high quality images.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Kick-start your project** with my book [Mastering Digital Art with Stable
    Diffusion](https://machinelearningmastery.com/mastering-digital-art-with-stable-diffusion/).
    It provides **self-study tutorials** with **working code**.'
  prefs: []
  type: TYPE_NORMAL
- en: Let’s get started.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/745f6e92d71b5e9b88d286762a23c121.png)'
  prefs: []
  type: TYPE_IMG
- en: Generate Realistic  Faces in Stable Diffusion
  prefs: []
  type: TYPE_NORMAL
- en: Photo by [Amanda Dalbjörn](https://unsplash.com/photos/close-up-photo-of-persons-eye-fvInY-Gh7sc).
    Some rights reserved.
  prefs: []
  type: TYPE_NORMAL
- en: Overview
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This post is in three parts; they are:'
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Portrait Using Web UI
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a Portrait with Stable Diffusion XL
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Using CivitAI Models Checkpoint
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Creating a Portrait Using Web UI
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s start with simple prompt engineering on Stable Diffusion 1.5 using Stable
    Diffusion WebUI locally. You need to work on positive prompt, negative prompt,
    and advanced settings to get improved results. For example,
  prefs: []
  type: TYPE_NORMAL
- en: 'Positive prompt: “photo of young woman, highlight hair, sitting outside restaurant,
    wearing dress, rim lighting, studio lighting, looking at the camera, up close,
    perfect eyes”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Negative prompt: “disfigured, ugly, bad, immature, cartoon, anime, 3d, painting,
    b&w, double images”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sampler: DPM++ 2M Karras'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Steps: 30'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'CFG scale: 7'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Size: 912×512 (wide)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When creating a negative prompt, you need to focus on describing a “disfigured
    face” and seeing “double images”. This is especially important in Stable Diffusion
    1.5 models. You can include additional keywords if you notice a recurring pattern,
    such as misaligned eyes. In order to address this issue, you can add “perfect
    eyes” to your positive prompt and “disfigured eyes” to your negative prompt.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/bbd97b5e14e3898b1ea0f62c4b9439a8.png)'
  prefs: []
  type: TYPE_IMG
- en: A portrait created using Stable Diffusion 1.5 model
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, we got very good results on the first try. If you got a distorted
    or double image, try generating the image again. This model is not perfect and
    may occasionally generate incorrect images. So if that happens, simply generate
    a new image. You may also try to adjust the parameters such as sampling method,
    steps, and random seed. As a final resort, changing the model checkpoint also
    helps.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f6b8a9f310880e1f56bd2229b1cd3500.png)'
  prefs: []
  type: TYPE_IMG
- en: Different portraits generated by adjusting the input to Stable Diffusion
  prefs: []
  type: TYPE_NORMAL
- en: After modifying various keywords to produce diverse variations of realistic
    images, we achieved satisfactory outcomes even with the base model.
  prefs: []
  type: TYPE_NORMAL
- en: Creating a Portrait with Stable Diffusion XL
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The most common Stable Diffusion model is version 1.5, released in October 2022\.
    Then there is version 2.0, which is a similar architecture but retrained from
    scratch, released in November of the same year. Stable Diffusion XL (SDXL), that
    released in July 2023, is a different architecture and much bigger. All three
    versions have different heritages and behave differently to your prompt. It is
    generally believed that SDXL produce better pictures.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s use the latest model Stable Diffusion XL (SDXL) to get even better image
    generation results. This can be as simple as downloading the model checkpoint
    file and save it to your `stable-diffusion-webui/models/Stable-diffusion` folder
    of your Web UI, restart the Web UI, and repeat the steps in the previous section.
    Running the full model locally can require a significant amount of GPU memory.
    If you cannot meet its technical requirement, a good option is to use the free
    online demos available on Hugging Face Spaces.
  prefs: []
  type: TYPE_NORMAL
- en: You can access these applications by visiting [https://hf.co/spaces](https://hf.co/spaces)
    and searching for “SDXL”.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/4db53f3571a8384251d963b4a5cfdca6.png)'
  prefs: []
  type: TYPE_IMG
- en: Searching “SDXL” on Hugging Face space
  prefs: []
  type: TYPE_NORMAL
- en: Stable Diffusion XL by Google
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We will first try the fastest demo running on TPU version 5e to obtain our
    results, located at:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://hf.co/spaces/google/sdxl](https://hf.co/spaces/google/sdxl)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To ensure that our images are generated accurately, it is important to set up
    the negative prompt and image style to “Photographic” by going to the Advanced
    settings.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/586af82f0b9bd55186b1f1f34971d3d0.png)'
  prefs: []
  type: TYPE_IMG
- en: Setting “Photographic” in Advanced settings to fix the style of generated image
  prefs: []
  type: TYPE_NORMAL
- en: 'We will use the same prompt to generate a realistic image of the young girl
    sitting outside the restaurant:'
  prefs: []
  type: TYPE_NORMAL
- en: photo of young woman, highlight hair, sitting outside restaurant, wearing dress,
    rim lighting, studio lighting, looking at the camera, up close, perfect eyes
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '![](../Images/00f18271f8b276ffdb5774ffdb31d3cf.png)'
  prefs: []
  type: TYPE_IMG
- en: Generating pictures with SDXL
  prefs: []
  type: TYPE_NORMAL
- en: The results are impressive. The rendering of the eyes, nose, lips, shadows,
    and colors looks very realistic. By comparing the generated result here against
    the previous section, you can see the obvious difference between SDXL and its
    older version.
  prefs: []
  type: TYPE_NORMAL
- en: Fast Stable Diffusion XL by Prodia
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are more than one SDXL in Hugging Face Space. If you are used to the
    Stable Diffusion WebUI user interface then “Fast Stable Diffusion XL” Space is
    for you:'
  prefs: []
  type: TYPE_NORMAL
- en: '[https://hf.co/spaces/prodia/sdx](https://hf.co/spaces/prodia/sdx)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will write the same positive and negative prompts to generate the results.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/24a0e666899c6ad26c242d2afe8127cd.png)'
  prefs: []
  type: TYPE_IMG
- en: Fast Stable Diffusion XL by Prodia on Hugging Face Space
  prefs: []
  type: TYPE_NORMAL
- en: We got even better shadows and clarity in this. Let’s try to generate more images
    so that we can draw conclusions about our results.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s modify the prompt to generate an image of a man and a woman.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/228cc259946a7cb2a5237bb0e5294dd6.png)'
  prefs: []
  type: TYPE_IMG
- en: Portrait of a man and a woman generated with SDXL
  prefs: []
  type: TYPE_NORMAL
- en: The results are exceptional for generating characters of both genders and races.
    To test for model bias, we will generate characters of Indian descent and change
    the setting to a hospital, where both characters will be doctors.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/f21fd704e2ead6dc05a0b87e2299d570.png)'
  prefs: []
  type: TYPE_IMG
- en: Images of a woman and a man dressed as doctors, as generated by SDXL
  prefs: []
  type: TYPE_NORMAL
- en: SDXL has generated good results, but the images appear too smooth, as if an
    Instagram filter was applied. Realistic images have acne, marks, roughness, and
    sharpness that SDXL is missing. This can be difficult to achieve in the original
    SDXL model but resolvable if you switch to another checkpoint.
  prefs: []
  type: TYPE_NORMAL
- en: Using CivitAI Models Checkpoint
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will step ahead and generate even more realistic faces than
    SDXL using [CivitAI.com](https://civitai.com/). It is a model hosting platform
    that allows users upload and download specialized versions of Stable Diffusion
    models. It is also a gallery for users to post their work of AI-generated pictures.
  prefs: []
  type: TYPE_NORMAL
- en: In our case, we are interested in the best photorealistic model. To download
    that we will search for the keyword “**photorealistic**”. There will be a lot.
    The most popular ones are probably the best. Therefore, ensure you have set the
    filters to get the list sorted by the most downloaded models of all time.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1039361082645ae98b6e56272c719180.png)'
  prefs: []
  type: TYPE_IMG
- en: Searching for a model on CivitAI.com, setting the result to sort by “most downloaded”
    and “all time” would be helpful to find a quality model.
  prefs: []
  type: TYPE_NORMAL
- en: Select the most popular model and download the full version as shown (named
    “Realisic Vision V5.1” in this case, as depicted).
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/04d176d357ae4a13b2dc2abd90508bdb.png)'
  prefs: []
  type: TYPE_IMG
- en: Downloading model checkpoint “Realistic Vision V5.1” (beware not the inpainting
    version) from Civitai.com
  prefs: []
  type: TYPE_NORMAL
- en: After that, move the downloaded model to the Stable Diffusion WebUI model directory
    `stable-diffusion-webui/models/Stable-diffusion`. To activate the model on Web
    UI click on the refresh button and select the newer model by clicking on the drop
    down panel, or simply restart the Web UI.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/1a25de4233330060a0265f9d51d62629.png)'
  prefs: []
  type: TYPE_IMG
- en: Selecting the model checkpoint at the top left corner of Web UI.
  prefs: []
  type: TYPE_NORMAL
- en: All the information regarding the positive prompt, negative prompt, and advanced
    setting is mentioned on the model page. Therefore, we will use that information
    and modify it to generate an image of a young woman.
  prefs: []
  type: TYPE_NORMAL
- en: 'Positive prompt: “RAW photo, face portrait photo of beautiful 24 y.o woman,
    full lips, brown eyes, glasses, hard shadows, 8k uhd, dslr, soft lighting, high
    quality, film grain, Fujifilm XT3”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Negative prompt: “deformed iris, deformed pupils, semi-realistic, cgi, 3d,
    render, sketch, cartoon, drawing, anime, mutated hands and fingers, deformed,
    distorted, disfigured, poorly drawn, bad anatomy, wrong anatomy, extra limb, missing
    limb, floating limbs, disconnected limbs, mutation, mutated, ugly, disgusting,
    amputation”'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sampler: DPM++ SDE Karras'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Steps: 25'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'CFG scale: 7'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Size: 912×512'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![](../Images/b42e78401976ef5bc370e833b294acf3.png)'
  prefs: []
  type: TYPE_IMG
- en: Portrait as generated using the Realisitic Vision checkpoint on Web UI
  prefs: []
  type: TYPE_NORMAL
- en: We got a sharp and accurate image of the face. Let’s experiment with different
    prompts to generate even more realistic faces.
  prefs: []
  type: TYPE_NORMAL
- en: We will begin with an image of a man and woman without glasses.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/2dc7d32e5e9ee224032270478d655d8a.png)'
  prefs: []
  type: TYPE_IMG
- en: Man and woman without glasses. Images generated using the Realistic Vision model
    checkpoint.
  prefs: []
  type: TYPE_NORMAL
- en: Then, we will modify the prompt to generate an Indian man and woman.
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/c468002cda7253d758a63c695a5edee8.png)'
  prefs: []
  type: TYPE_IMG
- en: Indian man and woman. Images generated using the Realistic Vision model checkpoint.
  prefs: []
  type: TYPE_NORMAL
- en: Don’t you see the difference? We have achieved an excellent result. There is
    good texture on the face, natural-looking skin marks, and clarity in the details
    of the face.
  prefs: []
  type: TYPE_NORMAL
- en: Further Readings
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'You can learn more about this topic using the following resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Stable Diffusion 1 vs 2 – What you need to know](https://www.assemblyai.com/blog/stable-diffusion-1-vs-2-what-you-need-to-know/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Best AI Diffusion Models: A Comprehensive Comparison and Guide](https://www.ikomia.ai/blog/best-ai-diffusion-models-comparison-guide)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this post, we explored various methods for generating hyper-realistic and
    consistent faces using Stable Diffusion. We started with simple techniques and
    progressed to more advanced methods for producing highly realistic images. Specifically,
    we covered:'
  prefs: []
  type: TYPE_NORMAL
- en: How to generate realistic faces using Stable Difusion 1.5 with negative prompts
    and advanced settings.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: How to create lifelike photos with Stable Diffusion XL using Hugging Face Spaces’
    free demos.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Used a specialized model that was fine-tuned on high-quality images to get perfect
    photos with skin texture and facial clarity.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
