["```py\npip install git+https://github.com/huggingface/diffusers\npip install accelerate wand\npip install -r https://raw.githubusercontent.com/huggingface/diffusers/main/examples/text_to_image/requirements.txt\n\naccelerate config default\n# accelerate configuration saved at $HOME/.cache/huggingface/accelerate/default_config.yaml\n```", "```py\nimport wandb\nimport torch\nfrom diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler, AutoPipelineForText2Image\nfrom huggingface_hub import model_info\n```", "```py\nwget -q https://raw.githubusercontent.com/huggingface/diffusers/main/examples/text_to_image/train_text_to_image_lora.py\n```", "```py\nexport MODEL_NAME=\"runwayml/stable-diffusion-v1-5\"\nexport OUTPUT_DIR=\"./finetune_lora/pokemon\"\nexport HUB_MODEL_ID=\"pokemon-lora\"\nexport DATASET_NAME=\"svjack/pokemon-blip-captions-en-zh\"\n\nmkdir -p $OUTPUT_DIR\n\naccelerate launch --mixed_precision=\"bf16\"  train_text_to_image_lora.py \\\n  --pretrained_model_name_or_path=$MODEL_NAME \\\n  --dataset_name=$DATASET_NAME \\\n  --dataloader_num_workers=8 \\\n  --resolution=512 \\\n  --center_crop \\\n  --random_flip \\\n  --train_batch_size=1 \\\n  --gradient_accumulation_steps=4 \\\n  --max_train_steps=15000 \\\n  --learning_rate=1e-04 \\\n  --max_grad_norm=1 \\\n  --lr_scheduler=\"cosine\" \\\n  --lr_warmup_steps=0 \\\n  --output_dir=${OUTPUT_DIR} \\\n  --checkpointing_steps=500 \\\n  --caption_column=\"en_text\" \\\n  --validation_prompt=\"A pokemon with blue eyes.\" \\\n  --seed=1337\n```", "```py\nfile_name,caption\nimage_0.png,a drawing of a green pokemon with red eyes\nimage_1.png,a green and yellow toy with a red nose\nimage_2.png,a red and white ball with an angry look on its face\n...\n```", "```py\nfrom diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\nfrom huggingface_hub import model_info\nimport torch\n\n# LoRA weights ~3 MB\nmodel_path = \"pcuenq/pokemon-lora\"\n\ninfo = model_info(model_path)\nmodel_base = info.cardData[\"base_model\"]\npipe = StableDiffusionPipeline.from_pretrained(model_base, torch_dtype=torch.float16)\npipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n\npipe.unet.load_attn_procs(model_path)\npipe.to(\"cuda\")\n\nimage = pipe(\"Green pokemon with menacing face\", num_inference_steps=25).images[0]\nimage.save(\"green_pokemon.png\")\n```", "```py\nfrom diffusers import AutoPipelineForText2Image\nimport torch\n\npipeline = AutoPipelineForText2Image.from_pretrained(\"runwayml/stable-diffusion-v1-5\",\n                                                     torch_dtype=torch.float16\n                                                    ).to(\"cuda\")\npipeline.load_lora_weights(\"finetune_lora/pokemon\",\n                           weight_name=\"pytorch_lora_weights.safetensors\")\nimage = pipeline(\"A pokemon with blue eyes\").images[0]\n```"]