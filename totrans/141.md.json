["```py\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n```", "```py\n6,148,72,35,0,33.6,0.627,50,1\n1,85,66,29,0,26.6,0.351,31,0\n8,183,64,0,0,23.3,0.672,32,1\n1,89,66,23,94,28.1,0.167,21,0\n0,137,40,35,168,43.1,2.288,33,1\n...\n```", "```py\n...\n\n# load the dataset, split into input (X) and output (y) variables\ndataset = np.loadtxt('pima-indians-diabetes.csv', delimiter=',')\nX = dataset[:,0:8]\ny = dataset[:,8]\n```", "```py\nX = torch.tensor(X, dtype=torch.float32)\ny = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n```", "```py\n...\n\nmodel = nn.Sequential(\n    nn.Linear(8, 12),\n    nn.ReLU(),\n    nn.Linear(12, 8),\n    nn.ReLU(),\n    nn.Linear(8, 1),\n    nn.Sigmoid()\n```", "```py\nprint(model)\n```", "```py\nSequential(\n  (0): Linear(in_features=8, out_features=12, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=12, out_features=8, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=8, out_features=1, bias=True)\n  (5): Sigmoid()\n)\n```", "```py\n...\n\nclass PimaClassifier(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.hidden1 = nn.Linear(8, 12)\n        self.act1 = nn.ReLU()\n        self.hidden2 = nn.Linear(12, 8)\n        self.act2 = nn.ReLU()\n        self.output = nn.Linear(8, 1)\n        self.act_output = nn.Sigmoid()\n\n    def forward(self, x):\n        x = self.act1(self.hidden1(x))\n        x = self.act2(self.hidden2(x))\n        x = self.act_output(self.output(x))\n        return x\n\nmodel = PimaClassifier()\nprint(model)\n```", "```py\nPimaClassifier(\n  (hidden1): Linear(in_features=8, out_features=12, bias=True)\n  (act1): ReLU()\n  (hidden2): Linear(in_features=12, out_features=8, bias=True)\n  (act2): ReLU()\n  (output): Linear(in_features=8, out_features=1, bias=True)\n  (act_output): Sigmoid()\n)\n```", "```py\nloss_fn = nn.BCELoss()  # binary cross entropy\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n```", "```py\nn_epochs = 100\nbatch_size = 10\n\nfor epoch in range(n_epochs):\n    for i in range(0, len(X), batch_size):\n        Xbatch = X[i:i+batch_size]\n        y_pred = model(Xbatch)\n        ybatch = y[i:i+batch_size]\n        loss = loss_fn(y_pred, ybatch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    print(f'Finished epoch {epoch}, latest loss {loss}')\n```", "```py\nFinished epoch 0, latest loss 0.6271069645881653\nFinished epoch 1, latest loss 0.6056771874427795\nFinished epoch 2, latest loss 0.5916517972946167\nFinished epoch 3, latest loss 0.5822567939758301\nFinished epoch 4, latest loss 0.5682642459869385\nFinished epoch 5, latest loss 0.5640913248062134\n...\n```", "```py\n# compute accuracy (no_grad is optional)\nwith torch.no_grad():\n    y_pred = model(X)\n\naccuracy = (y_pred.round() == y).float().mean()\nprint(f\"Accuracy {accuracy}\")\n```", "```py\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# load the dataset, split into input (X) and output (y) variables\ndataset = np.loadtxt('pima-indians-diabetes.csv', delimiter=',')\nX = dataset[:,0:8]\ny = dataset[:,8]\n\nX = torch.tensor(X, dtype=torch.float32)\ny = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n\n# define the model\nmodel = nn.Sequential(\n    nn.Linear(8, 12),\n    nn.ReLU(),\n    nn.Linear(12, 8),\n    nn.ReLU(),\n    nn.Linear(8, 1),\n    nn.Sigmoid()\n)\nprint(model)\n\n# train the model\nloss_fn   = nn.BCELoss()  # binary cross entropy\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\nn_epochs = 100\nbatch_size = 10\n\nfor epoch in range(n_epochs):\n    for i in range(0, len(X), batch_size):\n        Xbatch = X[i:i+batch_size]\n        y_pred = model(Xbatch)\n        ybatch = y[i:i+batch_size]\n        loss = loss_fn(y_pred, ybatch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    print(f'Finished epoch {epoch}, latest loss {loss}')\n\n# compute accuracy (no_grad is optional)\nwith torch.no_grad():\n    y_pred = model(X)\naccuracy = (y_pred.round() == y).float().mean()\nprint(f\"Accuracy {accuracy}\")\n```", "```py\nAccuracy: 0.7604166865348816\nAccuracy: 0.7838541865348816\nAccuracy: 0.7669270634651184\nAccuracy: 0.7721354365348816\nAccuracy: 0.7669270634651184\n```", "```py\n...\n\n# make probability predictions with the model\npredictions = model(X)\n# round predictions\nrounded = predictions.round()\n```", "```py\n...\n# make class predictions with the model\npredictions = (model(X) > 0.5).int()\n```", "```py\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\n# load the dataset, split into input (X) and output (y) variables\ndataset = np.loadtxt('pima-indians-diabetes.csv', delimiter=',')\nX = dataset[:,0:8]\ny = dataset[:,8]\n\nX = torch.tensor(X, dtype=torch.float32)\ny = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n\n# define the model\nclass PimaClassifier(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.hidden1 = nn.Linear(8, 12)\n        self.act1 = nn.ReLU()\n        self.hidden2 = nn.Linear(12, 8)\n        self.act2 = nn.ReLU()\n        self.output = nn.Linear(8, 1)\n        self.act_output = nn.Sigmoid()\n\n    def forward(self, x):\n        x = self.act1(self.hidden1(x))\n        x = self.act2(self.hidden2(x))\n        x = self.act_output(self.output(x))\n        return x\n\nmodel = PimaClassifier()\nprint(model)\n\n# train the model\nloss_fn   = nn.BCELoss()  # binary cross entropy\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\nn_epochs = 100\nbatch_size = 10\n\nfor epoch in range(n_epochs):\n    for i in range(0, len(X), batch_size):\n        Xbatch = X[i:i+batch_size]\n        y_pred = model(Xbatch)\n        ybatch = y[i:i+batch_size]\n        loss = loss_fn(y_pred, ybatch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n# compute accuracy\ny_pred = model(X)\naccuracy = (y_pred.round() == y).float().mean()\nprint(f\"Accuracy {accuracy}\")\n\n# make class predictions with the model\npredictions = (model(X) > 0.5).int()\nfor i in range(5):\n    print('%s => %d (expected %d)' % (X[i].tolist(), predictions[i], y[i]))\n```", "```py\n[6.0, 148.0, 72.0, 35.0, 0.0, 33.599998474121094, 0.6269999742507935, 50.0] => 1 (expected 1)\n[1.0, 85.0, 66.0, 29.0, 0.0, 26.600000381469727, 0.35100001096725464, 31.0] => 0 (expected 0)\n[8.0, 183.0, 64.0, 0.0, 0.0, 23.299999237060547, 0.671999990940094, 32.0] => 1 (expected 1)\n[1.0, 89.0, 66.0, 23.0, 94.0, 28.100000381469727, 0.16699999570846558, 21.0] => 0 (expected 0)\n[0.0, 137.0, 40.0, 35.0, 168.0, 43.099998474121094, 2.2880001068115234, 33.0] => 1 (expected 1)\n```"]