["```py\nfrom multihead_attention import MultiHeadAttention\nfrom encoder import AddNormalization, FeedForward\n\nclass DecoderLayer(Layer):\n    def __init__(self, h, d_k, d_v, d_model, d_ff, rate, **kwargs):\n        super(DecoderLayer, self).__init__(**kwargs)\n        self.multihead_attention1 = MultiHeadAttention(h, d_k, d_v, d_model)\n        self.dropout1 = Dropout(rate)\n        self.add_norm1 = AddNormalization()\n        self.multihead_attention2 = MultiHeadAttention(h, d_k, d_v, d_model)\n        self.dropout2 = Dropout(rate)\n        self.add_norm2 = AddNormalization()\n        self.feed_forward = FeedForward(d_ff, d_model)\n        self.dropout3 = Dropout(rate)\n        self.add_norm3 = AddNormalization()\n        ...\n```", "```py\n...\ndef call(self, x, encoder_output, lookahead_mask, padding_mask, training):\n    # Multi-head attention layer\n    multihead_output1 = self.multihead_attention1(x, x, x, lookahead_mask)\n    # Expected output shape = (batch_size, sequence_length, d_model)\n\n    # Add in a dropout layer\n    multihead_output1 = self.dropout1(multihead_output1, training=training)\n\n    # Followed by an Add & Norm layer\n    addnorm_output1 = self.add_norm1(x, multihead_output1)\n    # Expected output shape = (batch_size, sequence_length, d_model)\n\n    # Followed by another multi-head attention layer\n    multihead_output2 = self.multihead_attention2(addnorm_output1, encoder_output, encoder_output, padding_mask)\n\n    # Add in another dropout layer\n    multihead_output2 = self.dropout2(multihead_output2, training=training)\n\n    # Followed by another Add & Norm layer\n    addnorm_output2 = self.add_norm1(addnorm_output1, multihead_output2)\n\n    # Followed by a fully connected layer\n    feedforward_output = self.feed_forward(addnorm_output2)\n    # Expected output shape = (batch_size, sequence_length, d_model)\n\n    # Add in another dropout layer\n    feedforward_output = self.dropout3(feedforward_output, training=training)\n\n    # Followed by another Add & Norm layer\n    return self.add_norm3(addnorm_output2, feedforward_output)\n```", "```py\nfrom positional_encoding import PositionEmbeddingFixedWeights\n\nclass Decoder(Layer):\n    def __init__(self, vocab_size, sequence_length, h, d_k, d_v, d_model, d_ff, n, rate, **kwargs):\n        super(Decoder, self).__init__(**kwargs)\n        self.pos_encoding = PositionEmbeddingFixedWeights(sequence_length, vocab_size, d_model)\n        self.dropout = Dropout(rate)\n        self.decoder_layer = [DecoderLayer(h, d_k, d_v, d_model, d_ff, rate) for _ in range(n)\n        ...\n```", "```py\n...\ndef call(self, output_target, encoder_output, lookahead_mask, padding_mask, training):\n    # Generate the positional encoding\n    pos_encoding_output = self.pos_encoding(output_target)\n    # Expected output shape = (number of sentences, sequence_length, d_model)\n\n    # Add in a dropout layer\n    x = self.dropout(pos_encoding_output, training=training)\n\n    # Pass on the positional encoded values to each encoder layer\n    for i, layer in enumerate(self.decoder_layer):\n        x = layer(x, encoder_output, lookahead_mask, padding_mask, training)\n\n    return x\n```", "```py\nfrom tensorflow.keras.layers import Layer, Dropout\nfrom multihead_attention import MultiHeadAttention\nfrom positional_encoding import PositionEmbeddingFixedWeights\nfrom encoder import AddNormalization, FeedForward\n\n# Implementing the Decoder Layer\nclass DecoderLayer(Layer):\n    def __init__(self, h, d_k, d_v, d_model, d_ff, rate, **kwargs):\n        super(DecoderLayer, self).__init__(**kwargs)\n        self.multihead_attention1 = MultiHeadAttention(h, d_k, d_v, d_model)\n        self.dropout1 = Dropout(rate)\n        self.add_norm1 = AddNormalization()\n        self.multihead_attention2 = MultiHeadAttention(h, d_k, d_v, d_model)\n        self.dropout2 = Dropout(rate)\n        self.add_norm2 = AddNormalization()\n        self.feed_forward = FeedForward(d_ff, d_model)\n        self.dropout3 = Dropout(rate)\n        self.add_norm3 = AddNormalization()\n\n    def call(self, x, encoder_output, lookahead_mask, padding_mask, training):\n        # Multi-head attention layer\n        multihead_output1 = self.multihead_attention1(x, x, x, lookahead_mask)\n        # Expected output shape = (batch_size, sequence_length, d_model)\n\n        # Add in a dropout layer\n        multihead_output1 = self.dropout1(multihead_output1, training=training)\n\n        # Followed by an Add & Norm layer\n        addnorm_output1 = self.add_norm1(x, multihead_output1)\n        # Expected output shape = (batch_size, sequence_length, d_model)\n\n        # Followed by another multi-head attention layer\n        multihead_output2 = self.multihead_attention2(addnorm_output1, encoder_output, encoder_output, padding_mask)\n\n        # Add in another dropout layer\n        multihead_output2 = self.dropout2(multihead_output2, training=training)\n\n        # Followed by another Add & Norm layer\n        addnorm_output2 = self.add_norm1(addnorm_output1, multihead_output2)\n\n        # Followed by a fully connected layer\n        feedforward_output = self.feed_forward(addnorm_output2)\n        # Expected output shape = (batch_size, sequence_length, d_model)\n\n        # Add in another dropout layer\n        feedforward_output = self.dropout3(feedforward_output, training=training)\n\n        # Followed by another Add & Norm layer\n        return self.add_norm3(addnorm_output2, feedforward_output)\n\n# Implementing the Decoder\nclass Decoder(Layer):\n    def __init__(self, vocab_size, sequence_length, h, d_k, d_v, d_model, d_ff, n, rate, **kwargs):\n        super(Decoder, self).__init__(**kwargs)\n        self.pos_encoding = PositionEmbeddingFixedWeights(sequence_length, vocab_size, d_model)\n        self.dropout = Dropout(rate)\n        self.decoder_layer = [DecoderLayer(h, d_k, d_v, d_model, d_ff, rate) for _ in range(n)]\n\n    def call(self, output_target, encoder_output, lookahead_mask, padding_mask, training):\n        # Generate the positional encoding\n        pos_encoding_output = self.pos_encoding(output_target)\n        # Expected output shape = (number of sentences, sequence_length, d_model)\n\n        # Add in a dropout layer\n        x = self.dropout(pos_encoding_output, training=training)\n\n        # Pass on the positional encoded values to each encoder layer\n        for i, layer in enumerate(self.decoder_layer):\n            x = layer(x, encoder_output, lookahead_mask, padding_mask, training)\n\n        return x\n```", "```py\nh = 8  # Number of self-attention heads\nd_k = 64  # Dimensionality of the linearly projected queries and keys\nd_v = 64  # Dimensionality of the linearly projected values\nd_ff = 2048  # Dimensionality of the inner fully connected layer\nd_model = 512  # Dimensionality of the model sub-layers' outputs\nn = 6  # Number of layers in the encoder stack\n\nbatch_size = 64  # Batch size from the training process\ndropout_rate = 0.1  # Frequency of dropping the input units in the dropout layers\n...\n```", "```py\n...\ndec_vocab_size = 20 # Vocabulary size for the decoder\ninput_seq_length = 5  # Maximum length of the input sequence\n\ninput_seq = random.random((batch_size, input_seq_length))\nenc_output = random.random((batch_size, input_seq_length, d_model))\n...\n```", "```py\n...\ndecoder = Decoder(dec_vocab_size, input_seq_length, h, d_k, d_v, d_model, d_ff, n, dropout_rate)\nprint(decoder(input_seq, enc_output, None, True)\n```", "```py\nfrom numpy import random\n\ndec_vocab_size = 20  # Vocabulary size for the decoder\ninput_seq_length = 5  # Maximum length of the input sequence\nh = 8  # Number of self-attention heads\nd_k = 64  # Dimensionality of the linearly projected queries and keys\nd_v = 64  # Dimensionality of the linearly projected values\nd_ff = 2048  # Dimensionality of the inner fully connected layer\nd_model = 512  # Dimensionality of the model sub-layers' outputs\nn = 6  # Number of layers in the decoder stack\n\nbatch_size = 64  # Batch size from the training process\ndropout_rate = 0.1  # Frequency of dropping the input units in the dropout layers\n\ninput_seq = random.random((batch_size, input_seq_length))\nenc_output = random.random((batch_size, input_seq_length, d_model))\n\ndecoder = Decoder(dec_vocab_size, input_seq_length, h, d_k, d_v, d_model, d_ff, n, dropout_rate)\nprint(decoder(input_seq, enc_output, None, True))\n```", "```py\ntf.Tensor(\n[[[-0.04132953 -1.7236308   0.5391184  ... -0.76394725  1.4969798\n    0.37682498]\n  [ 0.05501875 -1.7523409   0.58404493 ... -0.70776534  1.4498456\n    0.32555297]\n  [ 0.04983566 -1.8431275   0.55850077 ... -0.68202156  1.4222856\n    0.32104644]\n  [-0.05684051 -1.8862512   0.4771412  ... -0.7101341   1.431343\n    0.39346313]\n  [-0.15625843 -1.7992781   0.40803364 ... -0.75190556  1.4602519\n    0.53546077]]\n...\n\n [[-0.58847624 -1.646842    0.5973466  ... -0.47778523  1.2060764\n    0.34091905]\n  [-0.48688865 -1.6809179   0.6493542  ... -0.41274604  1.188649\n    0.27100053]\n  [-0.49568555 -1.8002801   0.61536175 ... -0.38540334  1.2023914\n    0.24383534]\n  [-0.59913146 -1.8598882   0.5098136  ... -0.3984461   1.2115746\n    0.3186561 ]\n  [-0.71045107 -1.7778647   0.43008155 ... -0.42037937  1.2255307\n    0.47380894]]], shape=(64, 5, 512), dtype=float32)\n```"]