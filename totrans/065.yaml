- en: Support Vector Machines in OpenCV
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: OpenCV中的支持向量机
- en: 原文：[https://machinelearningmastery.com/support-vector-machines-in-opencv/](https://machinelearningmastery.com/support-vector-machines-in-opencv/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://machinelearningmastery.com/support-vector-machines-in-opencv/](https://machinelearningmastery.com/support-vector-machines-in-opencv/)
- en: The Support Vector Machine algorithm is one of the most popular supervised machine
    learning techniques, and it is implemented in the OpenCV library.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机算法是最受欢迎的监督学习技术之一，并且它在OpenCV库中得到了实现。
- en: This tutorial will introduce the necessary skills to start using Support Vector
    Machines in OpenCV, using a custom dataset we will generate. In a subsequent tutorial,
    we will then apply these skills for the specific applications of image classification
    and detection.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程将介绍开始使用OpenCV中支持向量机所需的技能，我们将使用自定义数据集生成。在随后的教程中，我们将应用这些技能于图像分类和检测的具体应用。
- en: In this tutorial, you will learn how to apply OpenCV’s Support Vector Machine
    algorithm on a custom two-dimensional dataset.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，你将学习如何在自定义二维数据集上应用OpenCV的支持向量机算法。
- en: 'After completing this tutorial, you will know:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 完成本教程后，你将了解：
- en: Several of the most important characteristics of Support Vector Machines.
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量机的一些最重要的特征。
- en: How to use the Support Vector Machine algorithm on a custom dataset in OpenCV.
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在OpenCV中使用支持向量机算法处理自定义数据集。
- en: '**Kick-start your project** with my book [Machine Learning in OpenCV](https://machinelearning.samcart.com/products/machine-learning-opencv/).
    It provides **self-study tutorials** with **working code**.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '**通过我的书[《OpenCV中的机器学习》](https://machinelearning.samcart.com/products/machine-learning-opencv/)来**
    **启动你的项目**。它提供了**自学教程**和**可运行的代码**。'
- en: Let’s get started. [![](../Images/f64588ee6b508d0f79b81993da3e92c7.png)](https://machinelearningmastery.com/wp-content/uploads/2023/03/svm_cover-scaled.jpg)
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。[![](../Images/f64588ee6b508d0f79b81993da3e92c7.png)](https://machinelearningmastery.com/wp-content/uploads/2023/03/svm_cover-scaled.jpg)
- en: Support Vector Machines in OpenCV
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: OpenCV中的支持向量机
- en: Photo by [Lance Asper](https://unsplash.com/photos/O79h8KzusIc), some rights
    reserved.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由[Lance Asper](https://unsplash.com/photos/O79h8KzusIc)提供，版权所有。
- en: '**Tutorial Overview**'
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**教程概述**'
- en: 'This tutorial is divided into two parts; they are:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程分为两部分，它们是：
- en: Reminder of How Support Vector Machines Work
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量机工作原理的提醒
- en: Discovering the SVM Algorithm in OpenCV
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在OpenCV中发现SVM算法
- en: '**Reminder of How Support Vector Machines Work**'
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**支持向量机工作原理的提醒**'
- en: 'The Support Vector Machine (SVM) algorithm has already been explained well
    in [this tutorial by Jason Brownlee](https://machinelearningmastery.com/support-vector-machines-for-machine-learning/),
    but let’s first start with brushing up some of the most important points from
    his tutorial:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机（SVM）算法在[Jason Brownlee的这个教程](https://machinelearningmastery.com/support-vector-machines-for-machine-learning/)中已经解释得很好，不过我们先从复习他教程中的一些最重要的点开始：
- en: '**For simplicity, let’s say that we have two separate classes, 0 and 1\. A
    hyperplane can separate the data points within these two classes, the decision
    boundary that splits the input space to separate the data points by their class.
    The dimension of this hyperplane depends on the dimensionality of the input data
    points.**'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**为了简单起见，我们假设有两个独立的类别0和1。一个超平面可以将这两个类别中的数据点分开，决策边界将输入空间分割以根据类别区分数据点。这个超平面的维度取决于输入数据点的维度。**'
- en: '***   **If given a newly observed data point, we may find the class to which
    it belongs by calculating which side of the hyperplane it falls. **'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '***   **如果给定一个新观察到的数据点，我们可以通过计算它位于超平面哪一侧来找出它所属的类别。**'
- en: '***   **A *margin* is the distance between the decision boundary and the closest
    data points. It is found by considering only the closest data points belonging
    to the different classes. It is calculated as the perpendicular distance of these
    nearest data points to the decision boundary.**'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '***   **一个*边际*是决策边界与最近数据点之间的距离。它是通过仅考虑属于不同类别的最近数据点来确定的。它是这些最近数据点到决策边界的垂直距离。**'
- en: '***   **The largest margin to the closest data points characterizes the optimal
    decision boundary. These nearest data points are known as the *support vectors*. **'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '***   **最大的边际与最近数据点的距离特征化了最佳决策边界。这些最近的数据点被称为*支持向量*。**'
- en: '***   **If the classes are not perfectly separable from one another because
    they may be distributed so that some of their data points intermingle in space,
    the constraint of maximizing the margin needs to be relaxed. The margin constraint
    can be relaxed by introducing a tunable parameter known as *C*.**'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '***   **如果类别之间不能完全分开，因为它们可能分布得使得一些数据点在空间中混杂，那么需要放宽最大化边界的约束。通过引入一个称为 *C* 的可调参数，可以放宽边界约束。**'
- en: '***   **The value of the *C* parameter controls how much the margin constraint
    can be violated, with a value of 0 meaning that no violation is permitted at all.
    The aim of increasing the value of *C* is to reach a better compromise between
    maximizing the margin and reducing the number of misclassifications. **'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '***   **参数 *C* 的值控制边界约束可以被违反的程度，值为 0 意味着完全不允许违反。增加 *C* 的目的是在最大化边界和减少误分类之间达到更好的折衷。**'
- en: '***   **Furthermore, the SVM uses a kernel to compute a similarity (or distance)
    measure between the input data points. In the simplest case, the kernel implements
    a dot product operation when the input data is linearly separable and can be separated
    by a linear hyperplane. **'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '***   **此外，SVM 使用核函数来计算输入数据点之间的相似性（或距离）度量。在最简单的情况下，当输入数据是线性可分且可以通过线性超平面分离时，核函数实现了一个点积操作。**'
- en: '***   **If the data points are not linearly separable straight away, the *kernel
    trick* comes to the rescue, where the operation performed by the kernel seeks
    to transform the data to a higher-dimensional space in which it becomes linearly
    separable. This is analogous to the SVM finding a non-linear decision boundary
    in the original input space. **'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '***   **如果数据点一开始不是线性可分的，*核技巧* 就会派上用场，其中核函数执行的操作旨在将数据转换到更高维的空间，使其变得线性可分。这类似于
    SVM 在原始输入空间中找到一个非线性决策边界。**'
- en: '**## **Discovering the SVM algorithm in OpenCV**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**## **在 OpenCV 中发现 SVM 算法**'
- en: Let’s first consider applying the SVM to a simple linearly separable dataset
    that enables us to visualize several of the abovementioned concepts before moving
    on to more complex tasks.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，我们考虑将 SVM 应用于一个简单的线性可分数据集，这样我们可以在继续更复杂的任务之前，直观地了解前面提到的几个概念。
- en: 'For this purpose, we shall be generating a dataset consisting of 100 data points
    (specified by `n_samples`), which are equally divided into 2 Gaussian clusters
    (specified by `centers`) having a standard deviation set to 1.5 (specified by
    `cluster_std`). To be able to replicate the results, let’s also define a value
    for `random_state`, which we’re going to set to 15:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 为此，我们将生成一个包含 100 个数据点（由 `n_samples` 指定）的数据集，这些数据点均匀地分成 2 个高斯簇（由 `centers` 指定），标准差设置为
    1.5（由 `cluster_std` 指定）。为了能够复制结果，我们还将定义一个 `random_state` 的值，我们将其设置为 15：
- en: Python
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Python
- en: '[PRE0]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The code above should generate the following plot of data points. You may note
    that we are setting the color values to the ground truth labels to be able to
    distinguish between data points belonging to the two different classes:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 上面的代码应生成以下数据点的图。你可能会注意到，我们将颜色值设置为实际标签，以便区分属于两个不同类别的数据点：
- en: '[![](../Images/3df691de41cf7f3c35dc2f9bf6c17ad1.png)](https://machinelearningmastery.com/wp-content/uploads/2023/03/svm_1.png)'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/3df691de41cf7f3c35dc2f9bf6c17ad1.png)](https://machinelearningmastery.com/wp-content/uploads/2023/03/svm_1.png)'
- en: Linearly Separable Data Points Belonging to Two Different Classes
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 线性可分的数据点属于两个不同的类别
- en: 'The next step is to split the dataset into training and testing sets, where
    the former will be used to train the SVM and the latter to test it:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是将数据集分成训练集和测试集，其中前者用于训练 SVM，后者用于测试：
- en: Python
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: Python
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[![](../Images/089153a633cbb0ac10d2d09e1c7ba635.png)](https://machinelearningmastery.com/wp-content/uploads/2023/03/svm_2.png)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/089153a633cbb0ac10d2d09e1c7ba635.png)](https://machinelearningmastery.com/wp-content/uploads/2023/03/svm_2.png)'
- en: Splitting the Data Points in Training and Testing Sets
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 将数据点分为训练集和测试集
- en: 'We may see from the image of the training data above that the two classes are
    clearly distinguishable and should be easily separated by a linear hyperplane.
    Hence, let’s proceed to create and train an SVM in OpenCV that makes use of a
    linear kernel to find the optimal decision boundary between these two classes:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面的训练数据图像中，我们可以看到这两个类别明显可分，并且应该能够通过一个线性超平面轻松分开。因此，让我们继续创建和训练一个在 OpenCV 中使用线性核的
    SVM，以找到这两个类别之间的最佳决策边界：
- en: Python
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: Python
- en: '[PRE2]'
  id: totrans-41
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: Here, note that the SVM’s `train` method in OpenCV requires the input data to
    be of the 32-bit float type.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，请注意 OpenCV 中 SVM 的 `train` 方法需要输入数据为 32 位浮点类型。
- en: 'We may proceed to use the trained SVM to predict labels for the testing data
    and subsequently calculate the classifier’s accuracy by comparing the predictions
    with their corresponding ground truth:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以继续使用训练好的 SVM 对测试数据预测标签，并通过将预测与相应的真实标签进行比较来计算分类器的准确性：
- en: Python
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: Python
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: Python
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: Python
- en: '[PRE4]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: As expected, all of the testing data points have been correctly classified.
    Let’s also visualize the decision boundary computed by the SVM algorithm during
    training to understand better how it arrived at this classification result.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 预期地，所有测试数据点都被正确分类。让我们还可视化 SVM 算法在训练期间计算的决策边界，以更好地理解它是如何得出这一分类结果的。
- en: 'In the meantime, the code listing so far is as follows:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 与此同时，迄今为止的代码清单如下：
- en: Python
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: Python
- en: '[PRE5]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'To visualize the decision boundary, we will be creating many two-dimensional
    points structured into a rectangular grid, which span the space occupied by the
    data points used for testing:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可视化决策边界，我们将创建许多二维点，构成一个矩形网格，该网格跨越用于测试的数据点占据的空间：
- en: '[PRE6]'
  id: totrans-53
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'Next, we shall organize the x- and y-coordinates of the data points that make
    up the rectangular grid into a two-column array and pass them on to the `predict`
    method to generate a class label for each one of them:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们将把构成矩形网格的数据点的 x 和 y 坐标组织成一个两列数组，并传递给 `predict` 方法，为每一个数据点生成一个类标签：
- en: Python
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: Python
- en: '[PRE7]'
  id: totrans-56
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'We may finally visualize them by a contour plot overlayed with the data points
    used for testing to confirm that, indeed, the decision boundary computed by the
    SVM algorithm is linear:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以通过轮廓图来可视化它们，覆盖用于测试的数据点，以确认 SVM 算法计算的决策边界确实是线性的：
- en: Python
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: Python
- en: '[PRE8]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[![](../Images/bf15586b51941683f859cb2e76a5829e.png)](https://machinelearningmastery.com/wp-content/uploads/2023/03/svm_3.png)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/bf15586b51941683f859cb2e76a5829e.png)](https://machinelearningmastery.com/wp-content/uploads/2023/03/svm_3.png)'
- en: Linear Decision Boundary Computed by the SVM
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: SVM 计算的线性决策边界
- en: We may also confirm from the figure above that, as mentioned in the first section,
    the testing data points have been assigned a class label depending on the side
    of the decision boundary they were found on.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还可以从上图确认，在第一节中提到的，测试数据点已根据它们所在决策边界的一侧被分配了一个类标签。
- en: 'Furthermore, we may highlight the training data points that have been identified
    as the support vectors and which have played an instrumental role in determining
    the decision boundary:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还可以突出显示被识别为支持向量并在决策边界确定中发挥关键作用的训练数据点：
- en: Python
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: Python
- en: '[PRE9]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[![](../Images/9f46d2335c85f1f476afa36c888b4332.png)](https://machinelearningmastery.com/wp-content/uploads/2023/03/svm_4.png)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/9f46d2335c85f1f476afa36c888b4332.png)](https://machinelearningmastery.com/wp-content/uploads/2023/03/svm_4.png)'
- en: Support Vectors Highlighted in Red
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 突出显示的支持向量为红色
- en: 'The complete code listing to generate the decision boundary and visualize the
    support vectors is as follows:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 生成决策边界并可视化支持向量的完整代码清单如下：
- en: Python
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Python
- en: '[PRE10]'
  id: totrans-70
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: 'So far, we have considered the simplest case of having two well-distinguishable
    classes. But how do we distinguish between classes that are less clearly separable
    because they consist of data points that intermingle in space, such as the following:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们考虑了最简单的情况，即有两个可以明确区分的类。但是，如何区分空间中混合在一起的数据点所属的不太明显可分离的类别，比如以下情况：
- en: Python
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: Python
- en: '[PRE11]'
  id: totrans-73
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[![](../Images/d61273165fdd90cf1137b9c1f80ca270.png)](https://machinelearningmastery.com/wp-content/uploads/2023/03/svm_5.png)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/d61273165fdd90cf1137b9c1f80ca270.png)](https://machinelearningmastery.com/wp-content/uploads/2023/03/svm_5.png)'
- en: Non-Linearly Separable Data Points Belonging to Two Different Classes
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 属于两个不同类别的非线性可分数据点
- en: '[![](../Images/df2368cf095f546fe83047e5b3857825.png)](https://machinelearningmastery.com/wp-content/uploads/2023/03/svm_6.png)'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/df2368cf095f546fe83047e5b3857825.png)](https://machinelearningmastery.com/wp-content/uploads/2023/03/svm_6.png)'
- en: Splitting the Non-Linearly Separable Data in Training and Testing Sets
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 将非线性可分数据分割为训练集和测试集
- en: In this case, we might wish to explore different options depending on how much
    the two classes overlap one another, such as (1) relaxing the margin constraint
    for the linear kernel by increasing the value of the *C* parameter to allow for
    a better compromise between maximizing the margin and reducing misclassifications,
    or (2) using a different kernel function that can produce a non-linear decision
    boundary, such as the Radial Basis Function (RBF).
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们可能希望根据两个类别彼此重叠的程度探索不同的选项，例如 (1) 通过增加 *C* 参数的值放宽线性核的边界约束，以在最大化边界和减少误分类之间取得更好的折衷，或者
    (2) 使用能够产生非线性决策边界的不同核函数，如径向基函数（RBF）。
- en: 'In doing so, we need to set the values of a few properties of the SVM and the
    kernel function in use:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 在此过程中，我们需要设置SVM和正在使用的核函数的几个属性的值：
- en: 'SVM_C_SVC: Known as *C-Support Vector Classification*, this SVM type allows
    an n-class classification (n $\geq$ 2) of classes with imperfect separation (i.e.
    not linearly separable). Set using the `setType` method.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SVM_C_SVC：称为*C-支持向量分类*，此类SVM允许对具有不完全分离的类别进行n类分类（n $\geq$ 2）（即非线性可分）。使用 `setType`
    方法设定。
- en: 'C: Penalty multiplier for outliers when dealing with non-linearly separable
    classes. Set using the `setC` method.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: C：处理非线性可分类时异常值的惩罚倍数。使用 `setC` 方法设定。
- en: 'Gamma: Determines the radius of the RBF kernel function. A smaller gamma value
    results in a wider radius that can capture the similarity of data points far from
    each other but may result in overfitting. A larger gamma results in a narrower
    radius that can only capture the similarity of nearby data points, which may result
    in underfitting. Set using the `setGamma` method.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gamma：决定了RBF核函数的半径。较小的gamma值导致更宽的半径，可以捕捉远离彼此的数据点的相似性，但可能导致过拟合。较大的gamma值导致较窄的半径，只能捕捉附近数据点的相似性，可能导致欠拟合。使用
    `setGamma` 方法设定。
- en: 'Here, the *C* and *gamma* values are being set arbitrarily, but you may conduct
    further testing to investigate how different values affect the resulting prediction
    accuracy. Both of the aforementioned options give us a prediction accuracy of
    85% using the following code, but achieve this accuracy through different decision
    boundaries:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，*C* 和 *gamma* 的值被随意设定，但您可以进行进一步的测试，以探索不同数值如何影响最终预测准确性。前述两个选项均使用以下代码达到85%的预测准确性，但是通过不同的决策边界实现此准确性：
- en: 'Using a linear kernel with a relaxed margin constraint:'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用放宽边界约束的线性核函数：
- en: Python
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Python
- en: '[PRE12]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[![](../Images/d42a484fb6efbecb1ddfeadbaf1132e3.png)](https://machinelearningmastery.com/wp-content/uploads/2023/03/svm_7.png)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/d42a484fb6efbecb1ddfeadbaf1132e3.png)](https://machinelearningmastery.com/wp-content/uploads/2023/03/svm_7.png)'
- en: Decision Boundary Computed Using a Linear Kernel with Relaxed Margin Constraints
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 使用放宽边界约束的线性核函数计算的决策边界
- en: 'Using an RBF kernel function:'
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用RBF核函数：
- en: Python
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: Python
- en: '[PRE13]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '[![](../Images/354fa2840c012dd6cd6f75e6a9302576.png)](https://machinelearningmastery.com/wp-content/uploads/2023/03/svm_8.png)'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/354fa2840c012dd6cd6f75e6a9302576.png)](https://machinelearningmastery.com/wp-content/uploads/2023/03/svm_8.png)'
- en: Decision Boundary Computed Using an RBF Kernel
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 使用RBF核函数计算的决策边界
- en: The choice of values for the SVM parameters typically depends on the task and
    the data at hand and requires further testing to be tuned accordingly.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: SVM参数的选择通常取决于任务和手头的数据，并需要进一步测试以进行相应的调整。
- en: '**Further Reading**'
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**进一步阅读**'
- en: This section provides more resources on the topic if you want to go deeper.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您想深入了解这个主题，本节提供了更多资源。
- en: '**Books**'
  id: totrans-97
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**书籍**'
- en: '[Machine Learning for OpenCV](https://www.amazon.com/Machine-Learning-OpenCV-Intelligent-processing/dp/1783980281/ref=sr_1_1?crid=3VWMIM65XCS6K&keywords=machine+learning+for+opencv&qid=1678294085&sprefix=machine+learning+for+openc,aps,213&sr=8-1),
    2017.'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenCV的机器学习](https://www.amazon.com/Machine-Learning-OpenCV-Intelligent-processing/dp/1783980281/ref=sr_1_1?crid=3VWMIM65XCS6K&keywords=machine+learning+for+opencv&qid=1678294085&sprefix=machine+learning+for+openc,aps,213&sr=8-1)，2017年。'
- en: '[Mastering OpenCV 4 with Python](https://www.amazon.com/Mastering-OpenCV-Python-practical-processing/dp/1789344913),
    2019.'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[使用Python掌握OpenCV 4](https://www.amazon.com/Mastering-OpenCV-Python-practical-processing/dp/1789344913)，2019年。'
- en: '**Websites**'
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**网站**'
- en: Introduction to Support Vector Machines, [https://docs.opencv.org/4.x/d1/d73/tutorial_introduction_to_svm.html](https://docs.opencv.org/4.x/d1/d73/tutorial_introduction_to_svm.html)
  id: totrans-101
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量机简介，[https://docs.opencv.org/4.x/d1/d73/tutorial_introduction_to_svm.html](https://docs.opencv.org/4.x/d1/d73/tutorial_introduction_to_svm.html)
- en: '**Summary**'
  id: totrans-102
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**总结**'
- en: In this tutorial, you learned how to apply OpenCV’s Support Vector Machine algorithm
    on a custom two-dimensional dataset.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在本教程中，你学习了如何在自定义的二维数据集上应用 OpenCV 的支持向量机算法。
- en: 'Specifically, you learned:'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，你学到了：
- en: Several of the most important characteristics of the Support Vector Machine
    algorithm.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 支持向量机算法的几个最重要的特性。
- en: How to use the Support Vector Machine algorithm on a custom dataset in OpenCV.
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在 OpenCV 中对自定义数据集使用支持向量机算法。
- en: Do you have any questions?
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 你有任何问题吗？
- en: Ask your questions in the comments below, and I will do my best to answer.****************
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面的评论中提出你的问题，我会尽力回答。****************
