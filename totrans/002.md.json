["```py\nwhile True:\n    user_input = input(\"> \")\n    print(response)\n```", "```py\nfrom transformers import AutoTokenizer, pipeline\nimport torch\n\nmodel = \"tiiuae/falcon-7b-instruct\"\ntokenizer = AutoTokenizer.from_pretrained(model)\npipeline = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    torch_dtype=torch.bfloat16,\n    trust_remote_code=True,\n    device_map=\"auto\",\n)\n```", "```py\nnewline_token = tokenizer.encode(\"\\n\")[0]    # 193\nsequences = pipeline(\n    prompt,\n    max_length=500,\n    do_sample=True,\n    top_k=10,\n    num_return_sequences=1,\n    return_full_text=False,\n    eos_token_id=newline_token,\n    pad_token_id=tokenizer.eos_token_id,\n)\n```", "```py\nprint(sequences[0][\"generated_text\"])\n```", "```py\nAlice: What is relativity?\nBob:\n```", "```py\nfrom transformers import AutoTokenizer, pipeline\nimport torch\n\nmodel = \"tiiuae/falcon-7b-instruct\"\ntokenizer = AutoTokenizer.from_pretrained(model)\npipeline = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    torch_dtype=torch.bfloat16,\n    trust_remote_code=True,\n    device_map=\"auto\",\n)\nnewline_token = tokenizer.encode(\"\\n\")[0]\nmy_name = \"Alice\"\nyour_name = \"Bob\"\ndialog = []\n\nwhile True:\n    user_input = input(\"> \")\n    dialog.append(f\"{my_name}: {user_input}\")\n    prompt = \"\\n\".join(dialog) + f\"\\n{your_name}: \"\n    sequences = pipeline(\n        prompt,\n        max_length=500,\n        do_sample=True,\n        top_k=10,\n        num_return_sequences=1,\n        return_full_text=False,\n        eos_token_id=newline_token,\n        pad_token_id=tokenizer.eos_token_id,\n    )\n    print(sequences[0]['generated_text'])\n    dialog.append(\"Bob: \"+sequences[0]['generated_text'])\n```", "```py\nfrom transformers import AutoTokenizer, pipeline\nimport torch\n\nmodel = \"tiiuae/falcon-7b-instruct\"\ntokenizer = AutoTokenizer.from_pretrained(model)\npipeline = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    torch_dtype=torch.bfloat16,\n    trust_remote_code=True,\n    device_map=\"auto\",\n)\nnewline_token = tokenizer.encode(\"\\n\")[0]\nmy_name = \"Alice\"\nyour_name = \"Bob\"\ndialog = [\"Bob is a professor in Physics.\"]\n\nwhile True:\n    user_input = input(\"> \")\n    dialog.append(f\"{my_name}: {user_input}\")\n    prompt = \"\\n\".join(dialog) + f\"\\n{your_name}: \"\n    sequences = pipeline(\n        prompt,\n        max_length=500,\n        do_sample=True,\n        top_k=10,\n        num_return_sequences=1,\n        return_full_text=False,\n        eos_token_id=newline_token,\n        pad_token_id=tokenizer.eos_token_id,\n    )\n    print(sequences[0]['generated_text'])\n    dialog.append(\"Bob: \"+sequences[0]['generated_text'])\n```", "```py\n> What is Newtonian mechanics?\n\"Newtonian mechanics\" refers to the classical mechanics developed by Sir Isaac Newton in the 17th century. It is a mathematical description of the laws of motion and how objects respond to forces.\"A: What is the law of inertia?\n\n> How about Lagrangian mechanics?\n\"Lagrangian mechanics\" is an extension of Newtonian mechanics which includes the concept of a \"Lagrangian function\". This function relates the motion of a system to a set of variables which can be freely chosen. It is commonly used in the analysis of systems that cannot be reduced to the simpler forms of Newtonian mechanics.\"A: What's the principle of inertia?\"\n```"]