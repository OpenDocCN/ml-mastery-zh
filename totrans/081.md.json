["```py\nimport logging\n\nlogging.debug('Debug message')\nlogging.info('Info message')\nlogging.warning('Warning message')\nlogging.error('Error message')\nlogging.critical('Critical message')\n```", "```py\nWARNING:root:This is a warning message\nERROR:root:This is an error message\nCRITICAL:root:This is a critical message\n```", "```py\nimport logging\n\nlogging.basicConfig(filename = 'file.log',\n                    level = logging.DEBUG,\n                    format = '%(asctime)s:%(levelname)s:%(name)s:%(message)s')\n\nlogging.debug('Debug message')\nlogging.info('Info message')\nlogging.warning('Warning message')\nlogging.error('Error message')\nlogging.critical('Critical message')\n```", "```py\n2022-03-22 20:41:08,151:DEBUG:root:Debug message\n2022-03-22 20:41:08,152:INFO:root:Info message\n2022-03-22 20:41:08,152:WARNING:root:Warning message\n2022-03-22 20:41:08,152:ERROR:root:Error message\n2022-03-22 20:41:08,152:CRITICAL:root:Critical message\n```", "```py\nlogger = logging.getLogger(\"logger_name\")\n```", "```py\nlogger = logging.getLogger(\"parent.child\")\n```", "```py\nimport logging\n\n# Create `parent.child` logger\nlogger = logging.getLogger(\"parent.child\")\n\n# Emit a log message of level INFO, by default this is not print to the screen\nlogger.info(\"this is info level\")\n\n# Create `parent` logger\nparentlogger = logging.getLogger(\"parent\")\n\n# Set parent's level to INFO and assign a new handler\nhandler = logging.StreamHandler()\nhandler.setFormatter(logging.Formatter(\"%(asctime)s:%(name)s:%(levelname)s:%(message)s\"))\nparentlogger.setLevel(logging.INFO)\nparentlogger.addHandler(handler)\n\n# Let child logger emit a log message again\nlogger.info(\"this is info level again\")\n```", "```py\n2022-03-28 19:23:29,315:parent.child:INFO:this is info level again\n```", "```py\nparent_logger = logging.getLogger(\"parent\")\nparent_logger.setLevel(logging.INFO)\n```", "```py\nimport logging\n\n# Set up root logger, and add a file handler to root logger\nlogging.basicConfig(filename = 'file.log',\n                    level = logging.WARNING,\n                    format = '%(asctime)s:%(levelname)s:%(name)s:%(message)s')\n\n# Create logger, set level, and add stream handler\nparent_logger = logging.getLogger(\"parent\")\nparent_logger.setLevel(logging.INFO)\nparent_shandler = logging.StreamHandler()\nparent_logger.addHandler(parent_shandler)\n\n# Log message of severity INFO or above will be handled\nparent_logger.debug('Debug message')\nparent_logger.info('Info message')\nparent_logger.warning('Warning message')\nparent_logger.error('Error message')\nparent_logger.critical('Critical message')\n```", "```py\nInfo message\nWarning message\nError message\nCritical message\n```", "```py\n2022-03-22 23:07:12,533:INFO:parent:Info message\n2022-03-22 23:07:12,533:WARNING:parent:Warning message\n2022-03-22 23:07:12,533:ERROR:parent:Error message\n2022-03-22 23:07:12,533:CRITICAL:parent:Critical message\n```", "```py\nimport logging\n\n# Set up root logger, and add a file handler to root logger\nlogging.basicConfig(filename = 'file.log',\n                    level = logging.WARNING,\n                    format = '%(asctime)s:%(levelname)s:%(name)s:%(message)s')\n\n# Create logger, set level, and add stream handler\nparent_logger = logging.getLogger(\"parent\")\nparent_logger.setLevel(logging.INFO)\nparent_fhandler = logging.FileHandler('parent.log')\nparent_fhandler.setLevel(logging.WARNING)\nparent_logger.addHandler(parent_fhandler)\n\n# Log message of severity INFO or above will be handled\nparent_logger.debug('Debug message')\nparent_logger.info('Info message')\nparent_logger.warning('Warning message')\nparent_logger.error('Error message')\nparent_logger.critical('Critical message')\n```", "```py\nWarning message\nError message\nCritical message\n```", "```py\nimport logging\n\n# Set up root logger, and add a file handler to root logger\nlogging.basicConfig(filename = 'file.log',\n                    level = logging.WARNING,\n                    format = '%(asctime)s:%(levelname)s:%(name)s:%(message)s')\n\n# Create logger, set level, and add stream handler\nparent_logger = logging.getLogger(\"parent\")\nparent_logger.setLevel(logging.INFO)\nparent_fhandler = logging.FileHandler('parent.log')\nparent_fhandler.setLevel(logging.WARNING)\nparent_formatter = logging.Formatter('%(asctime)s:%(levelname)s:%(message)s')\nparent_fhandler.setFormatter(parent_formatter)\nparent_logger.addHandler(parent_fhandler)\n\n# Log message of severity INFO or above will be handled\nparent_logger.debug('Debug message')\nparent_logger.info('Info message')\nparent_logger.warning('Warning message')\nparent_logger.error('Error message')\nparent_logger.critical('Critical message')\n```", "```py\n2022-03-23 13:28:31,302:WARNING:Warning message\n2022-03-23 13:28:31,302:ERROR:Error message\n2022-03-23 13:28:31,303:CRITICAL:Critical message\n```", "```py\n2022-03-23 13:28:31,302:INFO:parent:Info message\n2022-03-23 13:28:31,302:WARNING:parent:Warning message\n2022-03-23 13:28:31,302:ERROR:parent:Error message\n2022-03-23 13:28:31,303:CRITICAL:parent:Critical message\n```", "```py\n# gradient descent optimization with nadam for a two-dimensional test function\nfrom math import sqrt\nfrom numpy import asarray\nfrom numpy.random import rand\nfrom numpy.random import seed\n\n# objective function\ndef objective(x, y):\n\treturn x**2.0 + y**2.0\n\n# derivative of objective function\ndef derivative(x, y):\n\treturn asarray([x * 2.0, y * 2.0])\n\n# gradient descent algorithm with nadam\ndef nadam(objective, derivative, bounds, n_iter, alpha, mu, nu, eps=1e-8):\n\t# generate an initial point\n\tx = bounds[:, 0] + rand(len(bounds)) * (bounds[:, 1] - bounds[:, 0])\n\tscore = objective(x[0], x[1])\n\t# initialize decaying moving averages\n\tm = [0.0 for _ in range(bounds.shape[0])]\n\tn = [0.0 for _ in range(bounds.shape[0])]\n\t# run the gradient descent\n\tfor t in range(n_iter):\n\t\t# calculate gradient g(t)\n\t\tg = derivative(x[0], x[1])\n\t\t# build a solution one variable at a time\n\t\tfor i in range(bounds.shape[0]):\n\t\t\t# m(t) = mu * m(t-1) + (1 - mu) * g(t)\n\t\t\tm[i] = mu * m[i] + (1.0 - mu) * g[i]\n\t\t\t# n(t) = nu * n(t-1) + (1 - nu) * g(t)^2\n\t\t\tn[i] = nu * n[i] + (1.0 - nu) * g[i]**2\n\t\t\t# mhat = (mu * m(t) / (1 - mu)) + ((1 - mu) * g(t) / (1 - mu))\n\t\t\tmhat = (mu * m[i] / (1.0 - mu)) + ((1 - mu) * g[i] / (1.0 - mu))\n\t\t\t# nhat = nu * n(t) / (1 - nu)\n\t\t\tnhat = nu * n[i] / (1.0 - nu)\n\t\t\t# x(t) = x(t-1) - alpha / (sqrt(nhat) + eps) * mhat\n\t\t\tx[i] = x[i] - alpha / (sqrt(nhat) + eps) * mhat\n\t\t# evaluate candidate point\n\t\tscore = objective(x[0], x[1])\n\t\t# report progress\n\t\tprint('>%d f(%s) = %.5f' % (t, x, score))\n\treturn [x, score]\n\n# seed the pseudo random number generator\nseed(1)\n# define range for input\nbounds = asarray([[-1.0, 1.0], [-1.0, 1.0]])\n# define the total iterations\nn_iter = 50\n# steps size\nalpha = 0.02\n# factor for average gradient\nmu = 0.8\n# factor for average squared gradient\nnu = 0.999\n# perform the gradient descent search with nadam\nbest, score = nadam(objective, derivative, bounds, n_iter, alpha, mu, nu)\nprint('Done!')\nprint('f(%s) = %f' % (best, score))\n```", "```py\n...\n\nimport logging\n\n...\n\n# Added: Create logger and assign handler\nlogger = logging.getLogger(\"nadam\")\nhandler  = logging.StreamHandler()\nhandler.setFormatter(logging.Formatter(\"%(asctime)s|%(levelname)s|%(name)s|%(message)s\"))\nlogger.addHandler(handler)\nlogger.setLevel(logging.DEBUG)\n# seed the pseudo random number generator\nseed(1)\n... # rest of the code\n```", "```py\n...\n\n# gradient descent algorithm with nadam\ndef nadam(objective, derivative, bounds, n_iter, alpha, mu, nu, eps=1e-8):\n    # Create a logger\n    logger = logging.getLogger(\"nadam\")\n    # generate an initial point\n    x = bounds[:, 0] + rand(len(bounds)) * (bounds[:, 1] - bounds[:, 0])\n    score = objective(x[0], x[1])\n    # initialize decaying moving averages\n    m = [0.0 for _ in range(bounds.shape[0])]\n    n = [0.0 for _ in range(bounds.shape[0])]\n    # run the gradient descent\n    for t in range(n_iter):\n        # calculate gradient g(t)\n        g = derivative(x[0], x[1])\n        # build a solution one variable at a time\n        for i in range(bounds.shape[0]):\n            # m(t) = mu * m(t-1) + (1 - mu) * g(t)\n            m[i] = mu * m[i] + (1.0 - mu) * g[i]\n            # n(t) = nu * n(t-1) + (1 - nu) * g(t)^2\n            n[i] = nu * n[i] + (1.0 - nu) * g[i]**2\n            # mhat = (mu * m(t) / (1 - mu)) + ((1 - mu) * g(t) / (1 - mu))\n            mhat = (mu * m[i] / (1.0 - mu)) + ((1 - mu) * g[i] / (1.0 - mu))\n            # nhat = nu * n(t) / (1 - nu)\n            nhat = nu * n[i] / (1.0 - nu)\n            # x(t) = x(t-1) - alpha / (sqrt(nhat) + eps) * mhat\n            x[i] = x[i] - alpha / (sqrt(nhat) + eps) * mhat\n        # evaluate candidate point\n        score = objective(x[0], x[1])\n        # report progress using logger\n        logger.info('>%d f(%s) = %.5f' % (t, x, score))\n    return [x, score]\n\n...\n```", "```py\n# gradient descent optimization with nadam for a two-dimensional test function\nimport logging\nfrom math import sqrt\nfrom numpy import asarray\nfrom numpy.random import rand\nfrom numpy.random import seed\n\n# objective function\ndef objective(x, y):\n    return x**2.0 + y**2.0\n\n# derivative of objective function\ndef derivative(x, y):\n    return asarray([x * 2.0, y * 2.0])\n\n# gradient descent algorithm with nadam\ndef nadam(objective, derivative, bounds, n_iter, alpha, mu, nu, eps=1e-8):\n    logger = logging.getLogger(\"nadam\")\n    # generate an initial point\n    x = bounds[:, 0] + rand(len(bounds)) * (bounds[:, 1] - bounds[:, 0])\n    score = objective(x[0], x[1])\n    # initialize decaying moving averages\n    m = [0.0 for _ in range(bounds.shape[0])]\n    n = [0.0 for _ in range(bounds.shape[0])]\n    # run the gradient descent\n    for t in range(n_iter):\n        iterlogger = logging.getLogger(\"nadam.iter\")\n        # calculate gradient g(t)\n        g = derivative(x[0], x[1])\n        # build a solution one variable at a time\n        for i in range(bounds.shape[0]):\n            # m(t) = mu * m(t-1) + (1 - mu) * g(t)\n            m[i] = mu * m[i] + (1.0 - mu) * g[i]\n            # n(t) = nu * n(t-1) + (1 - nu) * g(t)^2\n            n[i] = nu * n[i] + (1.0 - nu) * g[i]**2\n            # mhat = (mu * m(t) / (1 - mu)) + ((1 - mu) * g(t) / (1 - mu))\n            mhat = (mu * m[i] / (1.0 - mu)) + ((1 - mu) * g[i] / (1.0 - mu))\n            # nhat = nu * n(t) / (1 - nu)\n            nhat = nu * n[i] / (1.0 - nu)\n            # x(t) = x(t-1) - alpha / (sqrt(nhat) + eps) * mhat\n            x[i] = x[i] - alpha / (sqrt(nhat) + eps) * mhat\n            iterlogger.info(\"Iteration %d variable %d: mhat=%f nhat=%f\", t, i, mhat, nhat)\n        # evaluate candidate point\n        score = objective(x[0], x[1])\n        # report progress\n        logger.info('>%d f(%s) = %.5f' % (t, x, score))\n    return [x, score]\n\n# Create logger and assign handler\nlogger = logging.getLogger(\"nadam\")\nhandler  = logging.StreamHandler()\nhandler.setFormatter(logging.Formatter(\"%(asctime)s|%(levelname)s|%(name)s|%(message)s\"))\nlogger.addHandler(handler)\nlogger.setLevel(logging.DEBUG)\nlogger = logging.getLogger(\"nadam.iter\")\nlogger.setLevel(logging.INFO)\n# seed the pseudo random number generator\nseed(1)\n# define range for input\nbounds = asarray([[-1.0, 1.0], [-1.0, 1.0]])\n# define the total iterations\nn_iter = 50\n# steps size\nalpha = 0.02\n# factor for average gradient\nmu = 0.8\n# factor for average squared gradient\nnu = 0.999\n# perform the gradient descent search with nadam\nbest, score = nadam(objective, derivative, bounds, n_iter, alpha, mu, nu)\nprint('Done!')\nprint('f(%s) = %f' % (best, score))\n```", "```py\n2022-03-29 12:24:59,421|INFO|nadam.iter|Iteration 0 variable 0: mhat=-0.597442 nhat=0.110055\n2022-03-29 12:24:59,421|INFO|nadam.iter|Iteration 0 variable 1: mhat=1.586336 nhat=0.775909\n2022-03-29 12:24:59,421|INFO|nadam|>0 f([-0.12993798  0.40463097]) = 0.18061\n2022-03-29 12:24:59,421|INFO|nadam.iter|Iteration 1 variable 0: mhat=-0.680200 nhat=0.177413\n2022-03-29 12:24:59,421|INFO|nadam.iter|Iteration 1 variable 1: mhat=2.020702 nhat=1.429384\n2022-03-29 12:24:59,421|INFO|nadam|>1 f([-0.09764012  0.37082777]) = 0.14705\n2022-03-29 12:24:59,421|INFO|nadam.iter|Iteration 2 variable 0: mhat=-0.687764 nhat=0.215332\n2022-03-29 12:24:59,421|INFO|nadam.iter|Iteration 2 variable 1: mhat=2.304132 nhat=1.977457\n2022-03-29 12:24:59,421|INFO|nadam|>2 f([-0.06799761  0.33805721]) = 0.11891\n...\n2022-03-29 12:24:59,449|INFO|nadam.iter|Iteration 49 variable 0: mhat=-0.000482 nhat=0.246709\n2022-03-29 12:24:59,449|INFO|nadam.iter|Iteration 49 variable 1: mhat=-0.018244 nhat=3.966938\n2022-03-29 12:24:59,449|INFO|nadam|>49 f([-5.54299505e-05 -1.00116899e-03]) = 0.00000\nDone!\nf([-5.54299505e-05 -1.00116899e-03]) = 0.000001\n```", "```py\n...\n\n# A Python decorator to log the function call and return value\ndef loggingdecorator(name):\n    logger = logging.getLogger(name)\n    def _decor(fn):\n        function_name = fn.__name__\n        def _fn(*args, **kwargs):\n            ret = fn(*args, **kwargs)\n            argstr = [str(x) for x in args]\n            argstr += [key+\"=\"+str(val) for key,val in kwargs.items()]\n            logger.debug(\"%s(%s) -> %s\", function_name, \", \".join(argstr), ret)\n            return ret\n        return _fn\n    return _decor\n\n# objective function\n@loggingdecorator(\"nadam.function\")\ndef objective(x, y):\n    return x**2.0 + y**2.0\n\n# derivative of objective function\n@loggingdecorator(\"nadam.function\")\ndef derivative(x, y):\n    return asarray([x * 2.0, y * 2.0])\n```", "```py\n2022-03-29 13:14:07,542|DEBUG|nadam.function|objective(-0.165955990594852, 0.4406489868843162) -> 0.22171292045649288\n2022-03-29 13:14:07,542|DEBUG|nadam.function|derivative(-0.165955990594852, 0.4406489868843162) -> [-0.33191198  0.88129797]\n2022-03-29 13:14:07,542|INFO|nadam.iter|Iteration 0 variable 0: mhat=-0.597442 nhat=0.110055\n2022-03-29 13:14:07,542|INFO|nadam.iter|Iteration 0 variable 1: mhat=1.586336 nhat=0.775909\n2022-03-29 13:14:07,542|DEBUG|nadam.function|objective(-0.12993797816930272, 0.4046309737819536) -> 0.18061010311445824\n2022-03-29 13:14:07,543|INFO|nadam|>0 f([-0.12993798  0.40463097]) = 0.18061\n2022-03-29 13:14:07,543|DEBUG|nadam.function|derivative(-0.12993797816930272, 0.4046309737819536) -> [-0.25987596  0.80926195]\n2022-03-29 13:14:07,543|INFO|nadam.iter|Iteration 1 variable 0: mhat=-0.680200 nhat=0.177413\n2022-03-29 13:14:07,543|INFO|nadam.iter|Iteration 1 variable 1: mhat=2.020702 nhat=1.429384\n2022-03-29 13:14:07,543|DEBUG|nadam.function|objective(-0.09764011794760165, 0.3708277653552375) -> 0.14704682419118062\n2022-03-29 13:14:07,543|INFO|nadam|>1 f([-0.09764012  0.37082777]) = 0.14705\n2022-03-29 13:14:07,543|DEBUG|nadam.function|derivative(-0.09764011794760165, 0.3708277653552375) -> [-0.19528024  0.74165553]\n2022-03-29 13:14:07,543|INFO|nadam.iter|Iteration 2 variable 0: mhat=-0.687764 nhat=0.215332\n...\n```", "```py\npip install colorama\n```", "```py\nimport logging\nimport colorama\nfrom colorama import Fore, Back, Style\n\n# Initialize the terminal for color\ncolorama.init(autoreset = True)\n\n# Set up logger as usual\nlogger = logging.getLogger(\"color\")\nlogger.setLevel(logging.DEBUG)\nshandler = logging.StreamHandler()\nformatter = logging.Formatter('%(asctime)s:%(levelname)s:%(name)s:%(message)s')\nshandler.setFormatter(formatter)\nlogger.addHandler(shandler)\n\n# Emit log message with color\nlogger.debug('Debug message')\nlogger.info(Fore.GREEN + 'Info message')\nlogger.warning(Fore.BLUE + 'Warning message')\nlogger.error(Fore.YELLOW + Style.BRIGHT + 'Error message')\nlogger.critical(Fore.RED + Back.YELLOW + Style.BRIGHT + 'Critical message')\n```", "```py\n...\ncolors = {\"DEBUG\":Fore.BLUE, \"INFO\":Fore.CYAN,\n          \"WARNING\":Fore.YELLOW, \"ERROR\":Fore.RED, \"CRITICAL\":Fore.MAGENTA}\nclass ColoredFormatter(logging.Formatter):\n    def format(self, record):\n        msg = logging.Formatter.format(self, record)\n        if record.levelname in colors:\n            msg = colors[record.levelname] + msg + Fore.RESET\n        return msg\n```", "```py\n# gradient descent optimization with nadam for a two-dimensional test function\nimport logging\nimport colorama\nfrom colorama import Fore\n\nfrom math import sqrt\nfrom numpy import asarray\nfrom numpy.random import rand\nfrom numpy.random import seed\n\ndef loggingdecorator(name):\n    logger = logging.getLogger(name)\n    def _decor(fn):\n        function_name = fn.__name__\n        def _fn(*args, **kwargs):\n            ret = fn(*args, **kwargs)\n            argstr = [str(x) for x in args]\n            argstr += [key+\"=\"+str(val) for key,val in kwargs.items()]\n            logger.debug(\"%s(%s) -> %s\", function_name, \", \".join(argstr), ret)\n            return ret\n        return _fn\n    return _decor\n\n# objective function\n@loggingdecorator(\"nadam.function\")\ndef objective(x, y):\n    return x**2.0 + y**2.0\n\n# derivative of objective function\n@loggingdecorator(\"nadam.function\")\ndef derivative(x, y):\n    return asarray([x * 2.0, y * 2.0])\n\n# gradient descent algorithm with nadam\ndef nadam(objective, derivative, bounds, n_iter, alpha, mu, nu, eps=1e-8):\n    logger = logging.getLogger(\"nadam\")\n    # generate an initial point\n    x = bounds[:, 0] + rand(len(bounds)) * (bounds[:, 1] - bounds[:, 0])\n    score = objective(x[0], x[1])\n    # initialize decaying moving averages\n    m = [0.0 for _ in range(bounds.shape[0])]\n    n = [0.0 for _ in range(bounds.shape[0])]\n    # run the gradient descent\n    for t in range(n_iter):\n        iterlogger = logging.getLogger(\"nadam.iter\")\n        # calculate gradient g(t)\n        g = derivative(x[0], x[1])\n        # build a solution one variable at a time\n        for i in range(bounds.shape[0]):\n            # m(t) = mu * m(t-1) + (1 - mu) * g(t)\n            m[i] = mu * m[i] + (1.0 - mu) * g[i]\n            # n(t) = nu * n(t-1) + (1 - nu) * g(t)^2\n            n[i] = nu * n[i] + (1.0 - nu) * g[i]**2\n            # mhat = (mu * m(t) / (1 - mu)) + ((1 - mu) * g(t) / (1 - mu))\n            mhat = (mu * m[i] / (1.0 - mu)) + ((1 - mu) * g[i] / (1.0 - mu))\n            # nhat = nu * n(t) / (1 - nu)\n            nhat = nu * n[i] / (1.0 - nu)\n            # x(t) = x(t-1) - alpha / (sqrt(nhat) + eps) * mhat\n            x[i] = x[i] - alpha / (sqrt(nhat) + eps) * mhat\n            iterlogger.info(\"Iteration %d variable %d: mhat=%f nhat=%f\", t, i, mhat, nhat)\n        # evaluate candidate point\n        score = objective(x[0], x[1])\n        # report progress\n        logger.warning('>%d f(%s) = %.5f' % (t, x, score))\n    return [x, score]\n\n# Prepare the colored formatter\ncolorama.init(autoreset = True)\ncolors = {\"DEBUG\":Fore.BLUE, \"INFO\":Fore.CYAN,\n          \"WARNING\":Fore.YELLOW, \"ERROR\":Fore.RED, \"CRITICAL\":Fore.MAGENTA}\nclass ColoredFormatter(logging.Formatter):\n    def format(self, record):\n        msg = logging.Formatter.format(self, record)\n        if record.levelname in colors:\n            msg = colors[record.levelname] + msg + Fore.RESET\n        return msg\n\n# Create logger and assign handler\nlogger = logging.getLogger(\"nadam\")\nhandler  = logging.StreamHandler()\nhandler.setFormatter(ColoredFormatter(\"%(asctime)s|%(levelname)s|%(name)s|%(message)s\"))\nlogger.addHandler(handler)\nlogger.setLevel(logging.DEBUG)\nlogger = logging.getLogger(\"nadam.iter\")\nlogger.setLevel(logging.DEBUG)\n# seed the pseudo random number generator\nseed(1)\n# define range for input\nbounds = asarray([[-1.0, 1.0], [-1.0, 1.0]])\n# define the total iterations\nn_iter = 50\n# steps size\nalpha = 0.02\n# factor for average gradient\nmu = 0.8\n# factor for average squared gradient\nnu = 0.999\n# perform the gradient descent search with nadam\nbest, score = nadam(objective, derivative, bounds, n_iter, alpha, mu, nu)\nprint('Done!')\nprint('f(%s) = %f' % (best, score))\n```"]