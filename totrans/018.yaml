- en: Get a Taste of LLMs from GPT4All
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 体验 GPT4All 的 LLM
- en: 原文：[https://machinelearningmastery.com/get-a-taste-of-llms-from-gpt4all/](https://machinelearningmastery.com/get-a-taste-of-llms-from-gpt4all/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://machinelearningmastery.com/get-a-taste-of-llms-from-gpt4all/](https://machinelearningmastery.com/get-a-taste-of-llms-from-gpt4all/)
- en: Large language models have become popular recently. ChatGPT is fashionable.
    Trying out ChatGPT to understand what LLMs are about is easy, but sometimes, you
    may want an offline alternative that can run on your computer. In this post, you
    will learn about GPT4All as an LLM that you can install on your computer. In particular,
    you will learn
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，大型语言模型变得越来越流行。ChatGPT 非常时尚。尝试使用 ChatGPT 了解 LLM 的工作原理很容易，但有时你可能希望有一个可以在计算机上离线运行的替代方案。在这篇文章中，你将了解
    GPT4All 作为一个可以在计算机上安装的 LLM。特别是，你将学习
- en: What is GPT4All
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是 GPT4All
- en: How to install the desktop client for GPT4All
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何安装 GPT4All 的桌面客户端
- en: How to run GPT4All in Python
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在 Python 中运行 GPT4All
- en: '**Get started and apply ChatGPT** with my book [Maximizing Productivity with
    ChatGPT](https://machinelearningmastery.com/productivity-with-chatgpt/). It provides
    **real-world use cases** and **prompt examples** designed to get you using ChatGPT
    quickly.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '**开始使用 ChatGPT**，可以参考我的书 [《利用 ChatGPT 最大化生产力》](https://machinelearningmastery.com/productivity-with-chatgpt/)。它提供了
    **实际应用案例** 和 **提示示例**，旨在帮助你快速上手 ChatGPT。'
- en: Let’s get started.![](../Images/c623826cbb400d3a3cbc609df251a94c.png)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！[](../Images/c623826cbb400d3a3cbc609df251a94c.png)
- en: Get a Taste of LLMs from GPT4All
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 体验 GPT4All 的 LLM
- en: Picture generated by the author using Stable Diffusion. Some rights reserved.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由作者使用 Stable Diffusion 生成。保留所有权利。
- en: '**Updates:**'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '**更新：**'
- en: '**2023-10-10**: Refreshed the Python code for gpt4all module version 1.0.12'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**2023-10-10**：刷新了 gpt4all 模块 1.0.12 版本的 Python 代码'
- en: Overview
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'This post is divided into three parts; they are:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本文分为三部分；它们是：
- en: What is GPT4All?
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是 GPT4All？
- en: How to get GPT4All
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何获取 GPT4All
- en: How to use GPT4All in Python
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在 Python 中使用 GPT4All
- en: What is GPT4All?
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是 GPT4All？
- en: The term “GPT” is derived from the title of a 2018 paper, “Improving Language
    Understanding by Generative Pre-Training” by Radford et al. This paper describes
    how transformer models are demonstrated to be able to understand human language.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: “GPT”一词源自于 Radford 等人在 2018 年发表的论文《通过生成预训练提升语言理解》。这篇论文描述了变换器模型如何被证明能够理解人类语言。
- en: Since then, many people attempted to develop language models using transformer
    architecture, and it has been found that a model large enough can give excellent
    results. However, many of the models developed are proprietary. There are either
    provided as a service with paid subscription or under a license with certain restrictive
    terms. Some are even impossible to run on commodity hardware due to is size.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 自那时以来，许多人尝试使用变换器架构开发语言模型，已经发现一个足够大的模型可以产生优异的结果。然而，许多开发的模型都是专有的。这些模型要么作为付费订阅的服务提供，要么在具有某些限制条款的许可下提供。有些甚至由于体积过大而无法在普通硬件上运行。
- en: GPT4All project tried to make the LLMs available to the public on common hardware.
    It allows you to train and deploy your model. Pretrained models are also available,
    with a small size that can reasonably run on a CPU.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: GPT4All 项目试图让 LLM 在普通硬件上对公众开放。它允许你训练和部署你的模型。也提供了预训练模型，其体积较小，可以合理地在 CPU 上运行。
- en: How to get GPT4All
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何获取 GPT4All
- en: Let’s focus only on using the pre-trained models.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们仅关注使用预训练模型。
- en: At the time of writing, GPT4All is available from [https://gpt4all.io/index.html](https://gpt4all.io/index.html),
    which you can run as a desktop application or using a Python library. You can
    download the installer for your OS to run a desktop client. The client is only
    a few hundred MB. You should see an installation screen as follows:![](../Images/4486a6688a08d8b8b6472c99ea7faaf4.png)
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在撰写本文时，GPT4All 可从 [https://gpt4all.io/index.html](https://gpt4all.io/index.html)
    获取，你可以将其作为桌面应用程序运行或使用 Python 库。你可以下载适合你操作系统的安装程序以运行桌面客户端。客户端的体积只有几百 MB。你应该会看到如下的安装界面：![](../Images/4486a6688a08d8b8b6472c99ea7faaf4.png)
- en: After you have the client installed, launching it the first time will prompt
    you to install a model, which can be as large as many GB. To start, you may pick
    “`gpt4all-j-v1.3-groovy`” (the GPT4All-J model). It is a relatively small but
    popular model.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 安装客户端后，首次启动时会提示你安装一个模型，模型的大小可以达到几 GB。你可以选择“`gpt4all-j-v1.3-groovy`”（GPT4All-J
    模型）。这是一个相对较小但受欢迎的模型。
- en: '![](../Images/381d212b3d682cc1fa359bb0873be2e9.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/381d212b3d682cc1fa359bb0873be2e9.png)'
- en: 'Once the client and model are ready, you can type your message in the input
    box. The model may expect a specific form of input, e.g., a particular language
    or style. This model expects a conversation style (like ChatGPT) and generally
    handles English well. For example, below is how it responds to the input “Give
    me a list of 10 colors and their RGB code”:'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦客户端和模型准备好，你可以在输入框中键入你的消息。模型可能期望特定形式的输入，例如特定的语言或风格。这个模型期望一种对话风格（如 ChatGPT），并且通常处理英语效果很好。例如，下面是它对输入“给我一个包含
    10 种颜色及其 RGB 代码的列表”的回应：
- en: '![](../Images/7aac7ad319c2da868217154cc3202ace.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/7aac7ad319c2da868217154cc3202ace.png)'
- en: How to use GPT4All in Python
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 如何在 Python 中使用 GPT4All
- en: The key component of GPT4All is the model. The desktop client is merely an interface
    to it. Besides the client, you can also invoke the model through a Python library.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: GPT4All 的关键组件是模型。桌面客户端只是一个接口。除了客户端之外，你还可以通过 Python 库调用模型。
- en: 'The library is unsurprisingly named “`gpt4all`,” and you can install it with
    `pip` command:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 这个库名为“`gpt4all`”，你可以使用 `pip` 命令安装：
- en: '[PRE0]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '**Note: **This is a fast-moving library and the functions may change. The following
    code has been tested on version 1.0.12 but it may not work in future versions.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意：** 这是一个快速发展的库，功能可能会发生变化。以下代码已在版本 1.0.12 上测试，但在未来版本中可能无法使用。'
- en: 'Afterward, you can use it in Python in just a few lines of code:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，你可以用 Python 只需几行代码使用它：
- en: '[PRE1]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'Running the above code will download the model file if you haven’t yet. Afterward,
    the model is loaded, input is provided, and the response is returned as a string.
    The output printed may be:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 运行上述代码将下载模型文件（如果你还没有下载）。之后，模型会被加载，输入被提供，响应将作为字符串返回。打印的输出可能是：
- en: '[PRE2]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The chat history of the session is stored in the model’s attribute `current_chat_session`
    as a Python list. An example is as follows:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 会话的聊天记录存储在模型的属性 `current_chat_session` 中，格式为 Python 列表。示例如下：
- en: '[PRE3]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'The history is a sequence of dialog in the format of Python dictionaries with
    keys `role` and `content`. The `role` can be `"system"`, `"assistant"`, or `"user"`,
    while `content` is a string of text. If you’re chatting with your model like the
    example, your role is `"user"` while the computer’s response is `"assistant"`.
    You can keep using the `generate()` call to continue your conversation. Below
    is an example:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 聊天记录是一个格式为 Python 字典的对话序列，字典包含 `role` 和 `content` 两个键。`role` 可以是 `"system"`、`"assistant"`
    或 `"user"`，而 `content` 是文本字符串。如果你像示例那样与模型聊天，你的角色是 `"user"`，计算机的响应是 `"assistant"`。你可以继续使用
    `generate()` 调用来继续对话。下面是一个示例：
- en: '[PRE4]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Note that you invoked the model multiple times in the for-loop. Each time it
    responded, the model took the output and appended it to the list of chat messages
    so you accumulated the context. Then you add a new dialog and invoke the model
    again. This is how the model remember the chat history. Below is an example of
    how the above code respond to your questions:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，你在 for 循环中多次调用了模型。每次响应时，模型会将输出追加到聊天消息列表中，因此你积累了上下文。然后你添加一个新的对话，再次调用模型。这就是模型如何记住聊天记录的方式。下面是上述代码如何回应你问题的示例：
- en: '[PRE5]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'Therefore, the chat history accumulated by the end of the above code would
    be the following:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，上述代码结束时积累的聊天记录将如下所示：
- en: '[PRE6]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: You may get a better result from another model. You may also get a different
    result due to the randomness in the model.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 你可能会从其他模型中获得更好的结果。由于模型的随机性，你也可能得到不同的结果。
- en: Summary
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: 'GPT4All is a nice tool you can play with on your computer. It allows you to
    explore the interaction with a large language model and help you better understand
    the capability and limitation of a model. In this post, you learned that:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: GPT4All 是一个你可以在计算机上使用的不错工具。它允许你探索与大型语言模型的互动，并帮助你更好地理解模型的能力和限制。在这篇文章中，你了解到：
- en: GPT4All has a desktop client that you can install on your computer
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPT4All 有一个桌面客户端，你可以将其安装到你的计算机上。
- en: GPT4All has a Python interface that allows you to interact with a language model
    in code
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GPT4All 提供了一个 Python 接口，允许你在代码中与语言模型进行交互。
- en: There are multiple language model available
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 有多个语言模型可供选择。
