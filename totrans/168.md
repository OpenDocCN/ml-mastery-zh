# 如何有效地使用稳定扩散

> 原文：[https://machinelearningmastery.com/how-to-use-stable-diffusion-effectively/](https://machinelearningmastery.com/how-to-use-stable-diffusion-effectively/)

从提示到图片，稳定扩散是一个包含许多组件和参数的管道。所有这些组件共同工作产生输出。如果某个组件行为不同，输出也会发生变化。因此，设置不当很容易毁掉你的图片。在这篇文章中，你将看到：

+   不同组件如何影响稳定扩散管道的输出

+   如何找到最佳配置以帮助你生成高质量的图片

**通过我的书籍** [《掌握稳定扩散数字艺术》](https://machinelearningmastery.com/mastering-digital-art-with-stable-diffusion/) **来启动你的项目**。它提供了**自学教程**和**有效代码**。

让我们开始吧。

![](../Images/d12db7fd03b2701f6b41c78eca632763.png)

如何有效地使用稳定扩散。

照片由 [Kam Idris](https://unsplash.com/photos/black-and-white-bed-linen-kyt0PkBSCNQ) 提供。保留部分权利。

## 概述

本文分为三部分；它们是：

+   模型的重要性

+   选择采样器和调度器

+   尺寸和 CFG 规模

## 模型的重要性

如果管道中有一个组件影响最大，那一定是模型。在Web UI中，它被称为“检查点”，以我们在训练深度学习模型时保存模型的方式命名。

Web UI 支持多种稳定扩散模型架构。如今最常见的架构是 1.5 版 (SD 1.5)。事实上，所有 1.x 版本共享相似的架构（每个模型有 860M 参数），但在不同的策略下进行训练或微调。

![](../Images/4b5e0eec24a9e8aca0e6b3943b472e8a.png)

稳定扩散 1.x 的架构。图源：Rombach et al (2022)

还有稳定扩散 2.0 (SD 2.0) 和其更新版本 2.1。这不是对版本 1.5 的“修订”，而是从头训练的模型。它使用不同的文本编码器（[OpenCLIP](https://github.com/mlfoundations/open_clip) 而不是 [CLIP](https://huggingface.co/openai/clip-vit-large-patch14)）；因此，它们对关键词的理解不同。一个显著的区别是 OpenCLIP 知道的名人和艺术家的名字较少。因此，稳定扩散 1.5 的提示在 2.1 中可能已经过时。由于编码器不同，SD2.x 和 SD1.x 不兼容，但它们共享类似的架构。

接下来是 Stable Diffusion XL（SDXL）。虽然版本 1.5 的原生分辨率为 512×512，版本 2.0 将其增加到了 768×768，但 SDXL 的分辨率为 1024×1024。建议不要使用与其原生分辨率差异很大的尺寸。SDXL 是一种不同的架构，具有更大的66亿参数流水线。最显著的是，这些模型分为两部分：基础模型和精化器模型。它们成对出现，但您可以将其中一个替换为兼容的对应模型，或者如果愿意，跳过精化器。所使用的文本编码器结合了 CLIP 和 OpenCLIP。因此，它应该比任何旧架构更好地理解您的提示。运行 SDXL 的速度较慢，需要更多内存，但通常能提供更好的质量。

![](../Images/47685ba5f9fb0a80f640da4370ead373.png)

SDXL 的架构。来自 Podell 等人（2023）的图示。

对您而言重要的是，您应该将您的模型分类为三个不兼容的系列：SD1.5、SD2.x 和 SDXL。它们在您的提示下表现不同。您还会发现，SD1.5 和 SD2.x 需要一个负面的提示才能获得好的图片，但在 SDXL 中则不那么重要。如果您正在使用 SD2.x 模型，您还会注意到您可以在 Web UI 中选择您的精化器。

![](../Images/806e9c16fa29da73a9ca4aca296f4a89.png)

使用提示“沙漠中的快餐店，名为‘Sandy Burger’”，使用不同的随机种子，使用 SD 1.5 生成的图片。请注意，没有一张图片正确拼写了名字。

![](../Images/42e52ad1c2ac1c2eea4aa65b31a49ae9.png)

使用提示“沙漠中的快餐店，名为‘Sandy Burger’”，使用不同的随机种子，使用 SD 2.0 生成的图片。请注意，并非所有图片都正确拼写了名字。

![](../Images/593621857aaf689860cb5b8c2b34c04f.png)

使用提示“沙漠中的快餐店，名为‘Sandy Burger’”，使用不同的随机种子，使用 SDXL 生成的图片。请注意，其中三张正确拼写了名字，最后一张只缺少一个字母。

稳定扩散的一个特点是原始模型功能较弱但适应性强。因此，产生了大量第三方精细调整的模型。其中最重要的是专门用于某些风格的模型，比如日本动漫、西方卡通、Pixar 风格的2.5D图形或逼真的图片。

您可以在 Civitai.com 或 Hugging Face Hub 上找到这些模型。使用关键词如“逼真”或“2D”进行搜索，并按评分排序通常会有帮助。

## 选择采样器和调度器

图像扩散是从噪声开始，并通过策略性地用像素替换噪声，直到生成最终图片。后来发现这一过程可以表示为随机微分方程。可以通过数值方法求解该方程，并有不同精度的不同算法。

最常用的采样器是 Euler。它是传统但仍然有用的。然后，有一系列 DPM 采样器。最近还引入了一些新的采样器，如 UniPC 和 LCM。每个采样器都是一个算法。它要运行多个**步骤**，并且每个步骤使用不同的参数。这些参数是通过**调度器**（如 Karras 或指数）设置的。一些采样器有一个替代的“祖先”模式，它在每个步骤中增加随机性。如果你想要更具创意的输出，这是很有用的。那些采样器通常在名称中带有后缀“a”，例如“Euler a”而不是“Euler”。非祖先采样器会收敛，即它们在一定步骤后不会再改变输出。祖先采样器在增加步骤大小时会产生不同的输出。

![](../Images/93fa8f3477c7375decdf0d71694680fa.png)

在 Stable Diffusion Web UI 中选择采样器、调度器、步骤和其他参数

作为用户，你可以假设 Karras 是所有情况的调度器。然而，调度器和步长需要一些实验。应该选择 Euler 或 DPM++2M，因为它们在平衡质量和速度方面表现最佳。你可以从大约 20 到 30 的步长开始；你选择的步数越多，输出的质量（细节和准确性）就越好，但相应地速度会变慢。

## 尺寸和 CFG 比例

请记住，图像扩散过程从一个嘈杂的图片开始，逐渐放置由提示条件的像素。调节参数 CFG 比例（无分类器引导比例）可以控制条件对扩散过程的影响程度。

不幸的是，CFG 比例的最佳值取决于模型。一些模型最适合 CFG 比例为 1 到 2，而其他模型则优化为 7 到 9。在 Web UI 中，默认值为 7.5。但一般而言，CFG 比例越高，输出图像越符合你的提示。

如果你的 CFG 比例过低，输出的图像可能与你预期的不同。然而，导致未达到预期效果的另一个原因是输出大小。例如，如果你提示要一个站立男人的图片，除非将图像大小设置为高度明显大于宽度，否则可能得到一个半身照片或者头部特写。扩散过程在早期阶段设定图片构图。在较高的画布上更容易设计站立的人物。

![](../Images/ee61baa5c333951b640d931d59e1cfea.png)

在提供正方形画布时生成半身照片。

![](../Images/fc081d8edd1ae7354dd37c641d146810.png)

使用相同的提示、相同的种子，只改变画布大小来生成全身照片。

类似地，如果你给一个占图像小部分的物体过多的细节，这些细节可能会被忽略，因为像素不足以呈现这些细节。这就是为什么 SDXL 通常比 SD 1.5 更好的原因，因为通常使用更大的像素大小。

最后一点，使用图像扩散模型生成图片涉及随机性。始终从一批几张图片开始，以确保不良输出不仅仅是由于随机种子造成的。

## 进一步阅读

如果您希望深入了解这个主题，本节提供了更多资源。

+   [使用潜在扩散模型进行高分辨率图像合成](https://arxiv.org/abs/2112.10752)，作者为 Rombach 等人（2022）

+   [SDXL: 改进高分辨率图像合成的潜在扩散模型](http://arxiv.org/abs/2307.01952)，作者为 Podell 等人（2023）

+   [稳定扩散页面](https://en.wikipedia.org/wiki/Stable_Diffusion) 在维基百科上

## 概要

在本文中，您了解了一些微妙的细节，这些细节影响了稳定扩散中的图像生成。具体来说，您学到了：

+   不同版本稳定扩散之间的区别

+   调度器和采样器如何影响图像扩散过程

+   画布大小如何影响输出结果
