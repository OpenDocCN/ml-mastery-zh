["```py\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\n\ndata = load_iris()\nX = data['data']\ny = data['target']\nX = torch.tensor(X, dtype=torch.float32)\ny = torch.tensor(y, dtype=torch.long)\n\n# split\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n\nclass IrisModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.hidden = nn.Linear(4, 8)\n        self.act = nn.ReLU()\n        self.output = nn.Linear(8, 3)\n\n    def forward(self, x):\n        x = self.act(self.hidden(x))\n        x = self.output(x)\n        return x\n\n# loss metric and optimizer\nmodel = IrisModel()\nloss_fn = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# prepare model and training parameters\nn_epochs = 100\nbatch_size = 10\nbatch_start = torch.arange(0, len(X_train), batch_size)\n\n# training loop\nfor epoch in range(n_epochs):\n    for start in batch_start:\n        # take a batch\n        X_batch = X_train[start:start+batch_size]\n        y_batch = y_train[start:start+batch_size]\n        # forward pass\n        y_pred = model(X_batch)\n        loss = loss_fn(y_pred, y_batch)\n        # backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        # update weights\n        optimizer.step()\n\n# validating model\ny_pred = model(X_test)\nacc = (torch.argmax(y_pred, 1) == y_test).float().mean()\nacc = float(acc)*100\nprint(\"Model accuracy: %.2f%%\" % acc)\n```", "```py\nModel accuracy: 97.78%\n```", "```py\ntorch.onnx.export(model, X_test, 'iris.onnx', input_names=[\"features\"], output_names=[\"logits\"])\n```"]