# Python 代码分析

> 译文：[`machinelearningmastery.com/profiling-python-code/`](https://machinelearningmastery.com/profiling-python-code/)

性能分析是一种确定程序中时间花费的技术。通过这些统计数据，我们可以找到程序的“热点”并考虑改进的方法。有时，意外位置的热点也可能暗示程序中的一个错误。

在本教程中，我们将看到如何使用 Python 中的性能分析功能。具体来说，你将看到：

+   我们如何使用`timeit`模块比较小的代码片段

+   我们如何使用`cProfile`模块对整个程序进行分析

+   我们如何在现有程序中调用分析器

+   分析器无法做的事情

**启动你的项目**，请阅读我的新书[《机器学习中的 Python》](https://machinelearningmastery.com/python-for-machine-learning/)，包括*逐步教程*和所有示例的*Python 源代码*文件。

让我们开始吧！[](../Images/a86cb6c3738bf1a81ce1f210bfb00fd5.png)

Python 代码分析。照片由[Prashant Saini](https://unsplash.com/photos/BeoRcYyVgxE)提供。部分权利保留。

## 教程概述

本教程分为四部分；它们是：

+   分析小片段

+   分析模块

+   在代码中使用分析器

+   注意事项

## 分析小片段

当你被问到 Python 中完成相同任务的不同方法时，一种观点是检查哪种方法更高效。在 Python 的标准库中，我们有`timeit`模块，它允许我们进行一些简单的性能分析。

例如，要连接多个短字符串，我们可以使用字符串的`join()`函数或`+`运算符。那么，我们如何知道哪个更快呢？请考虑以下 Python 代码：

```py
longstr = ""
for x in range(1000):
  longstr += str(x)
```

这将产生一个长字符串`012345....`在变量`longstr`中。另一种写法是：

```py
longstr = "".join([str(x) for x in range(1000)])
```

为了比较这两者，我们可以在命令行中执行以下操作：

```py
python -m timeit 'longstr=""' 'for x in range(1000): longstr += str(x)'
python -m timeit '"".join([str(x) for x in range(1000)])'
```

这两个命令将产生以下输出：

```py
1000 loops, best of 5: 265 usec per loop
2000 loops, best of 5: 160 usec per loop
```

上述命令用于加载`timeit`模块，并传递一行代码进行测量。在第一种情况下，我们有两行语句，它们作为两个单独的参数传递给`timeit`模块。按照相同的原理，第一条命令也可以呈现为三行语句（通过将 for 循环拆分成两行），但每行的缩进需要正确地引用：

```py
python -m timeit 'longstr=""' 'for x in range(1000):' ' longstr += str(x)'
```

`timeit`的输出是找到多次运行中的最佳性能（默认为 5 次）。每次运行是多次执行提供的语句（次数是动态确定的）。时间以最佳运行中执行一次语句的平均时间来报告。

虽然`join`函数在字符串连接方面比`+`运算符更快，但上面的计时结果并不是公平的比较。这是因为我们在循环过程中使用`str(x)`来即时生成短字符串。更好的做法是如下：

```py
python -m timeit -s 'strings = [str(x) for x in range(1000)]' 'longstr=""' 'for x in strings:' ' longstr += str(x)'
python -m timeit -s 'strings = [str(x) for x in range(1000)]' '"".join(strings)'
```

产生：

```py
2000 loops, best of 5: 173 usec per loop
50000 loops, best of 5: 6.91 usec per loop
```

`-s`选项允许我们提供“设置”代码，该代码在分析之前执行且不计时。在上述代码中，我们在开始循环之前创建了短字符串列表。因此，创建这些字符串的时间不计入“每次循环”的时间。上述结果显示，`join()`函数比`+`运算符快两个数量级。`-s`选项的更常见用法是导入库。例如，我们可以比较 Python 数学模块中的平方根函数与 NumPy，并使用指数运算符`**`：

```py
python -m timeit '[x**0.5 for x in range(1000)]'
python -m timeit -s 'from math import sqrt' '[sqrt(x) for x in range(1000)]'
python -m timeit -s 'from numpy import sqrt' '[sqrt(x) for x in range(1000)]'
```

上述结果产生了以下测量，我们可以看到在这个特定的例子中，`math.sqrt()`是最快的，而`numpy.sqrt()`是最慢的：

```py
5000 loops, best of 5: 93.2 usec per loop
5000 loops, best of 5: 72.3 usec per loop
200 loops, best of 5: 974 usec per loop
```

如果你想知道为什么 NumPy 是最慢的，那是因为 NumPy 是为数组优化的。你将在以下替代方案中看到它的卓越速度：

```py
python -m timeit -s 'import numpy as np; x=np.array(range(1000))' 'np.sqrt(x)'
```

结果如下：

```py
100000 loops, best of 5: 2.08 usec per loop
```

如果你愿意，你也可以在 Python 代码中运行`timeit`。例如，下面的代码将类似于上述代码，但会给你每次运行的总原始时间：

```py
import timeit
measurements = timeit.repeat('[x**0.5 for x in range(1000)]', number=10000)
print(measurements)
```

在上述代码中，每次运行都是执行语句 10,000 次；结果如下。你可以看到在最佳运行中的每次循环约为 98 微秒的结果：

```py
[1.0888952040000106, 0.9799715450000122, 1.0921516899999801, 1.0946189250000202, 1.2792069260000005]
```

## 性能分析模块

关注一两个语句的性能是微观的角度。很可能，我们有一个很长的程序，想要查看是什么导致它运行缓慢。这是在考虑替代语句或算法之前发生的情况。

程序运行缓慢通常有两个原因：某一部分运行缓慢，或者某一部分运行次数过多，累计起来耗时过长。我们将这些“性能消耗者”称为热点。我们来看一个例子。考虑以下程序，它使用爬山算法来寻找感知机模型的超参数：

```py
# manually search perceptron hyperparameters for binary classification
from numpy import mean
from numpy.random import randn
from numpy.random import rand
from sklearn.datasets import make_classification
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.linear_model import Perceptron

# objective function
def objective(X, y, cfg):
	# unpack config
	eta, alpha = cfg
	# define model
	model = Perceptron(penalty='elasticnet', alpha=alpha, eta0=eta)
	# define evaluation procedure
	cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
	# evaluate model
	scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)
	# calculate mean accuracy
	result = mean(scores)
	return result

# take a step in the search space
def step(cfg, step_size):
	# unpack the configuration
	eta, alpha = cfg
	# step eta
	new_eta = eta + randn() * step_size
	# check the bounds of eta
	if new_eta <= 0.0:
		new_eta = 1e-8
	if new_eta > 1.0:
		new_eta = 1.0
	# step alpha
	new_alpha = alpha + randn() * step_size
	# check the bounds of alpha
	if new_alpha < 0.0:
		new_alpha = 0.0
	# return the new configuration
	return [new_eta, new_alpha]

# hill climbing local search algorithm
def hillclimbing(X, y, objective, n_iter, step_size):
	# starting point for the search
	solution = [rand(), rand()]
	# evaluate the initial point
	solution_eval = objective(X, y, solution)
	# run the hill climb
	for i in range(n_iter):
		# take a step
		candidate = step(solution, step_size)
		# evaluate candidate point
		candidate_eval = objective(X, y, candidate)
		# check if we should keep the new point
		if candidate_eval >= solution_eval:
			# store the new point
			solution, solution_eval = candidate, candidate_eval
			# report progress
			print('>%d, cfg=%s %.5f' % (i, solution, solution_eval))
	return [solution, solution_eval]

# define dataset
X, y = make_classification(n_samples=1000, n_features=5, n_informative=2, n_redundant=1, random_state=1)
# define the total iterations
n_iter = 100
# step size in the search space
step_size = 0.1
# perform the hill climbing search
cfg, score = hillclimbing(X, y, objective, n_iter, step_size)
print('Done!')
print('cfg=%s: Mean Accuracy: %f' % (cfg, score))
```

假设我们将此程序保存到文件`hillclimb.py`中，我们可以在命令行中按如下方式运行分析器：

```py
python -m cProfile hillclimb.py
```

输出将如下所示：

```py
>10, cfg=[0.3792455490265847, 0.21589566352848377] 0.78400
>17, cfg=[0.49105438202347707, 0.1342150084854657] 0.79833
>26, cfg=[0.5737524712834843, 0.016749795596210315] 0.80033
>47, cfg=[0.5067828976025809, 0.05280380038497864] 0.80133
>48, cfg=[0.5427345321546029, 0.0049895870979695875] 0.81167
Done!
cfg=[0.5427345321546029, 0.0049895870979695875]: Mean Accuracy: 0.811667
         2686451 function calls (2638255 primitive calls) in 5.500 seconds

   Ordered by: standard name

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      101    0.001    0.000    4.892    0.048 hillclimb.py:11(objective)
        1    0.000    0.000    5.501    5.501 hillclimb.py:2(<module>)
      100    0.000    0.000    0.001    0.000 hillclimb.py:25(step)
        1    0.001    0.001    4.894    4.894 hillclimb.py:44(hillclimbing)
        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(<module>)
      303    0.000    0.000    0.008    0.000 <__array_function__ internals>:2(all)
      303    0.000    0.000    0.005    0.000 <__array_function__ internals>:2(amin)
        2    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(any)
        4    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(atleast_1d)
     3333    0.003    0.000    0.018    0.000 <__array_function__ internals>:2(bincount)
      103    0.000    0.000    0.001    0.000 <__array_function__ internals>:2(concatenate)
        3    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(copyto)
      606    0.001    0.000    0.010    0.000 <__array_function__ internals>:2(cumsum)
        6    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(dot)
        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(empty_like)
        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(inv)
        2    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(linspace)
        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(lstsq)
      101    0.000    0.000    0.005    0.000 <__array_function__ internals>:2(mean)
        2    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(ndim)
        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(outer)
        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(polyfit)
        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(polyval)
        1    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(prod)
      303    0.000    0.000    0.002    0.000 <__array_function__ internals>:2(ravel)
        2    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(result_type)
      303    0.001    0.000    0.001    0.000 <__array_function__ internals>:2(shape)
      303    0.000    0.000    0.035    0.000 <__array_function__ internals>:2(sort)
        4    0.000    0.000    0.000    0.000 <__array_function__ internals>:2(trim_zeros)
     1617    0.002    0.000    0.112    0.000 <__array_function__ internals>:2(unique)
...
```

程序的正常输出会首先被打印，然后是分析器的统计信息。从第一行，我们可以看到我们程序中的`objective()`函数已运行 101 次，耗时 4.89 秒。但这 4.89 秒大部分时间都花在了它调用的函数上，该函数总共只花费了 0.001 秒。依赖模块中的函数也被分析。因此，你会看到很多 NumPy 函数。

上述输出很长，可能对你没有帮助，因为很难判断哪个函数是热点。实际上，我们可以对上述输出进行排序。例如，为了查看哪个函数被调用的次数最多，我们可以按`ncalls`进行排序：

```py
python -m cProfile -s ncalls hillclimb.py
```

它的输出如下：它表示 Python 字典中的`get()`函数是使用最频繁的函数（但它在 5.6 秒完成程序中只消耗了 0.03 秒）：

```py
         2685349 function calls (2637153 primitive calls) in 5.609 seconds

   Ordered by: call count

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
   247588    0.029    0.000    0.029    0.000 {method 'get' of 'dict' objects}
   246196    0.028    0.000    0.028    0.000 inspect.py:2548(name)
   168057    0.018    0.000    0.018    0.000 {method 'append' of 'list' objects}
   161738    0.018    0.000    0.018    0.000 inspect.py:2560(kind)
   144431    0.021    0.000    0.029    0.000 {built-in method builtins.isinstance}
   142213    0.030    0.000    0.031    0.000 {built-in method builtins.getattr}
...
```

其他排序选项如下：

| 排序字符串 | 含义 |
| --- | --- |
| 调用次数 | 调用计数 |
| cumulative | 累积时间 |
| cumtime | 累积时间 |
| file | 文件名 |
| filename | 文件名 |
| module | 文件名 |
| ncalls | 调用次数 |
| pcalls | 原始调用次数 |
| line | 行号 |
| name | 函数名 |
| nfl | 名称/文件/行 |
| stdname | 标准名称 |
| time | 内部时间 |
| tottime | 内部时间 |

如果程序完成需要一些时间，那么为了找到不同排序方式的分析结果，重复运行程序是不合理的。事实上，我们可以保存分析器的统计数据以便进一步处理，方法如下：

```py
python -m cProfile -o hillclimb.stats hillclimb.py
```

类似于上述情况，它将运行程序。但这不会将统计数据打印到屏幕上，而是将其保存到一个文件中。之后，我们可以像以下这样使用`pstats`模块打开统计文件，并提供一个提示以操作数据：

```py
python -m pstats hillclimb.stats
```

例如，我们可以使用排序命令来更改排序顺序，并使用 stats 打印我们看到的内容：

```py
Welcome to the profile statistics browser.
hillclimb.stat% help

Documented commands (type help <topic>):
========================================
EOF  add  callees  callers  help  quit  read  reverse  sort  stats  strip

hillclimb.stat% sort ncall
hillclimb.stat% stats hillclimb
Thu Jan 13 16:44:10 2022    hillclimb.stat

         2686227 function calls (2638031 primitive calls) in 5.582 seconds

   Ordered by: call count
   List reduced from 3456 to 4 due to restriction <'hillclimb'>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
      101    0.001    0.000    4.951    0.049 hillclimb.py:11(objective)
      100    0.000    0.000    0.001    0.000 hillclimb.py:25(step)
        1    0.000    0.000    5.583    5.583 hillclimb.py:2(<module>)
        1    0.000    0.000    4.952    4.952 hillclimb.py:44(hillclimbing)

hillclimb.stat%
```

你会注意到上述`stats`命令允许我们提供一个额外的参数。该参数可以是一个正则表达式，用于搜索函数，以便仅打印匹配的函数。因此，这是一种提供搜索字符串进行过滤的方法。

### 想要开始使用 Python 进行机器学习吗？

现在就参加我的 7 天免费电子邮件速成课程（附带示例代码）。

点击注册，并获得课程的免费 PDF 电子书版本。

这个`pstats`浏览器允许我们查看的不仅仅是上述表格。`callers`和`callees`命令显示了哪些函数调用了哪些函数，调用了多少次，以及花费了多少时间。因此，我们可以将其视为函数级别统计数据的细分。如果你有很多相互调用的函数，并且想要了解不同场景下时间的分配情况，这很有用。例如，这显示了`objective()`函数仅由`hillclimbing()`函数调用，而`hillclimbing()`函数调用了其他几个函数：

```py
hillclimb.stat% callers objective
   Ordered by: call count
   List reduced from 3456 to 1 due to restriction <'objective'>

Function                    was called by...
                                ncalls  tottime  cumtime
hillclimb.py:11(objective)  <-     101    0.001    4.951  hillclimb.py:44(hillclimbing)

hillclimb.stat% callees hillclimbing
   Ordered by: call count
   List reduced from 3456 to 1 due to restriction <'hillclimbing'>

Function                       called...
                                   ncalls  tottime  cumtime
hillclimb.py:44(hillclimbing)  ->     101    0.001    4.951  hillclimb.py:11(objective)
                                      100    0.000    0.001  hillclimb.py:25(step)
                                        4    0.000    0.000  {built-in method builtins.print}
                                        2    0.000    0.000  {method 'rand' of 'numpy.random.mtrand.RandomState' objects}

hillclimb.stat%
```

## 在代码中使用分析器

上述示例假设你已经将完整程序保存到一个文件中，并对整个程序进行了分析。有时，我们只关注程序的一部分。例如，如果我们加载了一个大型模块，它需要时间进行引导，并且我们想要从分析器中移除这个部分。在这种情况下，我们可以仅针对某些行调用分析器。以下是一个示例，来自于上述程序的修改：

```py
# manually search perceptron hyperparameters for binary classification
import cProfile as profile
import pstats
from numpy import mean
from numpy.random import randn
from numpy.random import rand
from sklearn.datasets import make_classification
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.linear_model import Perceptron

# objective function
def objective(X, y, cfg):
	# unpack config
	eta, alpha = cfg
	# define model
	model = Perceptron(penalty='elasticnet', alpha=alpha, eta0=eta)
	# define evaluation procedure
	cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
	# evaluate model
	scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)
	# calculate mean accuracy
	result = mean(scores)
	return result

# take a step in the search space
def step(cfg, step_size):
	# unpack the configuration
	eta, alpha = cfg
	# step eta
	new_eta = eta + randn() * step_size
	# check the bounds of eta
	if new_eta <= 0.0:
		new_eta = 1e-8
	if new_eta > 1.0:
		new_eta = 1.0
	# step alpha
	new_alpha = alpha + randn() * step_size
	# check the bounds of alpha
	if new_alpha < 0.0:
		new_alpha = 0.0
	# return the new configuration
	return [new_eta, new_alpha]

# hill climbing local search algorithm
def hillclimbing(X, y, objective, n_iter, step_size):
	# starting point for the search
	solution = [rand(), rand()]
	# evaluate the initial point
	solution_eval = objective(X, y, solution)
	# run the hill climb
	for i in range(n_iter):
		# take a step
		candidate = step(solution, step_size)
		# evaluate candidate point
		candidate_eval = objective(X, y, candidate)
		# check if we should keep the new point
		if candidate_eval >= solution_eval:
			# store the new point
			solution, solution_eval = candidate, candidate_eval
			# report progress
			print('>%d, cfg=%s %.5f' % (i, solution, solution_eval))
	return [solution, solution_eval]

# define dataset
X, y = make_classification(n_samples=1000, n_features=5, n_informative=2, n_redundant=1, random_state=1)
# define the total iterations
n_iter = 100
# step size in the search space
step_size = 0.1
# perform the hill climbing search with profiling
prof = profile.Profile()
prof.enable()
cfg, score = hillclimbing(X, y, objective, n_iter, step_size)
prof.disable()
# print program output
print('Done!')
print('cfg=%s: Mean Accuracy: %f' % (cfg, score))
# print profiling output
stats = pstats.Stats(prof).strip_dirs().sort_stats("cumtime")
stats.print_stats(10) # top 10 rows
```

它将输出以下内容：

```py
>0, cfg=[0.3776271076534661, 0.2308364063203663] 0.75700
>3, cfg=[0.35803234662466354, 0.03204434939660264] 0.77567
>8, cfg=[0.3001050823005957, 0.0] 0.78633
>10, cfg=[0.39518618870158934, 0.0] 0.78633
>12, cfg=[0.4291267905390187, 0.0] 0.78633
>13, cfg=[0.4403131521968569, 0.0] 0.78633
>16, cfg=[0.38865272555918756, 0.0] 0.78633
>17, cfg=[0.38871654921891885, 0.0] 0.78633
>18, cfg=[0.4542440671724224, 0.0] 0.78633
>19, cfg=[0.44899743344802734, 0.0] 0.78633
>20, cfg=[0.5855375509507891, 0.0] 0.78633
>21, cfg=[0.5935318064858227, 0.0] 0.78633
>23, cfg=[0.7606367310048543, 0.0] 0.78633
>24, cfg=[0.855444293727846, 0.0] 0.78633
>25, cfg=[0.9505501566826242, 0.0] 0.78633
>26, cfg=[1.0, 0.0244821888204496] 0.79800
Done!
cfg=[1.0, 0.0244821888204496]: Mean Accuracy: 0.798000
         2179559 function calls (2140124 primitive calls) in 4.941 seconds

   Ordered by: cumulative time
   List reduced from 581 to 10 due to restriction <10>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.001    0.001    4.941    4.941 hillclimb.py:46(hillclimbing)
      101    0.001    0.000    4.939    0.049 hillclimb.py:13(objective)
      101    0.001    0.000    4.931    0.049 _validation.py:375(cross_val_score)
      101    0.002    0.000    4.930    0.049 _validation.py:48(cross_validate)
      101    0.005    0.000    4.903    0.049 parallel.py:960(__call__)
      101    0.235    0.002    3.089    0.031 parallel.py:920(retrieve)
     3030    0.004    0.000    2.849    0.001 _parallel_backends.py:537(wrap_future_result)
     3030    0.020    0.000    2.845    0.001 _base.py:417(result)
     2602    0.016    0.000    2.819    0.001 threading.py:280(wait)
    12447    2.796    0.000    2.796    0.000 {method 'acquire' of '_thread.lock' objects}
```

## 注意事项

使用 Tensorflow 模型进行分析可能不会产生你预期的结果，特别是如果你为模型编写了自定义层或自定义函数。如果你正确地完成了这项工作，Tensorflow 应该在执行模型之前构建计算图，因此逻辑将发生变化。因此，分析器输出将不会显示你的自定义类。

对于涉及二进制代码的一些高级模块也是如此。分析器可以看到你调用了一些函数，并将它们标记为“内置”方法，但它无法进一步深入编译代码。

下面是用于 MNIST 分类问题的 LeNet5 模型的简短代码。如果你尝试分析它并打印前 15 行，你会看到一个包装器占据了大部分时间，而无法显示更多内容：

```py
import numpy as np
import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, Dense, AveragePooling2D, Flatten
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import EarlyStopping

# Load and reshape data to shape of (n_sample, height, width, n_channel)
(X_train, y_train), (X_test, y_test) = mnist.load_data()
X_train = np.expand_dims(X_train, axis=3).astype('float32')
X_test = np.expand_dims(X_test, axis=3).astype('float32')

# One-hot encode the output
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)

# LeNet5 model
model = Sequential([
    Conv2D(6, (5,5), input_shape=(28,28,1), padding="same", activation="tanh"),
    AveragePooling2D((2,2), strides=2),
    Conv2D(16, (5,5), activation="tanh"),
    AveragePooling2D((2,2), strides=2),
    Conv2D(120, (5,5), activation="tanh"),
    Flatten(),
    Dense(84, activation="tanh"),
    Dense(10, activation="softmax")
])
model.summary(line_length=100)

# Training
model.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"])
earlystopping = EarlyStopping(monitor="val_loss", patience=2, restore_best_weights=True)
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=20, batch_size=32, callbacks=[earlystopping])

# Evaluate
print(model.evaluate(X_test, y_test, verbose=0))
```

在下面的结果中，`TFE_Py_Execute` 被标记为“内置”方法，占用了总运行时间 39.6 秒中的 30.1 秒。注意 tottime 与 cumtime 相同，这意味着从分析器的角度来看，似乎所有时间都花费在这个函数上，并且它没有调用其他函数。这说明了 Python 分析器的局限性。

```py
         5962698 function calls (5728324 primitive calls) in 39.674 seconds

   Ordered by: cumulative time
   List reduced from 12295 to 15 due to restriction <15>

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
   3212/1    0.013    0.000   39.699   39.699 {built-in method builtins.exec}
        1    0.003    0.003   39.699   39.699 mnist.py:4(<module>)
     52/4    0.005    0.000   35.470    8.868 /usr/local/lib/python3.9/site-packages/keras/utils/traceback_utils.py:58(error_handler)
        1    0.089    0.089   34.334   34.334 /usr/local/lib/python3.9/site-packages/keras/engine/training.py:901(fit)
11075/9531    0.032    0.000   33.406    0.004 /usr/local/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:138(error_handler)
     4689    0.089    0.000   33.017    0.007 /usr/local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:882(__call__)
     4689    0.023    0.000   32.771    0.007 /usr/local/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:929(_call)
     4688    0.042    0.000   32.134    0.007 /usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py:3125(__call__)
     4689    0.075    0.000   30.941    0.007 /usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1888(_call_flat)
     4689    0.158    0.000   30.472    0.006 /usr/local/lib/python3.9/site-packages/tensorflow/python/eager/function.py:553(call)
     4689    0.034    0.000   30.152    0.006 /usr/local/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:33(quick_execute)
     4689   30.105    0.006   30.105    0.006 {built-in method tensorflow.python._pywrap_tfe.TFE_Py_Execute}
  3185/24    0.021    0.000    3.902    0.163 <frozen importlib._bootstrap>:1002(_find_and_load)
  3169/10    0.014    0.000    3.901    0.390 <frozen importlib._bootstrap>:967(_find_and_load_unlocked)
  2885/12    0.009    0.000    3.901    0.325 <frozen importlib._bootstrap_external>:844(exec_module)
```

最终，Python 的分析器仅提供时间统计信息，而不包括内存使用情况。你可能需要寻找其他库或工具来实现这一目的。

## 深入阅读

标准库模块 `timeit`、`cProfile` 和 `pstats` 的文档可以在 Python 的文档中找到：

+   `timeit` 模块: [`docs.python.org/3/library/timeit.html`](https://docs.python.org/3/library/timeit.html)

+   `cProfile` 模块和 `pstats` 模块: [`docs.python.org/3/library/profile.html`](https://docs.python.org/3/library/profile.html)

标准库的分析器非常强大，但不是唯一的。如果你想要更具视觉效果的工具，你可以尝试 Python Call Graph 模块。它可以使用 GraphViz 工具生成函数调用关系图：

+   Python Call Graph: [`pycallgraph.readthedocs.io/en/master/`](https://pycallgraph.readthedocs.io/en/master/)

无法深入编译代码的限制可以通过不使用 Python 的分析器而是使用针对编译程序的分析器来解决。我最喜欢的是 Valgrind：

+   Valgrind: [`valgrind.org/`](https://valgrind.org/)

但要使用它，你可能需要重新编译你的 Python 解释器以启用调试支持。

## 总结

在本教程中，我们了解了什么是分析器以及它能做什么。具体来说，

+   我们知道如何使用 `timeit` 模块比较小代码片段。

+   我们看到 Python 的 `cProfile` 模块可以提供有关时间使用的详细统计数据。

+   我们学会了如何使用 `pstats` 模块对 `cProfile` 的输出进行排序或过滤。
