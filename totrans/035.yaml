- en: Beginning Data Science (7-day mini-course)
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据科学入门（7天迷你课程）
- en: 原文：[https://machinelearningmastery.com/beginning-data-science-7-day-mini-course/](https://machinelearningmastery.com/beginning-data-science-7-day-mini-course/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://machinelearningmastery.com/beginning-data-science-7-day-mini-course/](https://machinelearningmastery.com/beginning-data-science-7-day-mini-course/)
- en: Data science uses mathematics to analyze data, distill information, and tell
    a story. The result of data science may be just to rigorously confirm a hypothesis,
    or to discover some useful property from the data. There are many tools you can
    use in data science, from basic statistics to sophisticated machine learning models.
    Even the most common tool can work wonderfully in a data science project.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学使用数学来分析数据、提炼信息并讲述故事。数据科学的结果可能只是严格验证一个假设，或从数据中发现一些有用的属性。你可以在数据科学中使用许多工具，从基本统计学到复杂的机器学习模型。即使是最常见的工具，也可以在数据科学项目中发挥出色的作用。
- en: In this 7-part crash course, you will learn from examples how to perform a data
    science project. This mini-course is focused on the core of data science. It is
    assumed that you gathered the data and made it ready to use. Writing a web scraper
    and validating the data you collect can be a big topic; it is not the scope here.
    This mini-course is intended for practitioners who are already comfortable with
    programming in Python, and willing to learn about the common tools for data science
    such as pandas and matplotlib. You will see how these tools can help, but more
    importantly, learn the process of drawing a quantitatively supported statement
    from the data you have. Let’s get started.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个7部分的速成课程中，你将通过示例学习如何进行数据科学项目。这个迷你课程专注于数据科学的核心内容。假设你已经收集了数据并做好了使用准备。编写网络爬虫和验证你收集的数据可能是一个大话题；这不在本课程的范围之内。这个迷你课程是为那些已经熟悉
    Python 编程并愿意学习数据科学常用工具（如 pandas 和 matplotlib）的从业人员准备的。你将看到这些工具如何提供帮助，更重要的是，学习如何从你拥有的数据中得出定量支持的结论。让我们开始吧。
- en: '![](../Images/8239ac26f53fe92d9798371cb3384718.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/8239ac26f53fe92d9798371cb3384718.png)'
- en: Beginner’s Guide to Data Science (7-day Mini-Course)
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学初学者指南（7天迷你课程）
- en: Photo by [Eduardo Soares](https://unsplash.com/photos/person-holding-white-and-red-card-utWyPB8_FU8).
    Some rights reserved.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 图片由 [Eduardo Soares](https://unsplash.com/photos/person-holding-white-and-red-card-utWyPB8_FU8)
    提供。版权所有。
- en: Who Is This Mini-Course For?
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 这个迷你课程适合谁？
- en: Before we start, let’s ensure you are in the right place. The list below provides
    some general guidelines as to who this course was designed for. Don’t panic if
    you don’t match these points exactly; you might just need to brush up in one area
    or another to keep up.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们开始之前，让我们确保你来对了地方。下面的列表提供了一些关于本课程设计对象的基本指南。如果你不完全符合这些条件也不要惊慌；你可能只需要在某个方面稍作复习以跟上进度。
- en: '**Developers that know how to write a little code**. This means that it is
    not a big deal for you to get things done with Python and know how to setup the
    ecosystem on your workstation (a prerequisite). It does not mean you’re a wizard
    coder, but you’re not afraid to install packages and write scripts.'
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**能够编写一些代码的开发人员**。这意味着你可以用 Python 完成任务，并且知道如何在工作站上设置生态系统（这是一个前提条件）。这并不意味着你是一个编码高手，但你不怕安装包和编写脚本。'
- en: '**Developers that know a little statistics**. This means you know about some
    basic statistical tools and are not afraid to use them. It does not mean you are
    a PhD in statistics, but you can look up the terms and learn if you encounter
    them.'
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**掌握一些统计学的开发人员**。这意味着你了解一些基本的统计工具，并且不怕使用它们。这并不意味着你是统计学博士，但如果遇到术语，你可以查找并学习。'
- en: '**Developers who know a bit about data science tools**. Using a Jupyter notebook
    is common in data science. Handing data in Python would be easier if you use the
    library pandas. This list goes on. You are not required to be an expert in any
    library, but being comfortable invoking the different libraries and writing code
    to manipulate data is all you need.'
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**了解一些数据科学工具的开发人员**。在数据科学中，使用 Jupyter notebook 是很常见的。如果使用 pandas 库处理数据会更容易。这只是其中的一部分。你不需要对任何库成为专家，但你需要对调用不同的库和编写代码以操作数据感到舒适。'
- en: This mini-course is not a textbook on data science. Rather, it is a project
    guideline that takes you step-by-step from a developer with minimal knowledge
    to a developer who can confidently demonstrate how a data science project can
    be done.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 这个迷你课程不是一本数据科学教科书。而是一个项目指南，它将你从一个基础知识较少的开发人员，逐步带到能够自信展示如何完成数据科学项目的开发人员。
- en: Mini-Course Overview
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 迷你课程概览
- en: This mini-course is divided into 7 parts.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 本迷你课程分为7部分。
- en: Each lesson was designed to take the average developer about 30 minutes. You
    might finish some much sooner and other you may choose to go deeper and spend
    more time.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 每节课的设计时间大约是30分钟。你可能会更快完成某些部分，也可能会选择深入研究，花费更多时间。
- en: You can complete each part as quickly or as slowly as you like. A comfortable
    schedule may be to complete one lesson per day over seven days. Highly recommended.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以按照自己喜欢的速度完成每一部分。一个舒适的安排可能是每天完成一节课，持续七天。强烈推荐。
- en: 'The topics you will cover over the next 7 lessons are as follows:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来7节课你将学习以下内容：
- en: '**Lesson 1**: Getting the Data'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第1课**：获取数据'
- en: '**Lesson 2**: Missing Values'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第2课**：缺失值'
- en: '**Lesson 3**: Descriptive Statistics'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第3课**：描述性统计'
- en: '**Lesson 4**: Exploring Data'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第4课**：探索数据'
- en: '**Lesson 5**: Visualize Correlation'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第5课**：可视化相关性'
- en: '**Lesson 6**: Hypothesis Testing'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第6课**：假设检验'
- en: '**Lesson 7**: Identifying Outliers'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**第7课**：识别异常值'
- en: This is going to be a lot of fun.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这将非常有趣。
- en: 'You’ll have to do some work, though: a little reading, research, and programming.
    You want to learn how to finish a data science project, right?'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 不过你得做些工作：一点阅读、研究和编程。你想学会如何完成一个数据科学项目，对吧？
- en: '**Post your results in the comments**; I’ll cheer you on!'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '**在评论中发布你的结果**；我会为你加油！'
- en: Hang in there; don’t give up.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 坚持住；不要放弃。
- en: 'Lesson 01: Getting the Data'
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第01课：获取数据
- en: 'The dataset we will use for this mini-course is the “All Countries Dataset”
    that is available on Kaggle:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将用于本迷你课程的数据集是“Kaggle上提供的‘所有国家数据集’”：
- en: '[https://www.kaggle.com/datasets/adityakishor1/all-countries-details](https://www.kaggle.com/datasets/adityakishor1/all-countries-details)'
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[https://www.kaggle.com/datasets/adityakishor1/all-countries-details](https://www.kaggle.com/datasets/adityakishor1/all-countries-details)'
- en: This dataset describes almost all countries’ demographic, economic, geographic,
    health, and political data. The most well-known dataset of this type would be
    the CIA World Fact Book. Scrapping from the World Fact Book should give you more
    comprehensive and up-to-date data. However, using this dataset in CSV format would
    save you a lot of trouble when building your web scraper.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这个数据集描述了几乎所有国家的人口、经济、地理、健康和政治数据。这类数据集中最著名的可能是CIA世界概况。抓取世界概况中的数据应该会给你更多全面和最新的数据。然而，使用这个CSV格式的数据集可以在构建你的网页抓取器时节省很多麻烦。
- en: Downloading [this dataset](https://www.kaggle.com/datasets/adityakishor1/all-countries-details)
    from Kaggle (you may need to sign up an account to do so), you will find the CSV
    file [`All Countries.csv`](https://github.com/Padre-Media/dataset/raw/main/All%20Countries.csv).
    Let’s check this dataset with pandas.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 下载[Kaggle上的这个数据集](https://www.kaggle.com/datasets/adityakishor1/all-countries-details)（你可能需要注册一个账户），你会找到CSV文件[`All
    Countries.csv`](https://github.com/Padre-Media/dataset/raw/main/All%20Countries.csv)。让我们用pandas检查这个数据集。
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The above code will print a table to the screen, like the following:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码将把一个表格打印到屏幕上，如下所示：
- en: '[PRE1]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: In the above, you see the basic information of the dataset. For example, at
    the top, you know that there are 194 entries (rows) in this CSV file. And the
    table tell you there are 64 columns (indexed by number 0 to 63). Some columns
    are numeric, such as latitude, and some are not, such as capital_city. The data
    type “object” in pandas usually means it is a string type. You also know that
    there are some missing values, such as in `agricultural_land`, there are only
    193 non-null values over 194 entries, meaning there is one row with missing values
    on this column.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 在上面，你可以看到数据集的基本信息。例如，在顶部，你知道这个CSV文件中有194条记录（行）。表格告诉你有64列（从0到63索引）。一些列是数值型的，比如纬度，另一些则不是，比如capital_city。pandas中的数据类型“object”通常意味着它是字符串类型。你还知道有一些缺失值，比如在`agricultural_land`中，194条记录中只有193个非空值，这意味着这一列中有一行缺失值。
- en: 'Let’s see more detail into the dataset, such as taking the first five rows
    as a sample:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们更详细地查看数据集，例如以前五行作为样本：
- en: '[PRE2]'
  id: totrans-39
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: This will show you the first five rows of the dataset in a tabular form.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 这将以表格形式显示数据集的前五行。
- en: Your Task
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你的任务
- en: This is the basic exploration of a dataset. But using the `head()` function
    may not be always appropriate (e.g., when the input data are sorted). There are
    also `tail()` function for the similar purpose. However, running `df.sample(5)`
    would usually more helpful as it is to randomly sample 5 rows. Try with this function.
    Also, as you can see from the above output, the columns are clipped to the screen
    width. How to modify the above code to show **all** columns from the sample?
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 这是数据集的基本探索。但是，使用`head()`函数可能并不总是合适（例如，当输入数据已排序时）。还有`tail()`函数用于类似的目的。然而，运行`df.sample(5)`通常会更有帮助，因为它是随机抽取
    5 行。尝试这个函数。此外，如你从上述输出中所见，列被截断到屏幕宽度。如何修改上述代码以显示样本的**所有**列？
- en: 'Hint: There is a `to_string()` function in pandas as well as you can adjust
    the general print option `display.max_columns`.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 提示：pandas 中有一个`to_string()`函数，你也可以调整通用打印选项`display.max_columns`。
- en: In the next lesson, you will see how to check your data for missing values.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个课时，你将学习如何检查数据中的缺失值。
- en: 'Lesson 02: Missing Values'
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 课时 02：缺失值
- en: Before analyzing any data, it is important to know how the data looks like.
    In pandas, a column in floating point may represent the missing values as `NaN`
    (“not a number”) and the presence of such values will break a lot of functions.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在分析数据之前，了解数据的情况非常重要。在 pandas 中，浮点型列可能会将缺失值表示为`NaN`（“不是一个数字”），并且这些值的存在会破坏许多函数。
- en: In pandas, you can find the missing values by `isnull()` or `notnull()`. These
    functions are to check whether the value is null, which includes the Python `None`
    and floating point `NaN`. The return value is boolean. If it is applied to a column,
    you get a column of True or False. The sum would be the count of True values.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 在 pandas 中，你可以通过`isnull()`或`notnull()`来查找缺失值。这些函数用于检查值是否为 null，包括 Python 的`None`和浮点型的`NaN`。返回值为布尔值。如果应用于列，你会得到一列
    True 或 False。求和结果是 True 值的数量。
- en: In below, you use `isnull()` to find the null values, then sum the result to
    count the number of them. You can sort the result to see which columns have the
    most and the least missing values.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在下面，你可以使用`isnull()`来查找缺失值，然后对结果进行求和以计算其数量。你可以对结果进行排序，以查看哪些列缺失值最多，哪些列缺失值最少。
- en: '[PRE3]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'You will see the above prints:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 你将看到上述打印内容：
- en: '[PRE4]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: In the above, you can see that some columns have no missing value, such as the
    name of the country. The column with most of the missing values is `internally_displaced_persons`,
    which is a demographic of refugees. As you can imagine, this is not normal and
    it is reasonable that most countries have no such population. Therefore, you can
    replace the missing value with zero when you work on that. This is an example
    of imputation using your domain knowledge.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述内容中，你可以看到某些列没有缺失值，例如国家名称。缺失值最多的列是`internally_displaced_persons`，这是难民的人口统计信息。如你所见，这并不正常，合理的情况是大多数国家没有这样的群体。因此，当你处理时，可以将缺失值替换为零。这是利用领域知识进行插补的一个例子。
- en: 'To visualize missing values, you can use the Python package `missingno`. It
    is useful to display how the missing values are distributed:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可视化缺失值，你可以使用 Python 包`missingno`。它有助于展示缺失值的分布情况：
- en: '[PRE5]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: The chart from above shows that some countries (rows) and some attributes (columns)
    have a lot of missing values. You can probably guess which column in the chart
    corresponds to `internally_displaced_persons`. The countries with many missing
    values are probably because those countries are not collecting those statistics.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 上述图表显示，某些国家（行）和一些属性（列）有大量的缺失值。你可以大致猜测图表中的哪一列对应`internally_displaced_persons`。缺失值较多的国家可能是因为这些国家没有收集这些统计数据。
- en: Your Task
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你的任务
- en: Not all missing values should be replaced by zero. Another strategy is to replace
    the missing value with the mean. Can you find another attribute in this dataset
    where the missing value replaced by mean is appropriate? Further, how to replace
    the missing value in a pandas DataFrame?
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有的缺失值都应该用零来替代。另一种策略是用均值替换缺失值。你能找到这个数据集中另一个适合用均值替换缺失值的属性吗？此外，如何在 pandas DataFrame
    中替换缺失值？
- en: In the next lesson, you will see how to use basic statistics to explore the
    data.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一个课时，你将学习如何使用基本统计数据来探索数据。
- en: 'Lesson 03: Descriptive Statistics'
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 课时 03：描述性统计
- en: 'Given a pandas DataFrame, looking at the descriptive statistics is an important
    first step. In code, you can use the `describe()` function from the DataFrame:'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个 pandas DataFrame，查看描述性统计是一个重要的第一步。在代码中，你可以使用 DataFrame 的`describe()`函数：
- en: '[PRE6]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'This shows the mean, the standard deviation, the min, the max, and the quartiles
    of each **numeric** attribute. Non-numeric columns are not reported in the output.
    You can verify this by printing the set of columns and compare:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示了每个**数值**属性的均值、标准差、最小值、最大值和四分位数。非数值列不会在输出中报告。你可以通过打印列的集合并进行比较来验证这一点：
- en: '[PRE7]'
  id: totrans-63
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'There are a lot of columns in this dataset. To look at the descriptive statistics
    of a particular column, you can filter its output as it is also a DataFrame:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 数据集中有很多列。要查看某一列的描述性统计信息，你可以将其输出过滤为DataFrame：
- en: '[PRE8]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'This prints:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 这会打印：
- en: '[PRE9]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: This is the same as defining `df2=df.describe()` and then extracting with `df2["inflation"]`.
    In case of the columns with missing value, the descriptive statistics are computed
    by skipping all the missing values.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这与定义`df2=df.describe()`然后提取`df2["inflation"]`是一样的。如果列中有缺失值，描述性统计数据会通过跳过所有缺失值来计算。
- en: Your Task
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你的任务
- en: Continue from the previous example, you can tell that there are missing values
    in the `inflation` column by checking that `df["inflation"].isnull().sum()` is
    not zero. The mean can be computed using `df["inflation"].mean()`. How you can
    verify that this mean has all the missing values skipped?
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 从之前的示例继续，你可以通过检查`df["inflation"].isnull().sum()`是否为零来判断`inflation`列中是否存在缺失值。均值可以通过`df["inflation"].mean()`来计算。你怎么验证这个均值是否跳过了所有的缺失值？
- en: In the next lesson, you will see how you can further your knowledge about the
    data.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一节课中，你将看到如何进一步了解数据。
- en: 'Lesson 04: Exploring Data'
  id: totrans-72
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第04节课：数据探索
- en: The goal of data science is to tell a story from the data. Let’s see some examples
    here.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学的目标是从数据中讲述一个故事。让我们在这里看看一些示例。
- en: 'In the dataset, there’s a column `life_expectancy`. What contributes to life
    expectancy? You can make some assumptions and verify with the data. You can check
    if life expectancy varies in different region in the world:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据集中，有一列`life_expectancy`。什么因素影响寿命？你可以做一些假设并通过数据验证。你可以检查世界不同地区的寿命是否存在差异：
- en: '[PRE10]'
  id: totrans-75
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Run above and observe its output. There are some variations, but they are not
    very drastic. The `groupby()` function applied on a DataFrame is similar to the
    `GROUP BY` clause in a SQL statement. But in pandas, applying a function on a
    **groupby** needs to pay attention to the different data types in the columns.
    If you use `mean()` like above, it is to compute the mean of all columns (and
    you selected `life_expectancy` afterward), which will fail if the column is not
    numeric. Hence, you need to add an argument to limit the operation to only those
    columns.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 运行上述代码并观察其输出。存在一些差异，但并不十分剧烈。在DataFrame上应用`groupby()`函数类似于SQL语句中的`GROUP BY`子句。但是在pandas中，应用函数到**groupby**时需要注意列中的不同数据类型。如果像上面那样使用`mean()`，它会计算所有列的均值（然后你选择了`life_expectancy`），如果列不是数值型则会失败。因此，你需要添加一个参数来限制操作只针对那些列。
- en: From above, you can tell that life expectancy is not related to which part of
    the world you’re located. You can also group by continent instead of region, but
    it may not be appropriate since some continents, like Asia, are large and diverse.
    The average in those cases may not be informative.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 从上面可以看出，寿命与世界的哪个部分无关。你也可以按大洲分组，但这可能不太合适，因为某些大洲，如亚洲，既大又多样化。在这些情况下，平均值可能不具有参考价值。
- en: 'You can apply a similar operation to find not the life expectancy but the GDP
    per capita. This is the country’s GDP divided by the population, which is one
    of the metrics to tell how rich a country is. In code:'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以应用类似的操作来查找不是寿命而是人均GDP。这是国家GDP除以人口，这是一种衡量国家富裕程度的指标。在代码中：
- en: '[PRE11]'
  id: totrans-79
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: This shows a vast difference in different regions. Hence, unlike life expectancy,
    where you live is correlated to how rich you are.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 这显示了不同地区之间的巨大差异。因此，与预期寿命不同，你所在的地区与你的财富水平有关。
- en: 'Besides group by, the other useful method to explore and summarize data is
    **pivot table**. There is a function in pandas DataFrame for that. Let’s see how
    the different type of government is preferred in different regions:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 除了分组，探索和总结数据的另一个有用方法是**数据透视表**。pandas DataFrame中有一个函数可以实现这一点。让我们看看不同地区对不同类型政府的偏好：
- en: '[PRE12]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The table above shows the **count** as it is specified as the aggregate function.
    The rows (index) are “region” and the columns are the values from `democracy_type`.
    The number in each cell counts the instances of such a “democracy type” within
    the same “region.” Some values are NaN, which means there are no data to “count”
    for that combination. And since it is a count, you know it means zero.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 上表显示了**计数**，它作为汇总函数被指定。行（索引）是“区域”，列是`democracy_type`中的值。每个单元格中的数字计数了该“民主类型”在同一“区域”中的实例。一些值是
    NaN，这意味着该组合没有数据可以“计数”。由于这是计数，所以你知道它意味着零。
- en: Your Task
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你的任务
- en: Pivot table and group by are very powerful tool to summarize data and distill
    information. How can you use the pivot table above to find different regions’
    average GDP per capita and democracy types? You will see the missing values. What
    is a reasonable missing value to impute to help find the average across different
    democracy types regardless of regions?
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 数据透视表和分组是总结数据和提炼信息的非常强大的工具。你如何使用上述透视表来查找不同地区的人均 GDP 和民主类型的平均值？你会看到缺失值。为了帮助找出不同民主类型的平均值，合理的缺失值填补是什么？
- en: In the next lesson, you will learn to investigate data from plots.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一课中，你将学习如何从图表中调查数据。
- en: 'Lesson 05: Visualize Correlation'
  id: totrans-87
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 第 05 课：可视化相关性
- en: In the previous lesson, we explored the column of life expectancy and the GDP
    per capita. Are they correlated?
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一课中，我们探讨了寿命预期和人均 GDP 列。它们有相关性吗？
- en: 'There are many ways to tell whether two attributes are correlated. A scatter
    plot is a good first step because it provides visual proof. To plot the GDP per
    capita (as computed in Lesson 4 by dividing GDP and population) against the life
    expectancy, you can use the Python library Seaborn together with Matplotlib:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 有很多方法可以判断两个属性是否相关。散点图是一个很好的第一步，因为它提供了视觉证明。要将人均 GDP（如第 4 课中通过除以 GDP 和人口计算）与寿命预期绘制在一起，你可以使用
    Python 库 Seaborn 结合 Matplotlib：
- en: '[PRE13]'
  id: totrans-90
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: The argument `hue` in the scatter plot function above is optional. This colors
    the dot according to the value of another attribute, hence it is useful to tell,
    for example, Africa is pronounced in lower end of life expectancy and GDP per
    capita.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 上述散点图函数中的参数`hue`是可选的。它根据另一个属性的值为点着色，因此，它对于说明例如非洲在寿命预期和人均 GDP 低端的表现很有用。
- en: 'However, there’s a problem in the chart produced above: You cannot see any
    linear pattern and it is difficult to tell the relationship between the two attributes.
    In this case, you must **transform** the data to determine the relationship. Let’s
    try with a **semi-log plot** in which the y-axis is presented in log scale. You
    can use Matplotlib to adjust the scale:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，上述图表存在一个问题：你无法看到任何线性模式，且很难判断两个属性之间的关系。在这种情况下，你必须**转换**数据以确定关系。让我们尝试使用**半对数图**，其中
    y 轴以对数刻度呈现。你可以使用 Matplotlib 来调整刻度：
- en: '[PRE14]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: Now, it seems more plausible that life expectancy is linear with the log of
    GDP per capita.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，看起来寿命预期与人均 GDP 对数是线性的更有可能。
- en: 'Numerically, you can compute the correlation factor between log of GDP per
    capita and life expectancy. A correlation factor close to +1 or -1 means the correlation
    is strong. Uncorrelated attributes would demonstrate a correlation factor close
    to zero. You can find the strongest correlated factors among all numerical attributes
    using pandas:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 从数值上，你可以计算人均 GDP 对数和寿命预期之间的相关因子。相关因子接近 +1 或 -1 意味着相关性强。无相关的属性将显示接近零的相关因子。你可以使用
    pandas 查找所有数值属性中相关性最强的因子。
- en: '[PRE15]'
  id: totrans-96
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: The code above finds the top 6 correlated attributes to life expectancy. It
    is regardless of positive or negative correlation since the sorting is based on
    the absolute value. Life expectancy itself should be at the top of the list by
    definition since anything has a correlation 1 with itself.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码找出了与寿命预期最相关的前 6 个属性。无论是正相关还是负相关，因为排序是基于绝对值的。根据定义，寿命预期本身应该排在列表的最顶部，因为任何东西与自己具有相关性
    1。
- en: 'You can create a correlogram using Seaborn to show the scatterplot between
    any pair of them:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 Seaborn 创建一个相关图，以显示任意一对属性之间的散点图：
- en: '[PRE16]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: A correlogram helps you quickly visualize what is correlated. For example, the
    self-employed percentage strongly correlates to the vulnerable employment percentage.
    The birth rate is negatively correlated to life expectancy (maybe because the
    older age, the less likely a person is to give birth). The histogram in the diagonal
    shows how that attribute is distributed.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 相关图帮助你快速可视化相关性。例如，自雇百分比与脆弱就业百分比高度相关。出生率与预期寿命呈负相关（也许因为年龄越大，人们生育的可能性越小）。对角线上的直方图显示了该属性的分布情况。
- en: Your Task
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你的任务
- en: A scatter plot is a powerful tool, especially when you have a computer to help
    you make one. In above, you established how two attributes are correlated visually,
    but **correlation is not causation**. To establish causality, you need more evidence.
    In statistics, there are nine “Bradford Hill criteria” that are famous in epidemiology.
    A simpler and weaker formulation are the two principles of Granger causality.
    Look at the data you have and compare to the Granger causality principles, what
    additional data is required to prove that life expectancy is **caused** by GDP
    per capita?
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 散点图是一个强大的工具，特别是当你有计算机来帮助你制作时。上面，你已经通过视觉展示了两个属性之间的相关性，但**相关性不等于因果关系**。要建立因果关系，你需要更多的证据。在统计学中，有九项在流行病学中非常著名的“布拉德福德·希尔标准”。一个更简单且较弱的表述是格兰杰因果关系的两个原则。查看你拥有的数据，并与格兰杰因果关系原则进行比较，证明预期寿命是由人均GDP**引起**的需要哪些额外数据？
- en: In the next lesson, you will use statistical tests against your data.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一课中，你将使用统计测试来分析你的数据。
- en: 'Lesson 06: Hypothesis Testing'
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 课程06：假设检验
- en: Since data science is to tell a story, how you can back up your claim is central
    to your work in a data science project.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 由于数据科学的任务是讲述故事，因此支持你的主张是数据科学项目中的核心工作。
- en: 'Let’s focus on life expectancy again: Urbanization is key to improving life
    expectancy since it also correlates with advanced medicine, hygiene, and immunization.
    How do you prove that?'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们再次关注预期寿命：城市化是提高预期寿命的关键，因为它还与先进的医学、卫生和免疫接种相关。你如何证明这一点？
- en: 'An easy way is to show two histograms of life expectancy, separating that for
    more urbanized countries and those that are not. Let’s define an urban country
    with more than 50% urban population. You can compute the population percentage
    using pandas, then separate the dataset into two:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 一个简单的方法是展示两个预期寿命的直方图，一个是针对更多城市化国家的，另一个是针对非城市化国家的。让我们定义一个城市国家为城市人口超过50%的国家。你可以使用pandas计算人口百分比，然后将数据集分为两个部分：
- en: '[PRE17]'
  id: totrans-108
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Then, you can create an overlapped histogram to show the life expectancy:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，你可以创建一个重叠的直方图来显示预期寿命：
- en: '[PRE18]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: 'This confirms the hypothesis above that urban countries have a higher life
    expectancy. However, a chart is not very strong evidence. The better way is to
    apply some statistical tests to quantify the strength of our claim. You want to
    compare the **mean life expectancy** between two independent groups, hence the
    t-test is appropriate. You can run a t-test using the SciPy package as follows:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 这证实了上述假设，即城市国家具有更高的预期寿命。然而，图表不是很有力的证据。更好的方法是应用一些统计测试来量化我们的主张的强度。你需要比较两个独立组之间的**均值预期寿命**，因此t检验是合适的。你可以使用SciPy包运行t检验，如下所示：
- en: '[PRE19]'
  id: totrans-112
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: Unlike Matplotlib, which will ignore the missing values, SciPy will not compute
    the statistics if any NaN exists in the provided data. Hence, above, you clean
    up the data by removing the missing values and re-create the DataFrames `df_urban`
    and `df_rural`. The t-test provided a p-value of 1.6×10^(-10), which is very small.
    Hence, the **null hypothesis** is rejected, i.e., rejecting that the two groups
    shared the same mean. But this t-test is not telling whether `df_urban` or `df_rural`
    his the higher mean. You can easily tell by computing the mean separately afterward.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 与Matplotlib不同，Matplotlib会忽略缺失值，而SciPy在提供的数据中存在任何NaN时不会计算统计数据。因此，上面你通过移除缺失值来清理数据，并重新创建`df_urban`和`df_rural`数据框。t检验提供了一个1.6×10^(-10)的p值，这个值非常小。因此，**零假设**被拒绝，即拒绝两个组的均值相同。但这个t检验并没有告诉我们`df_urban`或`df_rural`的均值更高。你可以通过分别计算均值来轻松确定。
- en: Your Task
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你的任务
- en: Instead of re-creating the DataFrames `df_urban` and `df_rural`, you can make
    the t-test from SciPy work by filling in the missing values with their respective
    mean. Try this out. How is the p-value changed? Does it change your conclusion?
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 与重新创建`df_urban`和`df_rural`数据框不同，你可以通过用各自的均值填补缺失值来使SciPy的t检验正常工作。尝试一下。这会改变p值吗？这改变了你的结论吗？
- en: In the next lesson, you will find outliers from the data.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在下一课中，你将从数据中发现异常值。
- en: 'Lesson 07: Identifying Outliers'
  id: totrans-117
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 课程07：识别异常值
- en: An outlier is a sample that is very different from the majority, making it very
    hard to consider as part of the larger group.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 异常值是与大多数样本非常不同的样本，这使得它很难被视为更大群体的一部分。
- en: The most well-known way of identifying outliers is the 68-95-99 rule of normal
    distribution, which says one, two, and three standard deviations away from the
    mean covering 68%, 95%, and 99% of the samples respectively. Usually, a sample
    2 SD away from the mean is far enough to be considered an outlier. Let’s see if
    any country’s life expectancy is an outlier.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 识别异常值最著名的方法是正态分布的68-95-99规则，该规则指出距离均值一个、两个和三个标准差分别覆盖68%、95%和99%的样本。通常，一个距离均值2个标准差的样本被认为是足够远的异常值。我们来看看是否有哪个国家的预期寿命是异常值。
- en: 'Before you use the 68-95-99 rule, you want to transform the data closer to
    normal distribution. One way is to use Box-Cox transform. You know the transform
    works well if you compare the **skewness** before and after the transform. The
    perfect normal distribution has a skewness zero:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在使用68-95-99规则之前，你需要将数据转换得更接近正态分布。一个方法是使用Box-Cox变换。你可以通过比较变换前后的**偏度**来判断变换效果是否良好。完美的正态分布偏度为零：
- en: '[PRE20]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'After the Box-Cox transform, the skewness changed from 0.137 to -0.006, which
    is closer to zero. The lambda value computed with the Box-Cox transform will be
    useful later. As a sidenote, you can verify that the transformed data is roughly
    symmetric:'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在Box-Cox变换后，偏度从0.137变化为-0.006，更接近于零。通过Box-Cox变换计算的lambda值在后续会很有用。顺便提一下，你可以验证变换后的数据大致对称：
- en: '[PRE21]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'Assuming the Box-Cox transformed data follows normal distribution, we can easily
    find what is 2 SD below and above the mean. But that is in the transformed data.
    Recall that Box-Cox transform is to transform *y* into w=(*y*^λ – 1)/λ. Hence
    we can perform the inverse transform with (wλ + 1)^(1/λ):'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 假设Box-Cox变换后的数据符合正态分布，我们可以很容易找到均值上下2个标准差的位置。但这只是变换后的数据。回忆一下Box-Cox变换是将*y*转换为w=(*y*^λ
    – 1)/λ。因此，我们可以通过 (wλ + 1)^(1/λ) 进行反变换：
- en: '[PRE22]'
  id: totrans-125
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'These are the lowerbound and upperbound for what is **not** outlier among the
    countries with the more rural population. Let’s see whether there is any country
    outside this range:'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这些是对于具有更多农村人口的国家来说，**不**是异常值的下界和上界。我们来看看是否有国家在这个范围之外：
- en: '[PRE23]'
  id: totrans-127
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: So Liechtenstein is an outlier at the upper end, while Chad and Lesotho are
    at the lower end. This test only points out these outliers to you without any
    explanation. You will need to look further into the data to hypothesize why these
    are the cases. But this is a typical workflow in data science.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 所以列支敦士登在上端是异常值，而乍得和莱索托在下端。这次测试只是指出了这些异常值，没有任何解释。你需要进一步研究数据，以假设为什么会出现这些情况。这是数据科学中的典型工作流程。
- en: Your Task
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 你的任务
- en: You can repeat this on  `df_urban` to find which urban countries are the outliers.
    How many countries are outliers at the lower and upper end?
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以对`df_urban`重复这个操作，找出哪些城市国家是异常值。在上下端有多少个国家是异常值？
- en: This was the final lesson.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是最后一课。
- en: The End! (*Look How Far You Have Come*)
  id: totrans-132
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结束了！(*看看你已经走了多远*)
- en: You made it. Well done!
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 你做到了。做得好！
- en: Take a moment and look back at how far you have come.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 花一点时间回顾一下你已经取得的进展。
- en: You discovered pandas, missingno, scipy, seaborn, and matplotlib as the Python
    libraries to help you finish a data science project.
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你发现了pandas、missingno、scipy、seaborn和matplotlib作为帮助你完成数据科学项目的Python库。
- en: With basic statistics, you can explore your dataset for insights. You can also
    confirm your hypothesis from your data.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用基本统计学，你可以从数据集中探索洞察。你也可以从数据中确认你的假设。
- en: You see how you can explore data using visuals such as scatter plot, and also
    using statistical tests.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你了解了如何通过散点图等可视化工具以及统计测试来探索数据。
- en: You know how transforming data can help you extract information from data, such
    as finding the outliers.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 你知道数据变换如何帮助你从数据中提取信息，比如发现异常值。
- en: Don’t make light of this; you have come a long way in a short time. This is
    just the beginning of your data science journey. Keep practicing and developing
    your skills.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 不要小看这一点；你在短时间内取得了长足的进步。这只是你数据科学旅程的开始。继续练习并提升你的技能。
- en: Summary
  id: totrans-140
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: '**How did you do with the mini-course?**'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: '**你在这个迷你课程中表现如何？**'
- en: Did you enjoy this crash course?
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 你喜欢这个速成课程吗？
- en: '**Do you have any questions? Were there any sticking points?**'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '**你有任何问题吗？有没有遇到什么难点？**'
- en: Let me know. Leave a comment below.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 告诉我。请在下方留言。
