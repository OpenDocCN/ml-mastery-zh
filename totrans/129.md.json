["```py\nimport torch\nimport torch.optim as optim\nimport torch.optim.lr_scheduler as lr_scheduler\n\nscheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.3, total_iters=10)\n```", "```py\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\n# load dataset, split into input (X) and output (y) variables\ndataframe = pd.read_csv(\"ionosphere.csv\", header=None)\ndataset = dataframe.values\nX = dataset[:,0:34].astype(float)\ny = dataset[:,34]\n\n# encode class values as integers\nencoder = LabelEncoder()\nencoder.fit(y)\ny = encoder.transform(y)\n\n# convert into PyTorch tensors\nX = torch.tensor(X, dtype=torch.float32)\ny = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n\n# train-test split for evaluation of the model\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n\n# create model\nmodel = nn.Sequential(\n    nn.Linear(34, 34),\n    nn.ReLU(),\n    nn.Linear(34, 1),\n    nn.Sigmoid()\n)\n\n# Train the model\nn_epochs = 50\nbatch_size = 24\nbatch_start = torch.arange(0, len(X_train), batch_size)\nlr = 0.1\nloss_fn = nn.BCELoss()\noptimizer = optim.SGD(model.parameters(), lr=lr)\nmodel.train()\nfor epoch in range(n_epochs):\n    for start in batch_start:\n        X_batch = X_train[start:start+batch_size]\n        y_batch = y_train[start:start+batch_size]\n        y_pred = model(X_batch)\n        loss = loss_fn(y_pred, y_batch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    print(\"Epoch %d: SGD lr=%.4f\" % (epoch, optimizer.param_groups[0][\"lr\"]))\n\n# evaluate accuracy after training\nmodel.eval()\ny_pred = model(X_test)\nacc = (y_pred.round() == y_test).float().mean()\nacc = float(acc)\nprint(\"Model accuracy: %.2f%%\" % (acc*100))\n```", "```py\nEpoch 0: SGD lr=0.1000\nEpoch 1: SGD lr=0.1000\nEpoch 2: SGD lr=0.1000\nEpoch 3: SGD lr=0.1000\nEpoch 4: SGD lr=0.1000\n...\nEpoch 45: SGD lr=0.1000\nEpoch 46: SGD lr=0.1000\nEpoch 47: SGD lr=0.1000\nEpoch 48: SGD lr=0.1000\nEpoch 49: SGD lr=0.1000\nModel accuracy: 86.79%\n```", "```py\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.optim.lr_scheduler as lr_scheduler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\n# load dataset, split into input (X) and output (y) variables\ndataframe = pd.read_csv(\"ionosphere.csv\", header=None)\ndataset = dataframe.values\nX = dataset[:,0:34].astype(float)\ny = dataset[:,34]\n\n# encode class values as integers\nencoder = LabelEncoder()\nencoder.fit(y)\ny = encoder.transform(y)\n\n# convert into PyTorch tensors\nX = torch.tensor(X, dtype=torch.float32)\ny = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n\n# train-test split for evaluation of the model\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n\n# create model\nmodel = nn.Sequential(\n    nn.Linear(34, 34),\n    nn.ReLU(),\n    nn.Linear(34, 1),\n    nn.Sigmoid()\n)\n\n# Train the model\nn_epochs = 50\nbatch_size = 24\nbatch_start = torch.arange(0, len(X_train), batch_size)\nlr = 0.1\nloss_fn = nn.BCELoss()\noptimizer = optim.SGD(model.parameters(), lr=lr)\nscheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.5, total_iters=30)\nmodel.train()\nfor epoch in range(n_epochs):\n    for start in batch_start:\n        X_batch = X_train[start:start+batch_size]\n        y_batch = y_train[start:start+batch_size]\n        y_pred = model(X_batch)\n        loss = loss_fn(y_pred, y_batch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    before_lr = optimizer.param_groups[0][\"lr\"]\n    scheduler.step()\n    after_lr = optimizer.param_groups[0][\"lr\"]\n    print(\"Epoch %d: SGD lr %.4f -> %.4f\" % (epoch, before_lr, after_lr))\n\n# evaluate accuracy after training\nmodel.eval()\ny_pred = model(X_test)\nacc = (y_pred.round() == y_test).float().mean()\nacc = float(acc)\nprint(\"Model accuracy: %.2f%%\" % (acc*100))\n```", "```py\nEpoch 0: SGD lr 0.1000 -> 0.0983\nEpoch 1: SGD lr 0.0983 -> 0.0967\nEpoch 2: SGD lr 0.0967 -> 0.0950\nEpoch 3: SGD lr 0.0950 -> 0.0933\nEpoch 4: SGD lr 0.0933 -> 0.0917\n...\nEpoch 28: SGD lr 0.0533 -> 0.0517\nEpoch 29: SGD lr 0.0517 -> 0.0500\nEpoch 30: SGD lr 0.0500 -> 0.0500\nEpoch 31: SGD lr 0.0500 -> 0.0500\n...\nEpoch 48: SGD lr 0.0500 -> 0.0500\nEpoch 49: SGD lr 0.0500 -> 0.0500\nModel accuracy: 88.68%\n```", "```py\nscheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n```", "```py\nEpoch 0: SGD lr 0.1000 -> 0.0990\nEpoch 1: SGD lr 0.0990 -> 0.0980\nEpoch 2: SGD lr 0.0980 -> 0.0970\nEpoch 3: SGD lr 0.0970 -> 0.0961\nEpoch 4: SGD lr 0.0961 -> 0.0951\n...\nEpoch 45: SGD lr 0.0636 -> 0.0630\nEpoch 46: SGD lr 0.0630 -> 0.0624\nEpoch 47: SGD lr 0.0624 -> 0.0617\nEpoch 48: SGD lr 0.0617 -> 0.0611\nEpoch 49: SGD lr 0.0611 -> 0.0605\n```", "```py\ndef lr_lambda(epoch):\n    # LR to be 0.1 * (1/1+0.01*epoch)\n    base_lr = 0.1\n    factor = 0.01\n    return base_lr/(1+factor*epoch)\n```", "```py\nscheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda)\n```", "```py\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.optim.lr_scheduler as lr_scheduler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\n# load dataset, split into input (X) and output (y) variables\ndataframe = pd.read_csv(\"ionosphere.csv\", header=None)\ndataset = dataframe.values\nX = dataset[:,0:34].astype(float)\ny = dataset[:,34]\n\n# encode class values as integers\nencoder = LabelEncoder()\nencoder.fit(y)\ny = encoder.transform(y)\n\n# convert into PyTorch tensors\nX = torch.tensor(X, dtype=torch.float32)\ny = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n\n# train-test split for evaluation of the model\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n\n# create model\nmodel = nn.Sequential(\n    nn.Linear(34, 34),\n    nn.ReLU(),\n    nn.Linear(34, 1),\n    nn.Sigmoid()\n)\n\ndef lr_lambda(epoch):\n    # LR to be 0.1 * (1/1+0.01*epoch)\n    base_lr = 0.1\n    factor = 0.01\n    return base_lr/(1+factor*epoch)\n\n# Train the model\nn_epochs = 50\nbatch_size = 24\nbatch_start = torch.arange(0, len(X_train), batch_size)\nlr = 0.1\nloss_fn = nn.BCELoss()\noptimizer = optim.SGD(model.parameters(), lr=lr)\nscheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda)\nmodel.train()\nfor epoch in range(n_epochs):\n    for start in batch_start:\n        X_batch = X_train[start:start+batch_size]\n        y_batch = y_train[start:start+batch_size]\n        y_pred = model(X_batch)\n        loss = loss_fn(y_pred, y_batch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    before_lr = optimizer.param_groups[0][\"lr\"]\n    scheduler.step()\n    after_lr = optimizer.param_groups[0][\"lr\"]\n    print(\"Epoch %d: SGD lr %.4f -> %.4f\" % (epoch, before_lr, after_lr))\n\n# evaluate accuracy after training\nmodel.eval()\ny_pred = model(X_test)\nacc = (y_pred.round() == y_test).float().mean()\nacc = float(acc)\nprint(\"Model accuracy: %.2f%%\" % (acc*100))\n```", "```py\nEpoch 0: SGD lr 0.0100 -> 0.0099\nEpoch 1: SGD lr 0.0099 -> 0.0098\nEpoch 2: SGD lr 0.0098 -> 0.0097\nEpoch 3: SGD lr 0.0097 -> 0.0096\nEpoch 4: SGD lr 0.0096 -> 0.0095\n...\nEpoch 45: SGD lr 0.0069 -> 0.0068\nEpoch 46: SGD lr 0.0068 -> 0.0068\nEpoch 47: SGD lr 0.0068 -> 0.0068\nEpoch 48: SGD lr 0.0068 -> 0.0067\nEpoch 49: SGD lr 0.0067 -> 0.0067\n```"]