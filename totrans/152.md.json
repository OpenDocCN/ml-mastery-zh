["```py\nimport torch\ntorch.manual_seed(42)\n\n# define the class for multilinear regression\nclass MLR(torch.nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super().__init__()\n        self.linear = torch.nn.Linear(input_dim, output_dim)\n    def forward(self,x):\n        y_pred = self.linear(x)\n        return y_pred\n```", "```py\n...\n# building the model object\nmodel = MLR(1, 5)\n```", "```py\n...\n# define the single input sample 'x' and make predictions\nx = torch.tensor([[2.0]])\ny_pred = model(x)\nprint(y_pred)\n```", "```py\ntensor([[ 1.7309,  1.1732,  0.1187,  2.7188, -1.1718]],\n       grad_fn=<AddmmBackward0>)\n```", "```py\n...\nprint(list(model.parameters()))\n```", "```py\n[Parameter containing:\n tensor([[ 0.7645],\n         [ 0.8300],\n         [-0.2343],\n         [ 0.9186],\n         [-0.2191]], requires_grad=True),\n Parameter containing:\n tensor([ 0.2018, -0.4869,  0.5873,  0.8815, -0.7336], requires_grad=True)]\n```", "```py\n# define the multiple input tensor 'x' and make predictions\nX = torch.tensor([[2.0],[4.0],[6.0]])\n```", "```py\n...\nY_pred = model(X)\nprint(Y_pred)\n```", "```py\ntensor([[ 1.7309,  1.1732,  0.1187,  2.7188, -1.1718],\n        [ 3.2599,  2.8332, -0.3498,  4.5560, -1.6100],\n        [ 4.7890,  4.4932, -0.8184,  6.3932, -2.0482]],\n       grad_fn=<AddmmBackward0>)\n```", "```py\nimport torch\ntorch.manual_seed(42)\n\n# define the class for multilinear regression\nclass MLR(torch.nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super().__init__()\n        self.linear = torch.nn.Linear(input_dim, output_dim)\n    def forward(self,x):\n        y_pred = self.linear(x)\n        return y_pred\n\n# building the model object\nmodel = MLR(1, 5)\n\n# define the single input sample 'x' and make predictions\nx = torch.tensor([[2.0]])\ny_pred = model(x)\nprint(y_pred)\nprint(list(model.parameters()))\n\n# define the multiple input tensor 'x' and make predictions\nX = torch.tensor([[2.0],[4.0],[6.0]])\nY_pred = model(X)\nprint(Y_pred)\n```"]