- en: 'The Da Vinci Code of Data: Mastering The Data Science Mind Map'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 数据的达芬奇密码：掌握数据科学思维导图
- en: 原文：[https://machinelearningmastery.com/the-da-vinci-code-of-data-mastering-the-data-science-mind-map/](https://machinelearningmastery.com/the-da-vinci-code-of-data-mastering-the-data-science-mind-map/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://machinelearningmastery.com/the-da-vinci-code-of-data-mastering-the-data-science-mind-map/](https://machinelearningmastery.com/the-da-vinci-code-of-data-mastering-the-data-science-mind-map/)
- en: Data Science embodies a delicate balance between the art of visual storytelling,
    the precision of statistical analysis, and the foundational bedrock of data preparation,
    transformation, and analysis. The intersection of these domains is where true
    data alchemy happens – transforming and interpreting data to tell compelling stories
    that drive decision-making and knowledge discovery. Just as Leonardo da Vinci
    masterfully blended scientific observation with artistic genius, we will explore
    how the art of storytelling in data science can illuminate insights with the same
    precision and beauty. In this post, we will navigate through our Data Science
    Mind Map to unpack and simplify this process while providing links that showcase
    concrete examples.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学体现了视觉叙事艺术、统计分析精确性以及数据准备、转换和分析的基础之间的微妙平衡。这些领域的交汇点是真正的数据炼金术发生的地方——将数据转化和解释成引人入胜的故事，以驱动决策制定和知识发现。正如莱昂纳多·达芬奇巧妙地将科学观察与艺术天赋融合在一起，我们将探讨数据科学中的叙事艺术如何以同样的精确性和美感揭示洞察。在这篇文章中，我们将通过数据科学思维导图来解开并简化这一过程，同时提供展示具体示例的链接。
- en: Let’s get started.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: '![](../Images/1493f611af9724f2f938803b0c185ab8.png)'
  id: totrans-4
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1493f611af9724f2f938803b0c185ab8.png)'
- en: 'The Da Vinci Code of Data: Mastering The Data Science Mind Map'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的达芬奇密码：掌握数据科学思维导图
- en: Photo by [Alexandre Debiève](https://unsplash.com/photos/macro-photography-of-black-circuit-board-FO7JIlwjOtU).
    Some rights reserved.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 图片来源：[亚历山大·德比耶夫](https://unsplash.com/photos/macro-photography-of-black-circuit-board-FO7JIlwjOtU)。保留所有权利。
- en: Overview
  id: totrans-7
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'This post is divided into two parts; they are:'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 本文分为两个部分；它们是：
- en: Mastering The Data Science Mind Map
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 掌握数据科学思维导图
- en: The Art of Storytelling in Data Science
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据科学中的叙事艺术
- en: Mastering The Data Science Mind Map
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 掌握数据科学思维导图
- en: 'In our quest to master the Data Science Mind Map, we emphasize the critical
    importance of the foundational Python packages that every data scientist should
    be familiar with. These packages form the pillars of our Mind Map, representing
    the triad of essential skills: data preparation, visualization, and statistical
    analysis. They are tools and building blocks that enable us to transform raw data
    into a compelling narrative. As we proceed, we will delve into each package’s
    unique role and its dual or singular functions within the data science workflow,
    exploring their synergy and individual strengths in crafting data stories.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们追求掌握数据科学思维导图的过程中，我们强调每个数据科学家都应该熟悉的基础Python包的重要性。这些包构成了我们思维导图的支柱，代表了必备技能的三位一体：数据准备、可视化和统计分析。它们是将原始数据转化为引人入胜叙事的工具和构建块。随着我们的深入，我们将探讨每个包在数据科学工作流程中的独特作用及其双重或单一功能，探索它们在讲述数据故事中的协同作用和各自的优势。
- en: '[![](../Images/3eda0b201a080fe2992126c4caddf555.png)](https://machinelearningmastery.com/the-da-vinci-code-of-data-mastering-the-data-science-mind-map/screenshot-2024-03-08-at-00-31-11/)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[![](../Images/3eda0b201a080fe2992126c4caddf555.png)](https://machinelearningmastery.com/the-da-vinci-code-of-data-mastering-the-data-science-mind-map/screenshot-2024-03-08-at-00-31-11/)'
- en: '**`Pandas`**: The brainchild of [Wes McKinney](https://en.wikipedia.org/wiki/Wes_McKinney),
    `pandas` stands out as a foundation for data wrangling and as a bridge to statistical
    analysis. In `pandas`, the `DataFrame` is not just a data structure; it is the
    cornerstone upon which data manipulation, transformation, and analysis are built.
    This two-dimensional, size-mutable, and potentially heterogeneous tabular data
    structure is akin to a spreadsheet loaded right into Python. With its rows and
    columns neatly organized, the `DataFrame` makes data operations both intuitive
    and efficient. Each method, whether it’s `DataFrame.describe()` for statistical
    summaries, `DataFrame.groupby()` for aggregation, or `DataFrame.pivot_tables()`
    for advanced reshaping, is applied to a `DataFrame`, unlocking the full potential
    of your data. As shown in our detailed post on [decoding data with descriptive
    statistics](https://machinelearningmastery.com/decoding-data-descriptive-statistics/),
    `pandas` allows you to distill complex datasets into meaningful statistics efficiently,
    a vital step before any further analysis. Moreover, understanding data types is
    pivotal, as it determines the type of analysis you can perform. Our post on [classifying
    variables](https://machinelearningmastery.com/classifying_variables/) guides you
    through this critical stage, where methods like `DataFrame.dtypes` and `DataFrame.select_dtypes()`
    in `pandas` facilitate the discernment and manipulation of different data categories.
    The `DataFrame.query()` function lets you filter with ease, making complex SQL-like
    querying in Python a breeze, and offering a more dynamic approach to data manipulation.
    For more in-depth examples and applications of these methods, consider exploring
    the insights in the posts on transforming real estate data and harmonizing data
    techniques [here](https://machinelearningmastery.com/harmonizing-data-a-symphony-of-segmenting-concatenating-pivoting-and-merging/).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '**`Pandas`**：由[Wes McKinney](https://en.wikipedia.org/wiki/Wes_McKinney)创立的**`pandas`**，是数据整理的基础，并且是统计分析的桥梁。在`pandas`中，`DataFrame`不仅仅是一个数据结构；它是数据操作、转换和分析的基石。这个二维、可变大小、且潜在异质的表格数据结构类似于直接加载到Python中的电子表格。`DataFrame`的行和列整齐地组织，使得数据操作既直观又高效。每个方法，无论是用于统计摘要的`DataFrame.describe()`，还是用于聚合的`DataFrame.groupby()`，或者用于高级重塑的`DataFrame.pivot_tables()`，都是应用于`DataFrame`，充分挖掘数据的潜力。正如我们在[解码数据的描述性统计](https://machinelearningmastery.com/decoding-data-descriptive-statistics/)中详细介绍的那样，`pandas`允许你高效地将复杂的数据集提炼成有意义的统计数据，这是进一步分析的关键步骤。此外，理解数据类型至关重要，因为它决定了你可以进行的分析类型。我们在[变量分类](https://machinelearningmastery.com/classifying_variables/)的帖子中引导你完成这个关键阶段，其中`pandas`中的`DataFrame.dtypes`和`DataFrame.select_dtypes()`方法有助于辨别和操作不同的数据类别。`DataFrame.query()`函数让你轻松筛选，使得在Python中进行复杂的类似SQL查询变得轻松，并提供了一种更动态的数据操作方式。有关这些方法的更多深入示例和应用，建议你探索关于房地产数据转换和数据技术协调的帖子[这里](https://machinelearningmastery.com/harmonizing-data-a-symphony-of-segmenting-concatenating-pivoting-and-merging/)。'
- en: '**`Numpy`**: A foundational library for numerical computation in Python, enabling
    data scientists to perform complex mathematical calculations and data manipulation
    with ease and speed. In our post on [hypothesis testing](https://machinelearningmastery.com/a-dive-into-hypothesis-testing/),
    we leveraged `numpy` to efficiently calculate key statistical measures such as
    the mean, serving as a pivotal step in setting the groundwork for conducting hypothesis
    tests. While `pandas` excels at handling tabular data, `numpy` follows suit by
    providing support for arrays, forming a formidable duo in the data science toolkit.'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '**`Numpy`**：一个用于Python的基础库，支持数值计算，使数据科学家能够轻松快速地进行复杂的数学计算和数据操作。在我们关于[假设检验](https://machinelearningmastery.com/a-dive-into-hypothesis-testing/)的帖子中，我们利用`numpy`高效地计算关键统计指标，如均值，这为进行假设检验奠定了基础。虽然`pandas`擅长处理表格数据，`numpy`则通过提供对数组的支持，形成了数据科学工具包中的强大组合。'
- en: '**`Sklearn.preprocessing`**: Despite the depth of this series not extending
    into machine learning, it’s worthwhile to highlight `sklearn.preprocessing` for
    its role in data transformations, specifically with the `QuantileTransformer()`.
    This technique was demonstrated in our post that discussed [how to combat skew](https://machinelearningmastery.com/skewness-be-gone-transformative-tricks-for-data-scientists/).'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '**`Sklearn.preprocessing`**: 尽管这一系列内容未涉及机器学习的深度，但值得强调的是`sklearn.preprocessing`在数据转换中的作用，特别是`QuantileTransformer()`。这一技术在我们讨论了[如何对抗偏态](https://machinelearningmastery.com/skewness-be-gone-transformative-tricks-for-data-scientists/)的帖子中进行了演示。'
- en: '**`Missingno`**: The`missingno` package uniquely bridges the gap between preprocessing,
    analysis, and visualization in the data science workflow. It specializes in providing
    a graphical representation of missing data within a dataset, thus serving a dual
    function: it aids in the early stages of data cleaning and preparation by visually
    identifying patterns of missingness, and it also facilitates exploratory data
    analysis by revealing underlying structures or anomalies that could influence
    subsequent statistical analyses. In our post, [Revealing the Invisible: A Guide
    to Missing Data in Python](https://machinelearningmastery.com/revealing_the_invisible/),
    we delve into how `missingno` can be used to efficiently detect and handle missing
    data, demonstrating its critical role in ensuring the integrity and robustness
    of your data science projects. Through intuitive visualizations, `missingno` not
    only enhances data preprocessing but also enriches the analytical narrative by
    shedding light on aspects of the data that often remain obscured.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '**`Missingno`**: `missingno`包独特地弥合了数据科学工作流程中预处理、分析和可视化之间的差距。它专注于提供数据集中缺失数据的图形表示，从而发挥双重功能：它通过可视化缺失模式帮助数据清理和准备的早期阶段，同时也通过揭示潜在结构或异常促进探索性数据分析，这些结构或异常可能会影响后续统计分析。在我们的帖子[揭示隐形数据：Python中缺失数据的指南](https://machinelearningmastery.com/revealing_the_invisible/)中，我们深入探讨了如何高效检测和处理缺失数据，展示了其在确保数据科学项目的完整性和鲁棒性中的关键作用。通过直观的可视化，`missingno`不仅增强了数据预处理，还通过揭示数据中常被忽视的方面丰富了分析叙事。'
- en: '**`Geopandas`**: This package extends the functionalities of `pandas` into
    the realm of geospatial data, making it an indispensable tool for both data preprocessing
    and visualization in geographical contexts. It allows data scientists to easily
    manipulate and analyze spatial data, integrating seamlessly with other Python
    libraries for geospatial analysis. With `Geopandas`, you can perform sophisticated
    spatial operations, merge spatial datasets, and conduct spatial joins, all while
    maintaining the familiar `pandas` DataFrame structure. This capability ensures
    that handling geospatial data is as intuitive as working with tabular data. Moreover,
    `Geopandas` excels in visualizing geospatial data, enabling the creation of maps
    that can reveal compelling insights into geographical patterns and relationships.
    In our post, [From Data to Map: Mastering Geospatial Analysis with Python](https://machinelearningmastery.com/data-to-map-geospatial/),
    we showcase how `Geopandas` can transform raw geospatial data into informative
    maps, highlighting its dual role in both preprocessing and visually interpreting
    spatial data within the data science workflow.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '**`Geopandas`**: 该包将`pandas`的功能扩展到地理空间数据领域，使其成为地理上下文中数据预处理和可视化的不可或缺的工具。它允许数据科学家轻松操作和分析空间数据，与其他Python地理空间分析库无缝集成。使用`Geopandas`，你可以执行复杂的空间操作、合并空间数据集以及进行空间连接，同时保持熟悉的`pandas`
    DataFrame结构。这一能力确保了处理地理空间数据如同处理表格数据般直观。此外，`Geopandas`在可视化地理空间数据方面表现出色，能够创建揭示地理模式和关系的地图。在我们的帖子[从数据到地图：掌握Python地理空间分析](https://machinelearningmastery.com/data-to-map-geospatial/)中，我们展示了`Geopandas`如何将原始地理空间数据转换为信息丰富的地图，突出了其在数据科学工作流程中预处理和视觉解读空间数据的双重角色。'
- en: '**`Folium`**: Specializing in the singular role of creating interactive maps,
    `folium` leverages the mapping strengths of the Leaflet.js library within the
    Python environment. It excels at building rich, interactive geospatial visualizations,
    allowing for the dynamic representation of data overlaid on maps. This capability
    is invaluable for projects requiring intuitive spatial data exploration and presentation,
    making `folium` a go-to library for [geospatial mapping](https://machinelearningmastery.com/finding-value-with-data-the-cohesive-force-behind-luxury-real-estate-decisions/).'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**`Folium`**: 专注于创建交互式地图的独特角色，`folium` 在 Python 环境中利用了 Leaflet.js 库的映射优势。它擅长构建丰富的互动地理空间可视化，允许在地图上动态表示数据。这一能力对于需要直观空间数据探索和展示的项目至关重要，使
    `folium` 成为[地理空间映射](https://machinelearningmastery.com/finding-value-with-data-the-cohesive-force-behind-luxury-real-estate-decisions/)的首选库。'
- en: '**`Matplotlib`** and **`Seaborn`**: These two packages emerge as pivotal threads,
    interwoven to enhance the fabric of analytical storytelling. `Matplotlib`, the
    foundational library, offers extensive flexibility and control, laying the groundwork
    for creating a wide array of static, animated, and interactive visualizations.
    It serves as the bedrock upon which `seaborn` is built, with the latter extending
    `matplotlib`‘s capabilities by offering a high-level interface for drawing attractive
    and informative statistical graphics. `seaborn` specializes in making complex
    visualizations accessible, integrating tightly with `pandas` DataFrames to streamline
    the process from data manipulation to representation. This synergy is particularly
    evident when exploring feature relationships and uncovering patterns within datasets,
    as `seaborn`‘s advanced plotting functions, like pair plots, build upon `matplotlib`‘s
    foundational structures to provide richer, more insightful visual narratives.
    Our posts on [exploring feature relationships](https://machinelearningmastery.com/feature-relationships-101/)
    and [utilizing pair plots](https://machinelearningmastery.com/pair-plots/) delve
    into how `seaborn` and `matplotlib`, in conjunction with `pandas`, form a cohesive
    visualization suite. Together, these libraries offer an unparalleled toolkit for
    data scientists aiming to translate complex data insights into compelling visual
    stories, highlighting the interconnectedness and distinct strengths of each package
    in the visualization ecosystem.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '**`Matplotlib`** 和 **`Seaborn`**: 这两个包作为关键的线索，共同提升了分析叙事的结构。`Matplotlib`，作为基础库，提供了广泛的灵活性和控制，奠定了创建各种静态、动画和交互式可视化的基础。它是
    `seaborn` 构建的基石，后者通过提供一个高层接口来绘制吸引人且信息丰富的统计图形，扩展了 `matplotlib` 的功能。`seaborn` 专注于使复杂的可视化变得易于访问，与
    `pandas` DataFrames 紧密集成，以简化从数据处理到表示的过程。这种协同效应在探索特征关系和发现数据集中的模式时尤为明显，因为 `seaborn`
    的高级绘图函数，如配对图，基于 `matplotlib` 的基础结构提供了更丰富、更深入的视觉叙事。我们关于[探索特征关系](https://machinelearningmastery.com/feature-relationships-101/)和[利用配对图](https://machinelearningmastery.com/pair-plots/)的文章深入探讨了
    `seaborn` 和 `matplotlib` 与 `pandas` 结合形成的紧密可视化套件。这些库为数据科学家提供了无与伦比的工具包，旨在将复杂的数据洞察转化为引人入胜的视觉故事，突显了每个包在可视化生态系统中的互联性和独特优势。'
- en: '**`Statsmodels.api`**: This tool is particularly useful in the realm of statistical
    visualization through its QQ plots (Quantile-Quantile plots) functionality, aiding
    in the assessment of whether data distributions match theoretical expectations,
    typically the normal distribution. We demonstrate this technique in this [post](https://machinelearningmastery.com/leveraging-anova-and-kruskal-wallis-tests-to-analyze-the-impact-of-the-great-recession-on-housing-prices/). The
    generation of a QQ plot involves comparing the sorted values of the sample data
    against the expected values of the chosen theoretical distribution, providing
    a graphical method to evaluate the assumption of normality critical to many parametric
    statistical tests.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**`Statsmodels.api`**: 这个工具在统计可视化领域尤其有用，通过其 QQ 图（分位数-分位数图）功能，帮助评估数据分布是否符合理论预期，通常是正态分布。我们在这篇[文章](https://machinelearningmastery.com/leveraging-anova-and-kruskal-wallis-tests-to-analyze-the-impact-of-the-great-recession-on-housing-prices/)中展示了这一技术。生成
    QQ 图涉及将样本数据的排序值与所选理论分布的预期值进行比较，提供了一种图形化方法来评估正态性假设，这对于许多参数统计测试至关重要。'
- en: '**`Scipy.stats`**: As the data science journey progresses from descriptive
    to inferential statistics, `scipy.stats` emerges as a pivotal toolkit. This package
    is fundamental for conducting a wide range of statistical tests and analyses that
    form the backbone of inferential statistics, enabling data scientists to draw
    meaningful conclusions from their data. Within `scipy.stats`, you find an extensive
    array of functions designed for hypothesis testing, confidence interval estimation,
    and much more, making it indispensable for rigorous statistical investigation.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**`Scipy.stats`**: 随着数据科学旅程从描述性统计向推断统计的推进，`scipy.stats` 成为一个关键工具包。这个包对于进行广泛的统计检验和分析至关重要，构成了推断统计的基础，使数据科学家能够从数据中得出有意义的结论。在
    `scipy.stats` 中，你可以找到大量设计用于假设检验、置信区间估计等的函数，使其成为严格统计调查中不可或缺的工具。'
- en: 'Our exploration of statistical techniques through various posts demonstrates
    the versatility and power of `scipy.stats`:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 通过各种帖子，我们对统计技术的探索展示了 `scipy.stats` 的多样性和强大功能：
- en: 'In [Inferential Insights: Confidence Intervals](https://machinelearningmastery.com/inferential-insights-confidence-intervals/),
    we delve into how confidence intervals can provide a range of plausible values
    for an unknown parameter, showcasing the `t.interval` function for calculating
    intervals based on sample data.'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 [推断见解：置信区间](https://machinelearningmastery.com/inferential-insights-confidence-intervals/)
    中，我们深入探讨了置信区间如何提供未知参数的合理值范围，展示了用于根据样本数据计算区间的 `t.interval` 函数。
- en: '[A Dive into Hypothesis Testing](https://machinelearningmastery.com/a-dive-into-hypothesis-testing/)
    illustrates the core of inferential statistics, employing tests like the t-test
    to evaluate hypotheses about our data.'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[深入假设检验](https://machinelearningmastery.com/a-dive-into-hypothesis-testing/)
    说明了推断统计学的核心，使用像 t 检验这样的测试来评估关于数据的假设。'
- en: Our examination of the [Chi-Squared Test with the Ames Housing Dataset](https://machinelearningmastery.com/chi-squared-ames/)
    uses the `chi2_contingency` function to test for independence between categorical
    variables.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们对 [Ames 房价数据集的卡方检验](https://machinelearningmastery.com/chi-squared-ames/)
    的检查使用了 `chi2_contingency` 函数来检验分类变量之间的独立性。
- en: '[Leveraging ANOVA and Kruskal-Wallis Tests](https://machinelearningmastery.com/leveraging-anova-and-kruskal-wallis-tests-to-analyze-the-impact-of-the-great-recession-on-housing-prices/)
    highlights how `scipy.stats` supports both parametric (ANOVA) and non-parametric
    (Kruskal-Wallis) tests to assess the effects of categorical variables (‘YrSold’)
    on continuous outcomes (‘SalePrice’).'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[利用 ANOVA 和 Kruskal-Wallis 检验](https://machinelearningmastery.com/leveraging-anova-and-kruskal-wallis-tests-to-analyze-the-impact-of-the-great-recession-on-housing-prices/)
    重点介绍了 `scipy.stats` 如何支持参数（ANOVA）和非参数（Kruskal-Wallis）检验，以评估分类变量（‘YrSold’）对连续结果（‘SalePrice’）的影响。'
- en: Utilizing the non-parametric [Kolmogorov-Smirnov test](https://machinelearningmastery.com/skewness-be-gone-transformative-tricks-for-data-scientists/),
    we compare transformed data against the normal distribution, demonstrating the
    transformative power of methods like Quantile, Log, and Box-Cox to combat data
    with skewed distributions.
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利用非参数的 [Kolmogorov-Smirnov 检验](https://machinelearningmastery.com/skewness-be-gone-transformative-tricks-for-data-scientists/)，我们将变换后的数据与正态分布进行比较，展示了像分位数变换、对数变换和
    Box-Cox 变换等方法对抗偏态分布数据的变革力量。
- en: '`Scipy.stats` thus plays a crucial role in transitioning data science efforts
    from understanding what is in the data (descriptive statistics) to inferring the
    implications of that data (inferential statistics), providing a comprehensive
    suite for statistical testing and analysis.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，`scipy.stats` 在将数据科学工作从理解数据（描述性统计）转向推断数据的含义（推断统计）中发挥了关键作用，提供了一个全面的统计检验和分析套件。
- en: The Data Science Mind Map introduces you to a collection of Python libraries,
    each playing a distinct yet interconnected role in the broader data science landscape.
    From the data structuring prowess of `pandas` and the numerical might of `numpy`,
    to the cleaning insights provided by `missingno` and the geographical intelligence
    of `geopandas`; from the captivating visualizations afforded by `folium`, `matplotlib`,
    and `seaborn`, to the analytical depth and statistical rigor of `statsmodels.api`
    and `scipy.stats` — each library contributes a unique thread to the interdisciplinary
    nature of Data Science.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 数据科学思维导图向你介绍了一系列 Python 库，每个库在广泛的数据科学领域中扮演着独特而互联的角色。从`pandas`的数据显示结构能力和`numpy`的数值强度，到`missingno`提供的数据清理见解和`geopandas`的地理信息；从`folium`、`matplotlib`和`seaborn`带来的引人入胜的可视化，到`statsmodels.api`和`scipy.stats`的分析深度和统计严谨性——每个库为数据科学的跨学科性质贡献了一根独特的线索。
- en: '**Kick-start your project** with my book [The Beginner’s Guide to Data Science](https://machinelearning.samcart.com/products/beginners-guide-data-science/).
    It provides **self-study tutorials** with **working code**.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**启动你的项目**，可以参考我的书籍 [数据科学入门指南](https://machinelearning.samcart.com/products/beginners-guide-data-science/)。它提供了**自学教程**和**有效代码**。'
- en: The Art of Storytelling in Data Science
  id: totrans-32
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据科学中的讲故事艺术
- en: Imagine the process of storytelling in data science as Leonardo da Vinci embarking
    on the creation of a masterpiece. Each brushstroke, choice of color, and play
    of light and shadow serve a purpose, much like the elements of our data narrative.
    Let’s explore this artistic journey.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 想象数据科学中的讲故事过程就像列奥纳多·达·芬奇开始创作一件杰作。每一笔画、颜色选择以及光影效果都有其目的，就像我们数据叙事中的元素一样。让我们探讨这一艺术之旅。
- en: '**Sketching the Outline**: Before touching brush to canvas, Leonardo spent
    countless hours in preparation. He dissected human bodies to understand anatomy,
    studied the properties of light and shadow, and sketched detailed drawings. Similarly,
    our first step in data storytelling involves deep diving into the dataset, understanding
    its variables, and planning our analysis. This stage sets the foundation for a
    narrative that is both accurate and compelling.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**勾勒大纲**：在触笔画布之前，列奥纳多花费了无数小时进行准备。他解剖人体以了解解剖结构，研究光影的特性，并进行详细的草图绘制。同样，我们在数据讲述中的第一步是深入分析数据集，理解其变量，并规划我们的分析。这一阶段为一个既准确又引人入胜的叙事奠定了基础。'
- en: '**Choosing the Palette**: Just as Leonardo mixed his paints to achieve the
    perfect hues, a data storyteller selects tools and techniques from the Data Science
    Mind Map. The choice of Python packages, such as pandas for data manipulation,
    matplotlib and seaborn for visualization, or `scipy.stats` for statistical analysis,
    becomes our palette, allowing us to illuminate insights from the data.'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: '**选择调色板**：正如列奥纳多混合颜料以获得完美的色调，数据讲述者从数据科学思维导图中选择工具和技术。选择 Python 包，如用于数据处理的 pandas、用于可视化的
    matplotlib 和 seaborn，或用于统计分析的`scipy.stats`，就像是我们的调色板，让我们能够从数据中揭示洞见。'
- en: '**Creating Depth with Perspective**: Leonardo’s use of perspective gave his
    paintings depth, making them more lifelike and engaging. In data storytelling,
    we create depth through analysis, examining the data from multiple angles to uncover
    underlying patterns and relationships. This perspective helps us build a narrative
    that resonates with the audience, providing them with insights beyond the surface.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '**用视角创造深度**：列奥纳多利用透视法为他的画作增添了深度，使其更加生动和引人入胜。在数据讲述中，我们通过分析来创造深度，从多个角度审视数据，以发现潜在的模式和关系。这种视角帮助我们建立一个与观众产生共鸣的叙事，提供超越表面的见解。'
- en: '**Highlighting with Light and Shadow**: Leonardo was a master of chiaroscuro,
    the technique of using light and shadow to bring drama and focus to his paintings.
    In our data story, visualizations serve as our light and shadow, highlighting
    key findings and drawing the audience’s attention to the most important insights.
    Through effective visualization, we can make complex data understandable and memorable.'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '**用光影突出重点**：列奥纳多是明暗对比法的大师，他通过光影为画作带来了戏剧性和重点。在我们的数据故事中，可视化就像光影一样，突出关键发现并将观众的注意力引向最重要的见解。通过有效的可视化，我们可以使复杂的数据变得易于理解和记忆。'
- en: '**The Final Masterpiece**: When Leonardo presented his finished work, it was
    not just a painting; it was a story captured in time, evoking emotion and provoking
    thought. Our data story, culminating in the presentation of our findings, aims
    to do the same. It’s where our preparation, analysis, and visualization come together
    to inform, persuade, and inspire our audience to action.'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '**最终杰作**：当列奥纳多展示他完成的作品时，它不仅是一幅画；它是一个捕捉在时间中的故事，引发情感和引发思考。我们的数据故事，以呈现我们的发现为高潮，旨在做到这一点。这里是我们的准备、分析和可视化结合的地方，以告知、说服和激励我们的观众采取行动。'
- en: Just as viewers stand in front of a da Vinci painting, absorbing its beauty
    and depth, we invite your audience to reflect on the data driven stories you will
    tell. This reflection is where understanding deepens, and the true impact of your
    work is felt, echoing the enduring legacy of da Vinci’s art.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 就像观众站在达·芬奇的画作前，吸收其美感和深度一样，我们邀请你的受众反思你将讲述的数据驱动故事。这种反思是理解加深的地方，也是你工作的真正影响感受到的地方，回响着达·芬奇艺术的持久遗产。
- en: Want to Get Started With Beginner's Guide to Data Science?
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 想要开始学习数据科学的初学者指南吗？
- en: Take my free email crash course now (with sample code).
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 现在就参加我的免费电子邮件速成课程（包括示例代码）。
- en: Click to sign-up and also get a free PDF Ebook version of the course.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 点击注册，还可以获得免费的PDF电子书版课程。
- en: '**Further****Reading**'
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**进一步阅读**'
- en: Tutorials
  id: totrans-44
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 教程
- en: '[Data Storytelling: The Essential Data Science Skill Everyone Needs (Forbes)](https://www.forbes.com/sites/brentdykes/2016/03/31/data-storytelling-the-essential-data-science-skill-everyone-needs/?sh=5e26a0ee52ad)'
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据叙事：每个人都需要的基本数据科学技能（Forbes）](https://www.forbes.com/sites/brentdykes/2016/03/31/data-storytelling-the-essential-data-science-skill-everyone-needs/?sh=5e26a0ee52ad)'
- en: '**Resources**'
  id: totrans-46
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**资源**'
- en: '[The Data Science Mind Map](https://machinelearningmastery.com/the-da-vinci-code-of-data-mastering-the-data-science-mind-map/the-data-science-mind-map/)'
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[数据科学思维导图](https://machinelearningmastery.com/the-da-vinci-code-of-data-mastering-the-data-science-mind-map/the-data-science-mind-map/)'
- en: '**Summary**'
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '**总结**'
- en: In this final post of our Data Science series, we unveiled the art and science
    behind turning raw data into compelling narratives that inform and inspire action.
    By traversing the Data Science Mind Map, we’ve seen how foundational tools and
    techniques serve as the building blocks for data preparation, analysis, and visualization,
    enabling the transformation of complex datasets into insightful stories. Drawing
    an analogy to Leonardo da Vinci’s masterful blend of art and science, we’ve explored
    the storytelling process in Data Science as a creative endeavor that, much like
    painting a masterpiece, requires careful preparation, the right tools, and a keen
    eye for detail to reveal the stories hidden within data. This post has aimed to
    simplify the data science process and inspire you to approach your data with the
    curiosity of a scientist and the heart of an artist.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们数据科学系列的最后一篇文章中，我们揭示了将原始数据转化为引人入胜的叙事的艺术和科学。通过探索数据科学思维导图，我们看到基础工具和技术如何作为数据准备、分析和可视化的基石，使复杂的数据集转化为富有洞察力的故事。借用列奥纳多·达·芬奇在艺术和科学上的巧妙结合，我们探讨了数据科学中的叙事过程作为一种创作努力，像绘制一幅杰作一样，需要细致的准备、合适的工具和敏锐的眼光，以揭示数据中的隐藏故事。此文章旨在简化数据科学过程，并激励你以科学家的好奇心和艺术家的心态去看待数据。
- en: 'Specifically, you learned:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，你学到了：
- en: The essential role of foundational tools as depicted in The Data Science Mind
    Map.
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 基础工具在《数据科学思维导图》中扮演的核心角色。
- en: The process of storytelling in data science, from setting the stage, to creating
    depth, and finally, presenting the ‘masterpiece’ that evokes understanding and
    action.
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据科学中的叙事过程，从设定舞台、创造深度，到最终呈现激发理解和行动的“杰作”。
- en: Do you have any questions? Please ask your questions in the comments below,
    and I will do my best to answer.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 你有任何问题吗？请在下面的评论中提问，我会尽力回答。
