["```py\n# Load only categorical columns without missing values from the Ames dataset\nimport pandas as pd\nAmes = pd.read_csv(\"Ames.csv\").select_dtypes(include=[\"object\"]).dropna(axis=1)\nprint(f\"The shape of the DataFrame before One Hot Encoding is: {Ames.shape}\")\n\n# Import OneHotEncoder and apply it to Ames:\nfrom sklearn.preprocessing import OneHotEncoder\n\nencoder = OneHotEncoder(sparse=False)\nAmes_One_Hot = encoder.fit_transform(Ames)\n\n# Convert the encoded result back to a DataFrame\nAmes_encoded_df = pd.DataFrame(Ames_One_Hot, columns=encoder.get_feature_names_out(Ames.columns))\n\n# Display the new DataFrame and it's expanded shape\nprint(Ames_encoded_df.head())\nprint(f\"The shape of the DataFrame after One Hot Encoding is: {Ames_encoded_df.shape}\")\n```", "```py\nThe shape of the DataFrame before One Hot Encoding is: (2579, 27)\n\n   MSZoning_A (agr)  ...  SaleCondition_Partial\n0               0.0  ...                    0.0\n1               0.0  ...                    0.0\n2               0.0  ...                    0.0\n3               0.0  ...                    0.0\n4               0.0  ...                    0.0\n[5 rows x 188 columns]\n\nThe shape of the DataFrame after One Hot Encoding is: (2579, 188)\n```", "```py\n# Buidling on the code above to identify top categorical feature\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import cross_val_score\n\n# Set 'SalePrice' as the target variable\ny = pd.read_csv(\"Ames.csv\")[\"SalePrice\"]\n\n# Dictionary to store feature names and their corresponding mean CV R² scores\nfeature_scores = {}\n\nfor feature in Ames.columns:\n    encoder = OneHotEncoder(drop=\"first\")\n    X_encoded = encoder.fit_transform(Ames[[feature]])\n\n    # Initialize the linear regression model\n    model = LinearRegression()\n\n    # Perform 5-fold cross-validation and calculate R^2 scores\n    scores = cross_val_score(model, X_encoded, y)\n    mean_score = scores.mean()\n\n    # Store the mean R^2 score\n    feature_scores[feature] = mean_score\n\n# Sort features based on their mean CV R² scores in descending order\nsorted_features = sorted(feature_scores.items(), key=lambda item: item[1], reverse=True)\nprint(\"Feature selected for highest predictability:\", sorted_features[0][0])\n```", "```py\nFeature selected for highest predictability: Neighborhood\n```", "```py\n# Building on the code above to determine the performance of top 5 categorical features\nprint(\"Top 5 Categorical Features:\")\nfor feature, score in sorted_features[0:5]:\n    print(f\"{feature}: Mean CV R² = {score:.4f}\")\n```", "```py\nTop 5 Categorical Features:\nNeighborhood: Mean CV R² = 0.5407\nExterQual: Mean CV R² = 0.4651\nKitchenQual: Mean CV R² = 0.4373\nFoundation: Mean CV R² = 0.2547\nHeatingQC: Mean CV R² = 0.1892\n```"]