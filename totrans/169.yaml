- en: Using ControlNet with Stable Diffusion
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用 ControlNet 与 Stable Diffusion
- en: 原文：[https://machinelearningmastery.com/control-net-with-stable-diffusion/](https://machinelearningmastery.com/control-net-with-stable-diffusion/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://machinelearningmastery.com/control-net-with-stable-diffusion/](https://machinelearningmastery.com/control-net-with-stable-diffusion/)
- en: ControlNet is a neural network that can improve image generation in Stable Diffusion
    by adding extra conditions. This allows users to have more control over the images
    generated. Instead of trying out different prompts, the ControlNet models enable
    users to generate consistent images with just one prompt.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: ControlNet 是一个神经网络，通过添加额外条件来改善 Stable Diffusion 中的图像生成。这使用户可以更好地控制生成的图像。与其尝试不同的提示，ControlNet
    模型使用户能够通过仅一个提示生成一致的图像。
- en: 'In this post, you will learn how to gain precise control over images generated
    by Stable Diffusion using ControlNet. Specifically, we will cover:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，你将学习如何通过 ControlNet 精确控制由 Stable Diffusion 生成的图像。具体而言，我们将涵盖：
- en: What is ControlNet, and how it works
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是 ControlNet，以及它是如何工作的
- en: How to use ControlNet with the Hugging Face Spaces
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在 Hugging Face Spaces 中使用 ControlNet
- en: Using ControlNet with the Stable Diffusion WebUI
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 ControlNet 与 Stable Diffusion WebUI
- en: '**Kick-start your project** with my book [Mastering Digital Art with Stable
    Diffusion](https://machinelearningmastery.com/mastering-digital-art-with-stable-diffusion/).
    It provides **self-study tutorials** with **working code**.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**通过我的书籍** [《掌握 Stable Diffusion 的数字艺术》](https://machinelearningmastery.com/mastering-digital-art-with-stable-diffusion/)
    **启动你的项目**。它提供了**自学教程**和**可用代码**。'
- en: Let’s get started.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: '![](../Images/5a8a4831275d1577117a9be97654c47d.png)'
  id: totrans-9
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5a8a4831275d1577117a9be97654c47d.png)'
- en: Using ControlNet with Stable Diffusion
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 ControlNet 与 Stable Diffusion
- en: Photo by [Nadine Shaabana](https://unsplash.com/photos/red-sony-ps-dualshock-4-YsPnamiHdmI).
    Some rights reserved.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由 [Nadine Shaabana](https://unsplash.com/photos/red-sony-ps-dualshock-4-YsPnamiHdmI)
    拍摄。保留所有权利。
- en: Overview
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'This post is in four parts; they are:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本文分为四部分，它们是：
- en: What is ControlNet?
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是 ControlNet？
- en: ControlNet in Hugging Face Space
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hugging Face Space 中的 ControlNet
- en: Scribble Interactive
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Scribble Interactive
- en: ControlNet in Stable Diffusion Web UI
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Stable Diffusion Web UI 中的 ControlNet
- en: What is ControlNet?
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是 ControlNet？
- en: '[ControlNet](https://github.com/lllyasviel/ControlNet) is a neural network
    architecture that can be used to control diffusion models. In addition to the
    prompt you would usually provide to create the output image, it works by adding
    extra **conditioning** to the diffusion model with an input image as the additional
    constraint to guide the diffusion process.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[ControlNet](https://github.com/lllyasviel/ControlNet) 是一种神经网络架构，可用于控制扩散模型。除了通常提供的生成输出图像的提示外，它还通过将额外的**条件**与输入图像作为附加约束来指导扩散过程。'
- en: There are many types of conditioning inputs (canny edge, user sketching, human
    pose, depth, etc.) that can provide a diffusion model to have more control over
    image generation.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 有许多类型的条件输入（如 Canny 边缘、用户草图、人体姿势、深度等），可以为扩散模型提供更多的图像生成控制。
- en: 'Some examples of how ControlNet can control diffusion models:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: ControlNet 如何控制扩散模型的一些示例：
- en: By providing a specific human pose, an image mimicking the same pose is generated.
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 通过提供特定的人体姿势，生成模仿相同姿势的图像。
- en: Make the output follow the style from another image.
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使输出遵循另一图像的风格。
- en: Turn scribbles into high-quality images.
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 将涂鸦转换为高质量图像。
- en: Generate a similar image using a reference image.
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用参考图像生成类似的图像。
- en: Inpainting missing parts of an image.
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 修补图像的缺失部分。
- en: '![](../Images/256d2c038157499d826110cd6f32d50f.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/256d2c038157499d826110cd6f32d50f.png)'
- en: Block diagram of how ControlNet modified the diffusion process. Figure from
    Zhang et al (2023)
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: ControlNet 修改扩散过程的框图。图来自 Zhang 等人 (2023)
- en: 'ControlNet works by copying the weights from the original diffusion model into
    two sets:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: ControlNet 通过将权重从原始扩散模型复制到两个集合中来工作：
- en: A “locked” set that preserves the original model
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个“锁定”的集合，保留原始模型
- en: A “trainable” set that learns the new conditioning.
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个“可训练”的集合，学习新的条件。
- en: The ControlNet model essentially produces a difference vector in the latent
    space, which modifies the image that the diffusion model would otherwise produce.
    In equation, if the original model produces output image $y$ from prompt $x$ using
    a function $y=F(x;\Theta)$, in the case of ControlNet would be
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: ControlNet 模型本质上在潜在空间中生成一个差异向量，这个向量修改了扩散模型本应生成的图像。用公式表示，如果原始模型通过函数 $y=F(x;\Theta)$
    从提示 $x$ 生成输出图像 $y$，在 ControlNet 的情况下则为
- en: $$y_c = F(x;\Theta) + Z(F(x+Z(c;\Theta_{z1}); \Theta_c); \Theta_{z2})$$
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: $$y_c = F(x;\Theta) + Z(F(x+Z(c;\Theta_{z1}); \Theta_c); \Theta_{z2})$$
- en: in which the function $Z(\cdot;\Theta_z)$ is the zero convolution layer, and
    the parameters $\Theta_c, \Theta_{z1}, \Theta_{z2}$ are parameters from the ControlNet
    model. The zero-convolution layers have weights and biases initialized with zero,
    so they don’t initially cause distortion. As training happens, these layers learn
    to meet the conditioning constraints. This structure allows training ControlNet
    even on small machines. Note that the same diffusion architecture (e.g., Stable
    Diffusion 1.x) is used twice but with different model parameters $\Theta$ and
    $\Theta_c$. And now, you need to provide two inputs, $x$ and $c$ to create the
    output $y$.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 其中函数 $Z(\cdot;\Theta_z)$ 是零卷积层，参数 $\Theta_c, \Theta_{z1}, \Theta_{z2}$ 是来自 ControlNet
    模型的参数。零卷积层的权重和偏置初始化为零，因此初始时不会造成扭曲。随着训练的进行，这些层学会满足条件约束。这种结构允许在小型设备上训练 ControlNet。请注意，相同的扩散架构（例如
    Stable Diffusion 1.x）被使用两次，但使用不同的模型参数 $\Theta$ 和 $\Theta_c$。现在，您需要提供两个输入，$x$ 和
    $c$，以创建输出 $y$。
- en: The design of running ControlNet and the original Diffusion model in segregate
    allows fine-tuning on small datasets without destroying the original diffusion
    model. It also allows the same ControlNet to be used with different diffusion
    models as long as the architecture is compatible. The modular and fast-adapting
    nature of ControlNet makes it a versatile approach for gaining more precise control
    over image generation without extensive retraining.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 将 ControlNet 和原始扩散模型分开设计允许在小数据集上进行精细调整，而不破坏原始扩散模型。它还允许相同的 ControlNet 与不同的扩散模型一起使用，只要架构兼容。ControlNet
    的模块化和快速适应性使其成为一种灵活的方法，可以更精确地控制图像生成，而无需进行大量的重新训练。
- en: ControlNet in Hugging Face Space
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Hugging Face Spaces 中的 ControlNet
- en: Let’s see how ControlNet do magic to the diffusion model. In this section, we
    will use an online ControlNet demo available on Hugging Face Spaces to generate
    a human pose image using the ControlNet Canny model.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看看 ControlNet 如何在扩散模型中发挥魔力。在这一部分，我们将使用 Hugging Face Spaces 上可用的在线 ControlNet
    演示生成使用 ControlNet Canny 模型的人体姿势图像。
- en: '**URL:** [https://hf.co/spaces/hysts/ControlNet-v1-1](https://hf.co/spaces/hysts/ControlNet-v1-1)'
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**URL:** [https://hf.co/spaces/hysts/ControlNet-v1-1](https://hf.co/spaces/hysts/ControlNet-v1-1)'
- en: 'We will upload [Yogendra Singh’s](https://www.pexels.com/photo/dancing-man-wearing-pants-and-long-sleeved-shirt-1701194/)
    photo from Pexels.com to ControlNet Spaces and add a simple prompt. Instead of
    a boy, we will generate an image of women dancing in a club. Let’s use the tab
    “Canny”. Set the prompt to:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将从 Pexels.com 上传[Yogendra Singh的](https://www.pexels.com/photo/dancing-man-wearing-pants-and-long-sleeved-shirt-1701194/)照片到
    ControlNet Spaces，并添加一个简单的提示。我们将生成一个在夜总会跳舞的女性图像，而不是男孩。让我们使用标签“Canny”。将提示设置为：
- en: a girl dancing in a club
  id: totrans-40
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 一个在夜总会跳舞的女孩
- en: 'Click run, and you will see the output as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 点击运行，你将看到以下输出：
- en: '![](../Images/d53d3806c1b78c24882624a6d60e5437.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d53d3806c1b78c24882624a6d60e5437.png)'
- en: Running ControlNet on Hugging Face Space
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Hugging Face Space 上运行 ControlNet
- en: This is amazing! “Canny” is an image processing algorithm to detect edges. Hence,
    you provide the edge from your uploaded image as an outline sketch. Then, provide
    this as the additional input $c$ to ControlNet, together with your text prompt
    $x$, you provided the output image $y$. In essence, you can generate a similar
    pose image using canny edges on the original image.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 这太神奇了！“Canny”是一种图像处理算法，用于检测边缘。因此，您可以将您上传的图像的边缘作为轮廓草图提供。然后，将其作为附加输入 $c$ 与您提供的文本提示
    $x$ 一起提供给 ControlNet，您将获得输出图像 $y$。简言之，您可以使用原始图像上的 Canny 边缘生成类似姿势的图像。
- en: Let’s see another example. We will upload [Gleb Krasnoborov’s](https://www.pexels.com/photo/man-wearing-boxing-gloves-2628207/)
    photo and apply a new prompt that changes the background, effect, and ethnicity
    of the boxer to Asian. The prompt we use is
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们看另一个例子。我们将上传[Gleb Krasnoborov的](https://www.pexels.com/photo/man-wearing-boxing-gloves-2628207/)照片，并应用一个新的提示，该提示将改变拳击手的背景、效果和族裔为亚洲人。我们使用的提示是：
- en: A man shadow boxing in streets of Tokyo
  id: totrans-46
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 一个男人在东京街头进行影子拳击。
- en: 'and this is the output:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这是输出结果：
- en: '![](../Images/f1cd90c1b8e9f4cb38a9cbcfd9b5a55b.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f1cd90c1b8e9f4cb38a9cbcfd9b5a55b.png)'
- en: Another example of using Canny model in ControlNet
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在 ControlNet 中使用 Canny 模型的另一个示例
- en: Once again, the results are excellent. We generated an image of a boxer in a
    similar pose, shadowboxing on the streets of Tokyo.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 再次，结果非常出色。我们生成了一个拳击手在东京街头以类似姿势进行影子拳击的图像。
- en: Scribble Interactive
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Scribble Interactive
- en: The architecture of ControlNet can accept many different kinds of input. Using
    Canny edge as the outline is just one model of ControlNet. There are many more
    models, each trained as a different conditioning for image diffusion.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: ControlNet的架构可以接受多种不同类型的输入。使用Canny边缘作为轮廓仅是ControlNet的一个模型。还有许多其他模型，每个模型都经过不同的图像扩散条件训练。
- en: On the same Hugging Face Spaces page, the different versions of ControlNet versions
    are available, which can be accessed through the top tab. Let’s see another example
    using the Scribbles model. In order to generate an image using Scribbles, simply
    go to the Scribble Interactive tab draw a doodle with your mouse, and write a
    simple prompt to generate the image, such as
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 在同一个Hugging Face Spaces页面上，可以通过顶部标签访问ControlNet的不同版本。让我们看看使用Scribbles模型的另一个例子。为了使用Scribbles生成图像，只需转到Scribble
    Interactive选项卡，用鼠标画一个涂鸦，并写一个简单的提示生成图像，例如
- en: A house by the river
  id: totrans-54
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 河边的房子
- en: 'Like the following:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如下所示：
- en: '![](../Images/481ebece443fee7d7b39d3970531bde7.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/481ebece443fee7d7b39d3970531bde7.png)'
- en: 'Using Scribble ControlNet: Drawing a house and providing a text prompt'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 使用Scribble ControlNet：绘制一幅房子并提供文本提示
- en: 'Then, by setting the other parameters and pressing the “Run” button, you may
    get the output like the following:'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 然后，通过设置其他参数并按“运行”按钮，您可能会获得如下输出：
- en: '![](../Images/b8c299d8dcada8c9039d592799372327.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b8c299d8dcada8c9039d592799372327.png)'
- en: Output from Scribble ControlNet
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Scribble ControlNet的输出
- en: The generated image looks good but could be better. You can try again with more
    details in the scribbles as well as the text prompt to get an improved result.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 生成的图像看起来不错，但可以更好。您可以再次尝试，加入更多细节的涂鸦和文本提示，以获得改进的结果。
- en: Using scribble and a text prompt is a trivial way to generate images, especially
    when you can’t think of a very accurate textual description of the image you want
    to create. Below is another example of creating a picture of a hot air balloon.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 使用涂鸦和文本提示生成图像是一种生成图像的简单方法，特别是当您无法想出非常准确的图像描述时。下面是使用涂鸦创建热气球图片的另一个例子。
- en: '![](../Images/6eabb6c96067b14b2b38ada15552071d.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6eabb6c96067b14b2b38ada15552071d.png)'
- en: Creating a picture of a hot air balloon using Scribble.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 使用涂鸦创建热气球图片。
- en: ControlNet in Stable Diffusion Web UI
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 稳定扩散Web UI中的ControlNet
- en: 'As you have learned about using the Stable Diffusion Web UI in the previous
    posts, you can expect that ControlNet can also be used on the Web UI. It is an
    extension. If you haven’t installed it yet, you need to launch the Stable Diffusion
    Web UI. Then, go to the Extensions tab, click on “Install from the URL”, and enter
    the link to the ControlNet repository: https://github.com/Mikubill/sd-webui-controlnet
    to install.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 如您在之前的帖子中学习过使用稳定扩散Web UI，您可以预期ControlNet也可以在Web UI上使用。这是一个扩展。如果您尚未安装，您需要启动稳定扩散Web
    UI。然后，转到“扩展”选项卡，点击“从URL安装”，输入ControlNet存储库的链接：https://github.com/Mikubill/sd-webui-controlnet
    来安装。
- en: '![](../Images/d67e325b30ef2e56a33a93d95ffa5c4a.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/d67e325b30ef2e56a33a93d95ffa5c4a.png)'
- en: Installing ControlNet extension on Stable Diffusion Web UI
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在稳定扩散Web UI上安装ControlNet扩展
- en: The extension you installed is only the code. Before using the ControlNet Canny
    version, for example, you have to download and set up the Canny model.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 您安装的扩展仅包含代码。例如，在使用ControlNet Canny版本之前，您必须下载并设置Canny模型。
- en: Go to [https://hf.co/lllyasviel/ControlNet-v1-1/tree/main](https://hf.co/lllyasviel/ControlNet-v1-1/tree/main)
  id: totrans-70
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 前往[https://hf.co/lllyasviel/ControlNet-v1-1/tree/main](https://hf.co/lllyasviel/ControlNet-v1-1/tree/main)
- en: Download the [control_v11p_sd15_canny.pth](https://huggingface.co/lllyasviel/ControlNet-v1-1/blob/main/control_v11p_sd15_canny.pth)
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 下载[control_v11p_sd15_canny.pth](https://huggingface.co/lllyasviel/ControlNet-v1-1/blob/main/control_v11p_sd15_canny.pth)
- en: Put the model file in the the SD WebUI directory in `stable-diffusion-webui/extensions/sd-webui-controlnet/models`
    or `stable-diffusion-webui/models/ControlNet`
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将模型文件放置在`stable-diffusion-webui/extensions/sd-webui-controlnet/models`或`stable-diffusion-webui/models/ControlNet`目录中
- en: '**Note**: You can download all models (beware each model is in several GB in
    size) from the above repository using `git clone` command. Besides, this repository
    collects some more ControlNet models, [https://hf.co/lllyasviel/sd_control_collection](https://hf.co/lllyasviel/sd_control_collection)'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**: 您可以使用`git clone`命令从上述存储库下载所有模型（注意每个模型的大小均为数GB）。此外，该存储库收集了更多ControlNet模型，[https://hf.co/lllyasviel/sd_control_collection](https://hf.co/lllyasviel/sd_control_collection)'
- en: Now, you are all set up to use the model.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，您已经准备好使用该模型了。
- en: 'Let’s try it out with the Canny ControlNet. You go to the “txt2img” tab, scroll
    down to find the ControNet section to open it. Then, you follow these steps:'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们尝试使用 Canny ControlNet。你进入“txt2img”标签页，向下滚动找到 ControlNet 部分以打开它。然后，按照以下步骤操作：
- en: Change the control type to Canny.![](../Images/4ecd191985470c5701868cdbea963539.png)
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 更改控制类型为 Canny。![](../Images/4ecd191985470c5701868cdbea963539.png)
- en: Selecting “Canny” from the ControlNet box in Web UI.
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在 Web UI 中从 ControlNet 框中选择“Canny”。
- en: Upload the reference image.![](../Images/2c2a9f048c7856cec264606533929f59.png)
  id: totrans-78
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 上传参考图像。![](../Images/2c2a9f048c7856cec264606533929f59.png)
- en: Upload an image to ControlNet widget in Web UI
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在 Web UI 中将图像上传到 ControlNet 小部件
- en: 'Work on other sections on the txt2img tab: Write positive prompt, negative
    prompt, and change other advanced settings. For example,'
  id: totrans-80
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 处理 txt2img 标签中的其他部分：编写正面提示，负面提示，并更改其他高级设置。例如，
- en: '**Positive prompt:** “detailed, masterpiece, best quality, Astounding, Enchanting,
    Striking, man, natural light, beach, beach background, sunny, jungle, plants in
    background, beach background, beach, tropical beach, water,  clear skin, perfect
    light, perfect shadows”'
  id: totrans-81
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**正面提示：** “详细，杰作，最佳质量，令人惊叹，迷人，夺目，男人，自然光，海滩，海滩背景，阳光明媚，丛林，背景中的植物，海滩背景，海滩，热带海滩，水，清晰的皮肤，完美的光线，完美的阴影”'
- en: ''
  id: totrans-82
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
- en: '**Negative prompt:** “worst quality, low quality, lowres, monochrome, greyscale,
    multiple views, comic, sketch, bad anatomy, deformed, disfigured, watermark, multiple_views,
    mutation hands, watermark”'
  id: totrans-83
  prefs:
  - PREF_IND
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '**负面提示：** “最差质量，低质量，低分辨率，单色，灰度，多视角，漫画，素描，糟糕的解剖学，变形，毁容，水印，多视角，变异手，水印”'
- en: 'and the generation parameters:'
  id: totrans-84
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 以及生成参数：
- en: '**Sampling Steps:** 30'
  id: totrans-85
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**采样步骤：** 30'
- en: '**Sampler:** DDIM'
  id: totrans-86
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**采样器：** DDIM'
- en: '**CFG scale:** 7'
  id: totrans-87
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**CFG 比例：** 7'
- en: 'The output could be:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 输出可能是：
- en: '![](../Images/5c40b835c8b6326e4ac8a70c1ff712c2.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5c40b835c8b6326e4ac8a70c1ff712c2.png)'
- en: Output of image generation using ControlNet in Web UI
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 ControlNet 在 Web UI 中生成图像的输出
- en: As you can see, we have obtained high-quality and similar images. We can improve
    the photo by using different ControlNet models and applying various prompt engineering
    techniques, but this is the best we have now.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，我们获得了高质量且相似的图像。我们可以通过使用不同的 ControlNet 模型和应用各种提示工程技术来改进照片，但这已是我们目前得到的最佳效果。
- en: Here is the full image generated with the Canny version of ControlNet.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这是使用 Canny 版本的 ControlNet 生成的完整图像。
- en: '![](../Images/22f99663dd1ffc6fba1ced3e600b9126.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/22f99663dd1ffc6fba1ced3e600b9126.png)'
- en: Image generated using ControlNet with image diffusion model
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 ControlNet 和图像扩散模型生成的图像
- en: Further Readings
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: This section provides more resources on the topic if you are looking to go deeper.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 本节提供了更多关于此主题的资源，适合你深入了解。
- en: '[Adding Conditional Control to Text-to-Image Diffusion Models](https://arxiv.org/abs/2302.05543),
    by Zhang et al (2023)'
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[将条件控制添加到文本到图像扩散模型](https://arxiv.org/abs/2302.05543)，作者 Zhang 等（2023）'
- en: '[ControlNet](https://github.com/lllyasviel/ControlNet) on GitHub'
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ControlNet](https://github.com/lllyasviel/ControlNet) 在 GitHub 上'
- en: '[ControlNet v1.1](https://github.com/lllyasviel/ControlNet-v1-1-nightly) on
    GitHub'
  id: totrans-99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[ControlNet v1.1](https://github.com/lllyasviel/ControlNet-v1-1-nightly) 在
    GitHub 上'
- en: '[Model download](https://github.com/Mikubill/sd-webui-controlnet/wiki/Model-download)
    from the ControlNet Wiki'
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[模型下载](https://github.com/Mikubill/sd-webui-controlnet/wiki/Model-download)
    从 ControlNet Wiki'
- en: Summary
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: 'In this post, we learned about ControlNet, how it works, and how to use it
    to generate precise control images of users’ choices. Specifically, we covered:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，我们了解了 ControlNet，它是如何工作的，以及如何使用它生成用户选择的精确控制图像。具体来说，我们涵盖了：
- en: ControlNet online demo on Hugging Face to generate images using various reference
    images.
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Hugging Face 上的 ControlNet 在线演示，使用各种参考图像生成图像。
- en: Different versions of ControlNet and generated the image using the scribbles.
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用不同版本的 ControlNet 并通过涂鸦生成图像。
- en: Setting up ControlNet on Stable Diffusion WebUI and using it to generate the
    high-quality image of the boxer.
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Stable Diffusion WebUI 上设置 ControlNet 并使用它生成高质量的拳击手图像。
