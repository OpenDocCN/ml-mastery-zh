["```py\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\n\n# Load data into NumPy arrays\ndata = load_iris()\nX, y = data[\"data\"], data[\"target\"]\n\n# convert NumPy array into PyTorch tensors\nX = torch.tensor(X, dtype=torch.float32)\ny = torch.tensor(y, dtype=torch.long)\n\n# split\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n\n# PyTorch model\nclass Multiclass(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.hidden = nn.Linear(4, 8)\n        self.act = nn.ReLU()\n        self.output = nn.Linear(8, 3)\n        self.logsoftmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.act(self.hidden(x))\n        x = self.logsoftmax(self.output(x))\n        return x\n\nmodel = Multiclass()\n\n# loss metric and optimizer\nloss_fn = nn.NLLLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# prepare model and training parameters\nn_epochs = 100\nbatch_size = 5\nbatch_start = torch.arange(0, len(X), batch_size)\n\n# training loop\nfor epoch in range(n_epochs):\n    for start in batch_start:\n        # take a batch\n        X_batch = X_train[start:start+batch_size]\n        y_batch = y_train[start:start+batch_size]\n        # forward pass\n        y_pred = model(X_batch)\n        loss = loss_fn(y_pred, y_batch)\n        # backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        # update weights\n        optimizer.step()\n```", "```py\n...\ny_pred = model(X_test)\nacc = (torch.argmax(y_pred, 1) == y_test).float().mean()\nprint(\"Accuracy: %.2f\" % acc)\n```", "```py\nAccuracy: 0.96\n```", "```py\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n```", "```py\n# create a new model\nnewmodel = Multiclass()\n# ask PyTorch to ignore autograd on update and overwrite parameters\nwith torch.no_grad():\n    for newtensor, oldtensor in zip(newmodel.parameters(), model.parameters()):\n        newtensor.copy_(oldtensor)\n# test with new model using copied tensor\ny_pred = newmodel(X_test)\nacc = (torch.argmax(y_pred, 1) == y_test).float().mean()\nprint(\"Accuracy: %.2f\" % acc)\n```", "```py\nimport pprint\npp = pprint.PrettyPrinter(indent=4)\npp.pprint(model.state_dict())\n```", "```py\nOrderedDict([   (   'hidden.weight',\n                    tensor([[ 0.1480,  0.0336,  0.3425,  0.2832],\n        [ 0.5265,  0.8587, -0.7023, -1.1149],\n        [ 0.1620,  0.8440, -0.6189, -0.6513],\n        [-0.1559,  0.0393, -0.4701,  0.0825],\n        [ 0.6364, -0.6622,  1.1150,  0.9162],\n        [ 0.2081, -0.0958, -0.2601, -0.3148],\n        [-0.0804,  0.1027,  0.7363,  0.6068],\n        [-0.4101, -0.3774, -0.1852,  0.1524]])),\n                (   'hidden.bias',\n                    tensor([ 0.2057,  0.7998, -0.0578,  0.1041, -0.3903, -0.4521, -0.5307, -0.1532])),\n                (   'output.weight',\n                    tensor([[-0.0954,  0.8683,  1.0667,  0.2382, -0.4245, -0.0409, -0.2587, -0.0745],\n        [-0.0829,  0.8642, -1.6892, -0.0188,  0.0420, -0.1020,  0.0344, -0.1210],\n        [-0.0176, -1.2809, -0.3040,  0.1985,  0.2423,  0.3333,  0.4523, -0.1928]])),\n                ('output.bias', tensor([ 0.0998,  0.6360, -0.2990]))])\n```", "```py\nimport pickle\n\n# Save model\nwith open(\"iris-model.pickle\", \"wb\") as fp:\n    pickle.dump(model.state_dict(), fp)\n\n# Create new model and load states\nnewmodel = Multiclass()\nwith open(\"iris-model.pickle\", \"rb\") as fp:\n    newmodel.load_state_dict(pickle.load(fp))\n\n# test with new model using copied tensor\ny_pred = newmodel(X_test)\nacc = (torch.argmax(y_pred, 1) == y_test).float().mean()\nprint(\"Accuracy: %.2f\" % acc)\n```", "```py\n# Save model\ntorch.save(model.state_dict(), \"iris-model.pth\")\n\n# Create new model and load states\nnewmodel = Multiclass()\nnewmodel.load_state_dict(torch.load(\"iris-model.pth\"))\n\n# test with new model using copied tensor\ny_pred = newmodel(X_test)\nacc = (torch.argmax(y_pred, 1) == y_test).float().mean()\nprint(\"Accuracy: %.2f\" % acc)\n```", "```py\n# Save model\ntorch.save(model, \"iris-model-full.pth\")\n\n# Load model\nnewmodel = torch.load(\"iris-model-full.pth\")\n\n# test with new model using copied tensor\ny_pred = newmodel(X_test)\nacc = (torch.argmax(y_pred, 1) == y_test).float().mean()\nprint(\"Accuracy: %.2f\" % acc)\n```", "```py\nTraceback (most recent call last):\nFile \"<stdin>\", line 1, in <module>\nFile \"/.../torch/serialization.py\", line 789, in load\nreturn _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)\nFile \"/.../torch/serialization.py\", line 1131, in _load\nresult = unpickler.load()\nFile \"/.../torch/serialization.py\", line 1124, in find_class\nreturn super().find_class(mod_name, name)\nAttributeError: Can't get attribute 'Multiclass' on <module '__main__' (built-in)>\n```", "```py\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\n\n# Load data into NumPy arrays\ndata = load_iris()\nX, y = data[\"data\"], data[\"target\"]\n\n# convert NumPy array into PyTorch tensors\nX = torch.tensor(X, dtype=torch.float32)\ny = torch.tensor(y, dtype=torch.long)\n\n# split\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n\n# PyTorch model\nclass Multiclass(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.hidden = nn.Linear(4, 8)\n        self.act = nn.ReLU()\n        self.output = nn.Linear(8, 3)\n        self.logsoftmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.act(self.hidden(x))\n        x = self.logsoftmax(self.output(x))\n        return x\n\nmodel = Multiclass()\n\n# loss metric and optimizer\nloss_fn = nn.NLLLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# prepare model and training parameters\nn_epochs = 100\nbatch_size = 5\nbatch_start = torch.arange(0, len(X), batch_size)\n\n# training loop\nfor epoch in range(n_epochs):\n    for start in batch_start:\n        # take a batch\n        X_batch = X_train[start:start+batch_size]\n        y_batch = y_train[start:start+batch_size]\n        # forward pass\n        y_pred = model(X_batch)\n        loss = loss_fn(y_pred, y_batch)\n        # backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        # update weights\n        optimizer.step()\n\n# Save model\ntorch.save(model.state_dict(), \"iris-model.pth\")\n```", "```py\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\n\n# Load data into NumPy arrays\ndata = load_iris()\nX, y = data[\"data\"], data[\"target\"]\n\n# convert NumPy array into PyTorch tensors\nX = torch.tensor(X, dtype=torch.float32)\ny = torch.tensor(y, dtype=torch.long)\n\n# PyTorch model\nclass Multiclass(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.hidden = nn.Linear(4, 8)\n        self.act = nn.ReLU()\n        self.output = nn.Linear(8, 3)\n        self.logsoftmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x = self.act(self.hidden(x))\n        x = self.logsoftmax(self.output(x))\n        return x\n\n# Create new model and load states\nmodel = Multiclass()\nwith open(\"iris-model.pickle\", \"rb\") as fp:\n    model.load_state_dict(pickle.load(fp))\n\n# Run model for inference\ny_pred = model(X_test)\nacc = (torch.argmax(y_pred, 1) == y_test).float().mean()\nprint(\"Accuracy: %.2f\" % acc)\n```"]