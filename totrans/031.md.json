["```py\n# Load the Ames dataset\nimport pandas as pd\nAmes = pd.read_csv('Ames.csv')\n\n# Display the first few rows of the dataset and the data type of 'SalePrice'\nprint(Ames.head())\n\nsale_price_dtype = Ames['SalePrice'].dtype\nprint(f\"The data type of 'SalePrice' is {sale_price_dtype}.\")\n```", "```py\n         PID  GrLivArea  SalePrice  ...          Prop_Addr   Latitude  Longitude\n0  909176150        856     126000  ...    436 HAYWARD AVE  42.018564 -93.651619\n1  905476230       1049     139500  ...       3416 WEST ST  42.024855 -93.663671\n2  911128020       1001     124900  ...       320 S 2ND ST  42.021548 -93.614068\n3  535377150       1039     114000  ...   1524 DOUGLAS AVE  42.037391 -93.612207\n4  534177230       1665     227000  ...  2304 FILLMORE AVE  42.044554 -93.631818\n[5 rows x 85 columns]\n\nThe data type of 'SalePrice' is int64.\n```", "```py\n# Import Linear Regression from scikit-learn\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\n\n# Select features and target\nX = Ames[['GrLivArea']]  # Feature: GrLivArea, 2D matrix\ny = Ames['SalePrice']    # Target: SalePrice, 1D vector\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and fit the Linear Regression model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Scoring the model\nscore = round(model.score(X_test, y_test), 4)\nprint(f\"Model R^2 Score: {score}\")\n```", "```py\nModel R^2 Score: 0.4789\n```", "```py\nimport statsmodels.api as sm\n\n# Adding a constant to our independent variable for the intercept\nX_with_constant = sm.add_constant(X)\n\n# Fit the OLS model\nmodel_stats = sm.OLS(y, X_with_constant).fit()\n\n# Print the summary of the model\nprint(model_stats.summary())\n```", "```py\nOLS Regression Results                            \n==============================================================================\nDep. Variable:              SalePrice   R-squared:                       0.518\nModel:                            OLS   Adj. R-squared:                  0.518\nMethod:                 Least Squares   F-statistic:                     2774.\nDate:                Sun, 31 Mar 2024   Prob (F-statistic):               0.00\nTime:                        19:59:01   Log-Likelihood:                -31668.\nNo. Observations:                2579   AIC:                         6.334e+04\nDf Residuals:                    2577   BIC:                         6.335e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P>|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst       1.377e+04   3283.652      4.195      0.000    7335.256    2.02e+04\nGrLivArea    110.5551      2.099     52.665      0.000     106.439     114.671\n==============================================================================\nOmnibus:                      566.257   Durbin-Watson:                   1.926\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             3364.083\nSkew:                           0.903   Prob(JB):                         0.00\nKurtosis:                       8.296   Cond. No.                     5.01e+03\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 5.01e+03\\. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n```"]