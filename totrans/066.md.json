["```py\n<?xml version=\"1.0\"?>\n<annotation>\n  <folder>OXIIIT</folder>\n  <filename>Abyssinian_100.jpg</filename>\n  <source>\n    <database>OXFORD-IIIT Pet Dataset</database>\n    <annotation>OXIIIT</annotation>\n    <image>flickr</image>\n  </source>\n  <size>\n    <width>394</width>\n    <height>500</height>\n    <depth>3</depth>\n  </size>\n  <segmented>0</segmented>\n  <object>\n    <name>cat</name>\n    <pose>Frontal</pose>\n    <truncated>0</truncated>\n    <occluded>0</occluded>\n    <bndbox>\n      <xmin>151</xmin>\n      <ymin>71</ymin>\n      <xmax>335</xmax>\n      <ymax>267</ymax>\n    </bndbox>\n    <difficult>0</difficult>\n  </object>\n</annotation>\n```", "```py\nimport xml.etree.ElementTree as ET\n\ndef read_voc_xml(xmlfile: str) -> dict:\n    root = ET.parse(xmlfile).getroot()\n    boxes = {\"filename\": root.find(\"filename\").text,\n             \"objects\": []}\n    for box in root.iter('object'):\n        bb = box.find('bndbox')\n        obj = {\n            \"name\": box.find('name').text,\n            \"xmin\": int(bb.find(\"xmin\").text),\n            \"ymin\": int(bb.find(\"ymin\").text),\n            \"xmax\": int(bb.find(\"xmax\").text),\n            \"ymax\": int(bb.find(\"ymax\").text),\n        }\n        boxes[\"objects\"].append(obj)\n\n    return boxes\n```", "```py\n{'filename': 'yorkshire_terrier_160.jpg',\n'objects': [{'name': 'dog', 'xmax': 290, 'xmin': 97, 'ymax': 245, 'ymin': 18}]}\n```", "```py\nimg = cv2.imread(path)\nportion = img[ymin:ymax, xmin:xmax]\n```", "```py\ndef make_square(xmin, xmax, ymin, ymax):\n    \"\"\"Shrink the bounding box to square shape\"\"\"\n    xcenter = (xmax + xmin) // 2\n    ycenter = (ymax + ymin) // 2\n    halfdim = min(xmax-xmin, ymax-ymin) // 2\n    xmin, xmax = xcenter-halfdim, xcenter+halfdim\n    ymin, ymax = ycenter-halfdim, ycenter+halfdim\n    return xmin, xmax, ymin, ymax\n\n# Define HOG parameters\nwinSize = (64, 64)\nblockSize = (32, 32)\nblockStride = (16, 16)\ncellSize = (16, 16)\nnbins = 9\n\nnum_samples = 1000\n\nbase_path = pathlib.Path(\"oxford-iiit-pet\")\nimg_src = base_path / \"images\"\nann_src = base_path / \"annotations\" / \"xmls\"\n\n# collect samples by cropping the images from dataset\npositive = []\nnegative = []\n\n# collect positive samples\nfor xmlfile in ann_src.glob(\"*.xml\"):\n    # load xml\n    ann = read_voc_xml(str(xmlfile))\n    # use only cat photos\n    if ann[\"objects\"][0][\"name\"] != \"cat\":\n        continue\n    # adjust the bounding box to square\n    box = ann[\"objects\"][0]\n    xmin, xmax, ymin, ymax = box[\"xmin\"], box[\"xmax\"], box[\"ymin\"], box[\"ymax\"]\n    xmin, xmax, ymin, ymax = make_square(xmin, xmax, ymin, ymax)\n    # crop a positive sample\n    img = cv2.imread(str(img_src / ann[\"filename\"]))\n    sample = img[ymin:ymax, xmin:xmax]\n    sample = cv2.resize(sample, winSize)\n    positive.append(sample)\n    if len(positive) > num_samples:\n        break\n\n# collect negative samples\nfor xmlfile in ann_src.glob(\"*.xml\"):\n    # load xml\n    ann = read_voc_xml(str(xmlfile))\n    # use only dog photos\n    if ann[\"objects\"][0][\"name\"] == \"cat\":\n        continue\n    # random bounding box: at least the target size to avoid scaling up\n    height, width = img.shape[:2]\n    boxsize = random.randint(winSize[0], min(height, width))\n    x = random.randint(0, width-boxsize)\n    y = random.randint(0, height-boxsize)\n    sample = img[y:y+boxsize, x:x+boxsize]\n    sample = cv2.resize(sample, winSize)\n    negative.append(sample)\n    if len(negative) > num_samples:\n        break\n```", "```py\nsvm = cv2.ml.SVM_create()\nsvm.setType(cv2.ml.SVM_C_SVC)\nsvm.setKernel(cv2.ml.SVM_RBF)\nsvm.setTermCriteria((cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS, 10000, 1e-8))\nsvm.train(data, cv2.ml.ROW_SAMPLE, labels)\nsvm.save('svm_model.yml')\n```", "```py\nimages = positive + negative\nlabels = ([1] * len(positive)) + ([0] * len(negative))\nhog = cv2.HOGDescriptor(winSize, blockSize, blockStride, cellSize, nbins)\ndata = []\nfor img in images:\n    features = hog.compute(img)\n    data.append(features.flatten())\n\ndata = np.array(data, dtype=np.float32)\nlabels = np.array(labels, dtype=np.int32)\n```", "```py\nimport pathlib\nimport random\nimport xml.etree.ElementTree as ET\n\nimport cv2\nimport numpy as np\n\ndef read_voc_xml(xmlfile):\n    \"\"\"read the Pascal VOC XML\"\"\"\n    root = ET.parse(xmlfile).getroot()\n    boxes = {\"filename\": root.find(\"filename\").text,\n             \"objects\": []}\n    for box in root.iter('object'):\n        bb = box.find('bndbox')\n        obj = {\n            \"name\": box.find('name').text,\n            \"xmin\": int(bb.find(\"xmin\").text),\n            \"ymin\": int(bb.find(\"ymin\").text),\n            \"xmax\": int(bb.find(\"xmax\").text),\n            \"ymax\": int(bb.find(\"ymax\").text),\n        }\n        boxes[\"objects\"].append(obj)\n\n    return boxes\n\ndef make_square(xmin, xmax, ymin, ymax):\n    \"\"\"Shrink the bounding box to square shape\"\"\"\n    xcenter = (xmax + xmin) // 2\n    ycenter = (ymax + ymin) // 2\n    halfdim = min(xmax-xmin, ymax-ymin) // 2\n    xmin, xmax = xcenter-halfdim, xcenter+halfdim\n    ymin, ymax = ycenter-halfdim, ycenter+halfdim\n    return xmin, xmax, ymin, ymax\n\n# Define HOG parameters\nwinSize = (64, 64)\nblockSize = (32, 32)\nblockStride = (16, 16)\ncellSize = (16, 16)\nnbins = 9\n\nnum_samples = 1000\n\n# Load your dataset and corresponding bounding box annotations\nbase_path = pathlib.Path(\"oxford-iiit-pet\")\nimg_src = base_path / \"images\"\nann_src = base_path / \"annotations\" / \"xmls\"\n\n# collect samples by cropping the images from dataset\npositive = []\nnegative = []\n\n# collect positive samples\nfor xmlfile in ann_src.glob(\"*.xml\"):\n    # load xml\n    ann = read_voc_xml(str(xmlfile))\n    # use only cat photos\n    if ann[\"objects\"][0][\"name\"] != \"cat\":\n        continue\n    # adjust the bounding box to square\n    box = ann[\"objects\"][0]\n    xmin, xmax, ymin, ymax = box[\"xmin\"], box[\"xmax\"], box[\"ymin\"], box[\"ymax\"]\n    xmin, xmax, ymin, ymax = make_square(xmin, xmax, ymin, ymax)\n    # crop a positive sample\n    img = cv2.imread(str(img_src / ann[\"filename\"]))\n    sample = img[ymin:ymax, xmin:xmax]\n    sample = cv2.resize(sample, winSize)\n    positive.append(sample)\n    if len(positive) > num_samples:\n        break\n\n# collect negative samples\nfor xmlfile in ann_src.glob(\"*.xml\"):\n    # load xml\n    ann = read_voc_xml(str(xmlfile))\n    # use only dog photos\n    if ann[\"objects\"][0][\"name\"] == \"cat\":\n        continue\n    # random bounding box: at least the target size to avoid scaling up\n    height, width = img.shape[:2]\n    boxsize = random.randint(winSize[0], min(height, width))\n    x = random.randint(0, width-boxsize)\n    y = random.randint(0, height-boxsize)\n    sample = img[y:y+boxsize, x:x+boxsize]\n    assert tuple(sample.shape[:2]) == (boxsize, boxsize)\n    sample = cv2.resize(sample, winSize)\n    negative.append(sample)\n    if len(negative) > num_samples:\n        break\n\nimages = positive + negative\nlabels = ([1] * len(positive)) + ([0] * len(negative))\n\n# Create the HOG descriptor and the HOG from each image\nhog = cv2.HOGDescriptor(winSize, blockSize, blockStride, cellSize, nbins)\ndata = []\nfor img in images:\n    features = hog.compute(img)\n    data.append(features.flatten())\n\n# Convert data and labels to numpy arrays\ndata = np.array(data, dtype=np.float32)\nlabels = np.array(labels, dtype=np.int32)\n\n# Train the SVM\nsvm = cv2.ml.SVM_create()\nsvm.setType(cv2.ml.SVM_C_SVC)\nsvm.setKernel(cv2.ml.SVM_RBF)\nsvm.setTermCriteria((cv2.TERM_CRITERIA_MAX_ITER + cv2.TERM_CRITERIA_EPS,\n                     100000,\n                     1e-8))\n\nsvm.train(data, cv2.ml.ROW_SAMPLE, labels)\n\n# Save the SVM model\nsvm.save('svm_model.yml')\nprint(svm.getSupportVectors())\n```", "```py\nwinSize = (64, 64)\nblockSize = (32, 32)\nblockStride = (16, 16)\ncellSize = (16, 16)\nnbins = 9\n\nsvm = cv2.ml.SVM_load('svm_model.yml')\nhog = cv2.HOGDescriptor(winSize, blockSize, blockStride, cellSize, nbins)\nhog.setSVMDetector(svm.getSupportVectors()[0])\n\nlocations, scores = hog.detectMultiScale(img)\nx, y, w, h = locations[np.argmax(scores.flatten())]\ncv2.rectangle(img, (x, y), (x + w, y + h), (255,0,0), 5)\n```", "```py\nimport pathlib\nimport xml.etree.ElementTree as ET\n\nimport cv2\nimport numpy as np\n\ndef read_voc_xml(xmlfile: str) -> dict:\n    \"\"\"read the Pascal VOC XML and return (filename, object name, bounding box)\n    where bounding box is a vector of (xmin, ymin, xmax, ymax). The pixel\n    coordinates are 1-based.\n    \"\"\"\n    root = ET.parse(xmlfile).getroot()\n    boxes = {\"filename\": root.find(\"filename\").text,\n             \"objects\": []\n            }\n    for box in root.iter('object'):\n        bb = box.find('bndbox')\n        obj = {\n            \"name\": box.find('name').text,\n            \"xmin\": int(bb.find(\"xmin\").text),\n            \"ymin\": int(bb.find(\"ymin\").text),\n            \"xmax\": int(bb.find(\"xmax\").text),\n            \"ymax\": int(bb.find(\"ymax\").text),\n        }\n        boxes[\"objects\"].append(obj)\n\n    return boxes\n\n# load the SVM\nwinSize = (64, 64)\nblockSize = (32, 32)\nblockStride = (16, 16)\ncellSize = (16, 16)\nnbins = 9\n\nsvm = cv2.ml.SVM_load('svm_model.yml')\nhog = cv2.HOGDescriptor(winSize, blockSize, blockStride, cellSize, nbins)\nhog.setSVMDetector(svm.getSupportVectors()[0])\n\nbase_path = pathlib.Path(\"oxford-iiit-pet\")\nimg_src = base_path / \"images\"\nann_src = base_path / \"annotations\" / \"xmls\"\n\nfor xmlfile in ann_src.glob(\"*.xml\"):\n    # load xml\n    ann = read_voc_xml(str(xmlfile))\n    # annotate\n    img = cv2.imread(str(img_src / ann[\"filename\"]))\n    bbox = ann[\"objects\"][0]\n    start_point = (bbox[\"xmin\"], bbox[\"ymin\"])\n    end_point = (bbox[\"xmax\"], bbox[\"ymax\"])\n    annotated_img = cv2.rectangle(img, start_point, end_point, (0,0,255), 2)\n    # detect and draw\n    locations, scores = hog.detectMultiScale(img)\n    x, y, w, h = locations[np.argmax(scores.flatten())]\n    cv2.rectangle(img, (x, y), (x + w, y + h), (255,0,0), 5)\n    cv2.imshow(f\"{ann['filename']}: {ann['objects'][0]['name']}\", annotated_img)\n    key = cv2.waitKey(0)\n    cv2.destroyAllWindows()\n    if key == ord('q'):\n        break\n```"]