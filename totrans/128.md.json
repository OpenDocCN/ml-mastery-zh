["```py\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.preprocessing import LabelEncoder\n\n# Read data, convert to NumPy arrays\ndata = pd.read_csv(\"sonar.csv\", header=None)\nX = data.iloc[:, 0:60].values\ny = data.iloc[:, 60].values\n\n# encode class values as integers\nencoder = LabelEncoder()\nencoder.fit(y)\ny = encoder.transform(y)\n\n# convert into PyTorch tensors\nX = torch.tensor(X, dtype=torch.float32)\ny = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n\n# create DataLoader, then take one batch\nloader = DataLoader(list(zip(X,y)), shuffle=True, batch_size=16)\nfor X_batch, y_batch in loader:\n    print(X_batch, y_batch)\n    break\n```", "```py\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split\n\n# train-test split for evaluation of the model\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n\n# set up DataLoader for training set\nloader = DataLoader(list(zip(X_train, y_train)), shuffle=True, batch_size=16)\n\n# create model\nmodel = nn.Sequential(\n    nn.Linear(60, 60),\n    nn.ReLU(),\n    nn.Linear(60, 30),\n    nn.ReLU(),\n    nn.Linear(30, 1),\n    nn.Sigmoid()\n)\n\n# Train the model\nn_epochs = 200\nloss_fn = nn.BCELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.1)\nmodel.train()\nfor epoch in range(n_epochs):\n    for X_batch, y_batch in loader:\n        y_pred = model(X_batch)\n        loss = loss_fn(y_pred, y_batch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n# evaluate accuracy after training\nmodel.eval()\ny_pred = model(X_test)\nacc = (y_pred.round() == y_test).float().mean()\nacc = float(acc)\nprint(\"Model accuracy: %.2f%%\" % (acc*100))\n```", "```py\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\n\n# Read data, convert to NumPy arrays\ndata = pd.read_csv(\"sonar.csv\", header=None)\nX = data.iloc[:, 0:60].values\ny = data.iloc[:, 60].values\n\n# encode class values as integers\nencoder = LabelEncoder()\nencoder.fit(y)\ny = encoder.transform(y)\n\n# convert into PyTorch tensors\nX = torch.tensor(X, dtype=torch.float32)\ny = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n\n# train-test split for evaluation of the model\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, shuffle=True)\n\n# set up DataLoader for training set\nloader = DataLoader(list(zip(X_train, y_train)), shuffle=True, batch_size=16)\n\n# create model\nmodel = nn.Sequential(\n    nn.Linear(60, 60),\n    nn.ReLU(),\n    nn.Linear(60, 30),\n    nn.ReLU(),\n    nn.Linear(30, 1),\n    nn.Sigmoid()\n)\n\n# Train the model\nn_epochs = 200\nloss_fn = nn.BCELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.1)\nmodel.train()\nfor epoch in range(n_epochs):\n    for X_batch, y_batch in loader:\n        y_pred = model(X_batch)\n        loss = loss_fn(y_pred, y_batch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n# evaluate accuracy after training\nmodel.eval()\ny_pred = model(X_test)\nacc = (y_pred.round() == y_test).float().mean()\nacc = float(acc)\nprint(\"Model accuracy: %.2f%%\" % (acc*100))\n```", "```py\nfrom torch.utils.data import Dataset\n\nclass SonarDataset(Dataset):\n    def __init__(self, X, y):\n        # convert into PyTorch tensors and remember them\n        self.X = torch.tensor(X, dtype=torch.float32)\n        self.y = torch.tensor(y, dtype=torch.float32)\n\n    def __len__(self):\n        # this should return the size of the dataset\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        # this should return one sample from the dataset\n        features = self.X[idx]\n        target = self.y[idx]\n        return features, target\n```", "```py\n...\n\n# set up DataLoader for training set\ndataset = SonarDataset(X_train, y_train)\nloader = DataLoader(dataset, shuffle=True, batch_size=16)\n\n# create model\nmodel = nn.Sequential(\n    nn.Linear(60, 60),\n    nn.ReLU(),\n    nn.Linear(60, 30),\n    nn.ReLU(),\n    nn.Linear(30, 1),\n    nn.Sigmoid()\n)\n\n# Train the model\nn_epochs = 200\nloss_fn = nn.BCELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.1)\nmodel.train()\nfor epoch in range(n_epochs):\n    for X_batch, y_batch in loader:\n        y_pred = model(X_batch)\n        loss = loss_fn(y_pred, y_batch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n# evaluate accuracy after training\nmodel.eval()\ny_pred = model(torch.tensor(X_test, dtype=torch.float32))\ny_test = torch.tensor(y_test, dtype=torch.float32)\nacc = (y_pred.round() == y_test).float().mean()\nacc = float(acc)\nprint(\"Model accuracy: %.2f%%\" % (acc*100))\n```", "```py\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, random_split, default_collate\nfrom sklearn.preprocessing import LabelEncoder\n\n# Read data, convert to NumPy arrays\ndata = pd.read_csv(\"sonar.csv\", header=None)\nX = data.iloc[:, 0:60].values\ny = data.iloc[:, 60].values\n\n# encode class values as integers\nencoder = LabelEncoder()\nencoder.fit(y)\ny = encoder.transform(y).reshape(-1, 1)\n\nclass SonarDataset(Dataset):\n    def __init__(self, X, y):\n        # convert into PyTorch tensors and remember them\n        self.X = torch.tensor(X, dtype=torch.float32)\n        self.y = torch.tensor(y, dtype=torch.float32)\n\n    def __len__(self):\n        # this should return the size of the dataset\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        # this should return one sample from the dataset\n        features = self.X[idx]\n        target = self.y[idx]\n        return features, target\n\n# set up DataLoader for data set\ndataset = SonarDataset(X, y)\ntrainset, testset = random_split(dataset, [0.7, 0.3])\nloader = DataLoader(trainset, shuffle=True, batch_size=16)\n\n# create model\nmodel = nn.Sequential(\n    nn.Linear(60, 60),\n    nn.ReLU(),\n    nn.Linear(60, 30),\n    nn.ReLU(),\n    nn.Linear(30, 1),\n    nn.Sigmoid()\n)\n\n# Train the model\nn_epochs = 200\nloss_fn = nn.BCELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.1)\nmodel.train()\nfor epoch in range(n_epochs):\n    for X_batch, y_batch in loader:\n        y_pred = model(X_batch)\n        loss = loss_fn(y_pred, y_batch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n# create one test tensor from the testset\nX_test, y_test = default_collate(testset)\nmodel.eval()\ny_pred = model(X_test)\nacc = (y_pred.round() == y_test).float().mean()\nacc = float(acc)\nprint(\"Model accuracy: %.2f%%\" % (acc*100))\n```"]