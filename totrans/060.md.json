["```py\nconda create -n cvtrain python 'opencv>=3,<4'\nconda activate cvtrain\n```", "```py\n$ opencv_traincascade\nUsage: opencv_traincascade\n  -data <cascade_dir_name>\n  -vec <vec_file_name>\n  -bg <background_file_name>\n  [-numPos <number_of_positive_samples = 2000>]\n  [-numNeg <number_of_negative_samples = 1000>]\n  [-numStages <number_of_stages = 20>]\n  [-precalcValBufSize <precalculated_vals_buffer_size_in_Mb = 1024>]\n  [-precalcIdxBufSize <precalculated_idxs_buffer_size_in_Mb = 1024>]\n  [-baseFormatSave]\n  [-numThreads <max_number_of_threads = 16>]\n  [-acceptanceRatioBreakValue <value> = -1>]\n--cascadeParams--\n  [-stageType <BOOST(default)>]\n  [-featureType <{HAAR(default), LBP, HOG}>]\n  [-w <sampleWidth = 24>]\n  [-h <sampleHeight = 24>]\n--boostParams--\n  [-bt <{DAB, RAB, LB, GAB(default)}>]\n  [-minHitRate <min_hit_rate> = 0.995>]\n  [-maxFalseAlarmRate <max_false_alarm_rate = 0.5>]\n  [-weightTrimRate <weight_trim_rate = 0.95>]\n  [-maxDepth <max_depth_of_weak_tree = 1>]\n  [-maxWeakCount <max_weak_tree_count = 100>]\n--haarFeatureParams--\n  [-mode <BASIC(default) | CORE | ALL\n--lbpFeatureParams--\n--HOGFeatureParams--\n```", "```py\n# create an environment and install opencv 3\npyenv virtualenv 3.11 cvtrain\npyenv activate cvtrain\npip install 'opencv-python>=3,<4'\n```", "```py\n    # download OpenCV source code and switch to 3.4 branch\n    git clone https://github.com/opencv/opencv\n    cd opencv\n    git checkout 3.4\n    cd ..\n    ```", "```py\n    mkdir build\n    cd build\n    ```", "```py\n    cmake ../opencv\n    ```", "```py\n    make\n    ls bin\n    ```", "```py\n<?xml version=\"1.0\"?>\n<annotation>\n  <folder>OXIIIT</folder>\n  <filename>Abyssinian_100.jpg</filename>\n  <source>\n    <database>OXFORD-IIIT Pet Dataset</database>\n    <annotation>OXIIIT</annotation>\n    <image>flickr</image>\n  </source>\n  <size>\n    <width>394</width>\n    <height>500</height>\n    <depth>3</depth>\n  </size>\n  <segmented>0</segmented>\n  <object>\n    <name>cat</name>\n    <pose>Frontal</pose>\n    <truncated>0</truncated>\n    <occluded>0</occluded>\n    <bndbox>\n      <xmin>151</xmin>\n      <ymin>71</ymin>\n      <xmax>335</xmax>\n      <ymax>267</ymax>\n    </bndbox>\n    <difficult>0</difficult>\n  </object>\n</annotation>\n```", "```py\nimport xml.etree.ElementTree as ET\n\ndef read_voc_xml(xmlfile: str) -> dict:\n    root = ET.parse(xmlfile).getroot()\n    boxes = {\"filename\": root.find(\"filename\").text,\n             \"objects\": []}\n    for box in root.iter('object'):\n        bb = box.find('bndbox')\n        obj = {\n            \"name\": box.find('name').text,\n            \"xmin\": int(bb.find(\"xmin\").text),\n            \"ymin\": int(bb.find(\"ymin\").text),\n            \"xmax\": int(bb.find(\"xmax\").text),\n            \"ymax\": int(bb.find(\"ymax\").text),\n        }\n        boxes[\"objects\"].append(obj)\n\n    return boxes\n```", "```py\n{'filename': 'yorkshire_terrier_160.jpg',\n'objects': [{'name': 'dog', 'xmax': 290, 'xmin': 97, 'ymax': 245, 'ymin': 18}]}\n```", "```py\nfilename N x0 y0 w0 h0 x1 y1 w1 h1 ...\n```", "```py\ndataset\n|-- annotations\n|   |-- README\n|   |-- list.txt\n|   |-- test.txt\n|   |-- trainval.txt\n|   |-- trimaps\n|   |   |-- Abyssinian_1.png\n|   |   |-- Abyssinian_10.png\n|   |   ...\n|   |   |-- yorkshire_terrier_98.png\n|   |   `-- yorkshire_terrier_99.png\n|   `-- xmls\n|       |-- Abyssinian_1.xml\n|       |-- Abyssinian_10.xml\n|       ...\n|       |-- yorkshire_terrier_189.xml\n|       `-- yorkshire_terrier_190.xml\n`-- images\n    |-- Abyssinian_1.jpg\n    |-- Abyssinian_10.jpg\n    ...\n    |-- yorkshire_terrier_98.jpg\n    `-- yorkshire_terrier_99.jpg\n```", "```py\nimport pathlib\nimport xml.etree.ElementTree as ET\n\nimport numpy as np\n\ndef read_voc_xml(xmlfile: str) -> dict:\n    \"\"\"read the Pascal VOC XML and return (filename, object name, bounding box)\n    where bounding box is a vector of (xmin, ymin, xmax, ymax). The pixel\n    coordinates are 1-based.\n    \"\"\"\n    root = ET.parse(xmlfile).getroot()\n    boxes = {\"filename\": root.find(\"filename\").text,\n             \"objects\": []\n            }\n    for box in root.iter('object'):\n        bb = box.find('bndbox')\n        obj = {\n            \"name\": box.find('name').text,\n            \"xmin\": int(bb.find(\"xmin\").text),\n            \"ymin\": int(bb.find(\"ymin\").text),\n            \"xmax\": int(bb.find(\"xmax\").text),\n            \"ymax\": int(bb.find(\"ymax\").text),\n        }\n        boxes[\"objects\"].append(obj)\n\n    return boxes\n\n# Read Pascal VOC and write data\nbase_path = pathlib.Path(\"dataset\")\nimg_src = base_path / \"images\"\nann_src = base_path / \"annotations\" / \"xmls\"\n\nnegative = []\npositive = []\nfor xmlfile in ann_src.glob(\"*.xml\"):\n    # load xml\n    ann = read_voc_xml(str(xmlfile))\n    if ann['objects'][0]['name'] == 'dog':\n        # negative sample (dog)\n        negative.append(str(img_src / ann['filename']))\n    else:\n        # positive sample (cats)\n        bbox = []\n        for obj in ann['objects']:\n            x = obj['xmin']\n            y = obj['ymin']\n            w = obj['xmax'] - obj['xmin']\n            h = obj['ymax'] - obj['ymin']\n            bbox.append(f\"{x} {y} {w} {h}\")\n        line = f\"{str(img_src/ann['filename'])} {len(bbox)} {' '.join(bbox)}\"\n        positive.append(line)\n\n# write the output to `negative.dat` and `postiive.dat`\nwith open(\"negative.dat\", \"w\") as fp:\n    fp.write(\"\\n\".join(negative))\n\nwith open(\"positive.dat\", \"w\") as fp:\n    fp.write(\"\\n\".join(positive))\n```", "```py\ndataset/images/Siamese_102.jpg 1 154 92 194 176\ndataset/images/Bengal_152.jpg 1 84 8 187 201\ndataset/images/Abyssinian_195.jpg 1 8 6 109 115\ndataset/images/Russian_Blue_135.jpg 1 228 90 103 117\ndataset/images/Persian_122.jpg 1 60 16 230 228\n```", "```py\nopencv_createsamples -info positive.dat -vec positive.vec -w 30 -h 30\n```", "```py\n# need to create the data dir first\nmkdir cat_detect\n# then run the training\nopencv_traincascade -data cat_detect -vec positive.vec -bg negative.dat -numPos 900 -numNeg 2000 -numStages 10 -w 30 -h 30\n```", "```py\n$ opencv_traincascade -data cat_detect -vec positive.vec -bg negative.dat -numPos 900 -numNeg 2000 -numStages 10 -w 30 -h 30\nPARAMETERS:\ncascadeDirName: cat_detect\nvecFileName: positive.vec\nbgFileName: negative.dat\nnumPos: 900\nnumNeg: 2000\nnumStages: 10\nprecalcValBufSize[Mb] : 1024\nprecalcIdxBufSize[Mb] : 1024\nacceptanceRatioBreakValue : -1\nstageType: BOOST\nfeatureType: HAAR\nsampleWidth: 30\nsampleHeight: 30\nboostType: GAB\nminHitRate: 0.995\nmaxFalseAlarmRate: 0.5\nweightTrimRate: 0.95\nmaxDepth: 1\nmaxWeakCount: 100\nmode: BASIC\nNumber of unique features given windowSize [30,30] : 394725\n\n===== TRAINING 0-stage =====\n<BEGIN\nPOS count : consumed   900 : 900\nNEG count : acceptanceRatio    2000 : 1\nPrecalculation time: 3\n+----+---------+---------+\n|  N |    HR   |    FA   |\n+----+---------+---------+\n|   1|        1|        1|\n+----+---------+---------+\n|   2|        1|        1|\n+----+---------+---------+\n|   3|        1|        1|\n+----+---------+---------+\n|   4|        1|   0.8925|\n+----+---------+---------+\n|   5| 0.998889|   0.7785|\n...\n|  19| 0.995556|    0.503|\n+----+---------+---------+\n|  20| 0.995556|    0.492|\n+----+---------+---------+\nEND>\n...\nTraining until now has taken 0 days 2 hours 55 minutes 44 seconds.\n\n===== TRAINING 9-stage =====\n<BEGIN\nPOS count : consumed   900 : 948\nNEG count : acceptanceRatio    2000 : 0.00723552\nPrecalculation time: 4\n+----+---------+---------+\n|  N |    HR   |    FA   |\n+----+---------+---------+\n|   1|        1|        1|\n+----+---------+---------+\n|   2|        1|        1|\n+----+---------+---------+\n|   3|        1|        1|\n+----+---------+---------+\n|   4|        1|        1|\n+----+---------+---------+\n|   5| 0.997778|   0.9895|\n...\n|  50| 0.995556|   0.5795|\n+----+---------+---------+\n|  51| 0.995556|   0.4895|\n+----+---------+---------+\nEND>\nTraining until now has taken 0 days 3 hours 25 minutes 12 seconds.\n```", "```py\nimport cv2\n\nimage = 'dataset/images/Abyssinian_88.jpg'\nmodel = 'cat_detect/cascade.xml'\n\nclassifier = cv2.CascadeClassifier(model)\nimg = cv2.imread(image)\n\n# Convert the image to grayscale\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n\n# Perform object detection\nobjects = classifier.detectMultiScale(gray,\n                                      scaleFactor=1.1, minNeighbors=5,\n                                      minSize=(30, 30))\n\n# Draw rectangles around detected objects\nfor (x, y, w, h) in objects:\n    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n\n# Display the result\ncv2.imshow('Object Detection', img)\ncv2.waitKey(0)\ncv2.destroyAllWindows()\n```"]