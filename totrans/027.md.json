["```py\n# Load the essential libraries and Ames dataset\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LinearRegression\nimport pandas as pd\n\nAmes = pd.read_csv(\"Ames.csv\").select_dtypes(include=[\"int64\", \"float64\"])\nAmes.dropna(axis=1, inplace=True)\nX = Ames.drop(\"SalePrice\", axis=1)\ny = Ames[\"SalePrice\"]\n\n# Initialize the Linear Regression model\nmodel = LinearRegression()\n\n# Prepare to collect feature scores\nfeature_scores = {}\n\n# Evaluate each feature with cross-validation\nfor feature in X.columns:\n    X_single = X[[feature]]\n    cv_scores = cross_val_score(model, X_single, y)\n    feature_scores[feature] = cv_scores.mean()\n\n# Identify the top 5 features based on mean CV R² scores\nsorted_features = sorted(feature_scores.items(), key=lambda item: item[1], reverse=True)\ntop_5 = sorted_features[0:5]\n\n# Display the top 5 features and their individual performance\nfor feature, score in top_5:\n    print(f\"Feature: {feature}, Mean CV R²: {score:.4f}\")\n```", "```py\nFeature: OverallQual, Mean CV R²: 0.6183\nFeature: GrLivArea, Mean CV R²: 0.5127\nFeature: 1stFlrSF, Mean CV R²: 0.3957\nFeature: YearBuilt, Mean CV R²: 0.2852\nFeature: FullBath, Mean CV R²: 0.2790\n```", "```py\n# Extracting the top 5 features for our multiple linear regression\ntop_features = [feature for feature, score in top_5]\n\n# Building the model with the top 5 features\nX_top = Ames[top_features]\n\n# Evaluating the model with cross-validation\ncv_scores_mlr = cross_val_score(model, X_top, y, cv=5, scoring=\"r2\")\nmean_mlr_score = cv_scores_mlr.mean()\n\nprint(f\"Mean CV R² Score for Multiple Linear Regression Model: {mean_mlr_score:.4f}\")\n```", "```py\nMean CV R² Score for Multiple Linear Regression Model: 0.8003\n```", "```py\n# Perform Sequential Feature Selector with n=5 and build on above code\nfrom sklearn.feature_selection import SequentialFeatureSelector\n\nsfs = SequentialFeatureSelector(model, n_features_to_select=5)\nsfs.fit(X, y)\n\nselected_features = X.columns[sfs.get_support()].to_list()\nprint(f\"Features selected by SFS: {selected_features}\")\n\nscores = cross_val_score(model, Ames[selected_features], y)\nprint(f\"Mean CV R² Score using SFS with n=5: {scores.mean():.4f}\")\n```", "```py\nFeatures selected by SFS: ['GrLivArea', 'OverallQual', 'YearBuilt', '1stFlrSF', 'KitchenAbvGr']\nMean CV R² Score using SFS with n=5: 0.8056\n```", "```py\n# Performance of SFS from 1 feature to maximum, building on code above:\nimport matplotlib.pyplot as plt\n\n# Prepare to store the mean CV R² scores for each number of features\nmean_scores = []\n\n# Iterate over a range from 1 feature to the maximum number of features available\nfor n_features_to_select in range(1, len(X.columns)):\n    sfs = SequentialFeatureSelector(model, n_features_to_select=n_features_to_select)\n    sfs.fit(X, y)\n    selected_features = X.columns[sfs.get_support()]\n    score = cross_val_score(model, X[selected_features], y, cv=5, scoring=\"r2\").mean()\n    mean_scores.append(score)\n\n# Plot the mean CV R² scores against the number of features selected\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, len(X.columns)), mean_scores, marker=\"o\")\nplt.title(\"Performance vs. Number of Features Selected\")\nplt.xlabel(\"Number of Features\")\nplt.ylabel(\"Mean CV R² Score\")\nplt.grid(True)\nplt.show()\n```", "```py\n# Apply Sequential Feature Selector with tolerance = 0.005, building on code above\nsfs_tol = SequentialFeatureSelector(model, n_features_to_select=\"auto\", tol=0.005)\nsfs_tol.fit(X, y)\n\n# Get the number of features selected with tolerance\nn_features_selected = sum(sfs_tol.get_support())\n\n# Prepare to store the mean CV R² scores for each number of features\nmean_scores_tol = []\n\n# Iterate over a range from 1 feature to the Sweet Spot\nfor n_features_to_select in range(1, n_features_selected + 1):\n    sfs = SequentialFeatureSelector(model, n_features_to_select=n_features_to_select)\n    sfs.fit(X, y)\n    selected_features = X.columns[sfs.get_support()]\n    score = cross_val_score(model, X[selected_features], y, cv=5, scoring=\"r2\").mean()\n    mean_scores_tol.append(score)\n\n# Plot the mean CV R² scores against the number of features selected\nplt.figure(figsize=(10, 6))\nplt.plot(range(1, n_features_selected + 1), mean_scores_tol, marker=\"o\")\nplt.title(\"The Sweet Spot: Performance vs. Number of Features Selected\")\nplt.xlabel(\"Number of Features\")\nplt.ylabel(\"Mean CV R² Score\")\nplt.grid(True)\nplt.show()\n```", "```py\n# Print the selected features and their performance, building on the above: \nselected_features = X.columns[sfs_tol.get_support()]\nprint(f\"Number of features selected: {n_features_selected}\")\nprint(f\"Selected features: {selected_features.tolist()}\")\nprint(f\"Mean CV R² Score using SFS with tol=0.005: {mean_scores_tol[-1]:.4f}\")\n```", "```py\nNumber of features selected: 8\nSelected features: ['GrLivArea', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', '1stFlrSF', 'BedroomAbvGr', 'KitchenAbvGr']\nMean CV R² Score using SFS with tol=0.005: 0.8239\n```"]