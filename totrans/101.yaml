- en: A Gentle Introduction to Serialization for Python
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: Python 序列化的温和介绍
- en: 原文：[https://machinelearningmastery.com/a-gentle-introduction-to-serialization-for-python/](https://machinelearningmastery.com/a-gentle-introduction-to-serialization-for-python/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://machinelearningmastery.com/a-gentle-introduction-to-serialization-for-python/](https://machinelearningmastery.com/a-gentle-introduction-to-serialization-for-python/)
- en: Serialization refers to the process of converting a data object (e.g., Python
    objects, Tensorflow models) into a format that allows us to store or transmit
    the data and then recreate the object when needed using the reverse process of
    deserialization.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 序列化是指将数据对象（例如，Python 对象、Tensorflow 模型）转换为一种格式，使我们可以存储或传输数据，然后在需要时使用反序列化的逆过程重新创建该对象。
- en: There are different formats for the serialization of data, such as JSON, XML,
    HDF5, and Python’s pickle, for different purposes. JSON, for instance, returns
    a human-readable string form, while Python’s pickle library can return a byte
    array.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的序列化有不同的格式，如 JSON、XML、HDF5 和 Python 的 pickle，用于不同的目的。例如，JSON 返回人类可读的字符串形式，而
    Python 的 pickle 库则可以返回字节数组。
- en: In this post, you will discover how to use two common serialization libraries
    in Python to serialize data objects (namely pickle and HDF5) such as dictionaries
    and Tensorflow models in Python for storage and transmission.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，你将学习如何使用 Python 中的两个常见序列化库来序列化数据对象（即 pickle 和 HDF5），例如字典和 Tensorflow
    模型，以便于存储和传输。
- en: 'After completing this tutorial, you will know:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 完成本教程后，你将了解：
- en: Serialization libraries in Python such as pickle and h5py
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Python 中的序列化库，如 pickle 和 h5py
- en: Serializing objects such as dictionaries and Tensorflow models in Python
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Python 中序列化诸如字典和 Tensorflow 模型的对象
- en: How to use serialization for memoization to reduce function calls
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何使用序列化进行记忆化以减少函数调用
- en: '**Kick-start your project** with my new book [Python for Machine Learning](https://machinelearningmastery.com/python-for-machine-learning/),
    including *step-by-step tutorials* and the *Python source code* files for all
    examples.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '**快速启动你的项目**，通过我的新书 [Python for Machine Learning](https://machinelearningmastery.com/python-for-machine-learning/)，包括
    *逐步教程* 和所有示例的 *Python 源代码* 文件。'
- en: Let’s get started!![](../Images/5402df89ca73300f99566925bf47d5e0.png)
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧！！[](../Images/5402df89ca73300f99566925bf47d5e0.png)
- en: A Gentle Introduction to Serialization for Python. Photo by [little plant](https://unsplash.com/photos/TZw891-oMio).
    Some rights reserved
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Python 序列化的温和介绍。图片来源 [little plant](https://unsplash.com/photos/TZw891-oMio)。版权所有
- en: Overview
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概述
- en: 'The tutorial is divided into four parts; they are:'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程分为四个部分；它们是：
- en: What is serialization, and why do we serialize?
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是序列化，为什么我们要进行序列化？
- en: Using Python’s pickle library
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 使用 Python 的 pickle 库
- en: Using HDF5 in Python
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在 Python 中使用 HDF5
- en: Comparison between different serialization methods
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同序列化方法的比较
- en: What Is Serialization, and Why Should We Care?
  id: totrans-18
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 什么是序列化，我们为什么要关心它？
- en: Think about storing an integer; how would you store that in a file or transmit
    it? That’s easy! We can just write the integer to a file and store or transmit
    that file.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 想一想如何存储一个整数；你会如何将其存储在文件中或传输？这很简单！我们可以直接将整数写入文件中，然后存储或传输这个文件。
- en: But now, what if we think about storing a Python object (e.g., a Python dictionary
    or a Pandas DataFrame), which has a complex structure and many attributes (e.g.,
    the columns and index of the DataFrame, and the data type of each column)? How
    would you store it as a file or transmit it to another computer?
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 但是现在，如果我们考虑存储一个 Python 对象（例如，一个 Python 字典或一个 Pandas DataFrame），它有一个复杂的结构和许多属性（例如，DataFrame
    的列和索引，以及每列的数据类型）呢？你会如何将它存储为一个文件或传输到另一台计算机上？
- en: This is where serialization comes in!
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是序列化发挥作用的地方！
- en: '**Serialization** is the process of converting the object into a format that
    can be stored or transmitted. After transmitting or storing the serialized data,
    we are able to reconstruct the object later and obtain the exact same structure/object,
    which makes it really convenient for us to continue using the stored object later
    on instead of reconstructing the object from scratch.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**序列化**是将对象转换为可以存储或传输的格式的过程。在传输或存储序列化数据后，我们能够稍后重建对象，并获得完全相同的结构/对象，这使得我们可以在之后继续使用存储的对象，而不必从头开始重建对象。'
- en: In Python, there are many different formats for serialization available. One
    common example of hash maps (Python dictionaries) that works across many languages
    is the JSON file format which is human-readable and allows us to store the dictionary
    and recreate it with the same structure. But JSON can only store basic structures
    such as a list and dictionary, and it can only keep strings and numbers. We cannot
    ask JSON to remember the data type (e.g., numpy float32 vs. float64). It also
    cannot distinguish between Python tuples and lists.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Python 中，有许多不同的序列化格式可供选择。一个跨多种语言的常见示例是 JSON 文件格式，它是可读的并允许我们存储字典并以相同的结构重新创建它。但
    JSON 只能存储基本结构，如列表和字典，并且只能保留字符串和数字。我们不能要求 JSON 记住数据类型（例如，numpy float32 与 float64）。它也无法区分
    Python 元组和列表。
- en: More powerful serialization formats exist. In the following, we will explore
    two common serialization libraries in Python, namely pickle and h5py.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 更强大的序列化格式存在。接下来，我们将探讨两个常见的 Python 序列化库，即 `pickle` 和 `h5py`。
- en: Using Python’s Pickle Library
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 使用 Python 的 Pickle 库
- en: The `pickle` module is part of the Python standard library and implements methods
    to serialize (pickling) and deserialize (unpickling) Python objects.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '`pickle` 模块是 Python 标准库的一部分，实现了序列化（pickling）和反序列化（unpickling）Python 对象的方法。'
- en: 'To get started with `pickle`, import it in Python:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用 `pickle`，请在 Python 中导入它：
- en: '[PRE0]'
  id: totrans-28
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Afterward, to serialize a Python object such as a dictionary and store the byte
    stream as a file, we can use pickle’s `dump()` method.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 之后，为了序列化一个 Python 对象（如字典）并将字节流存储为文件，我们可以使用 `pickle` 的 `dump()` 方法。
- en: '[PRE1]'
  id: totrans-30
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The byte stream representing `test_dict` is now stored in the file “`test.pickle`”!
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 代表`test_dict`的字节流现在存储在文件“`test.pickle`”中！
- en: To recover the original object, we read the serialized byte stream from the
    file using pickle’s `load()` method.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 要恢复原始对象，我们使用 `pickle` 的 `load()` 方法从文件中读取序列化的字节流。
- en: '[PRE2]'
  id: totrans-33
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '**Warning:** Only unpickle data from sources you trust, as it is possible for
    arbitrary malicious code to be executed during the unpickling process.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '**警告：** 仅从您信任的来源反序列化数据，因为在反序列化过程中可能会执行任意恶意代码。'
- en: 'Putting them together, the following code helps you to verify that pickle can
    recover the same object:'
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 将它们结合起来，以下代码帮助您验证 `pickle` 可以恢复相同的对象：
- en: '[PRE3]'
  id: totrans-36
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'Besides writing the serialized object into a pickle file, we can also obtain
    the object serialized as a bytes-array type in Python using pickle’s `dumps()`
    function:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 除了将序列化的对象写入 `pickle` 文件外，我们还可以使用 `pickle` 的 `dumps()` 函数在 Python 中获取序列化为字节数组类型的对象：
- en: '[PRE4]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Similarly, we can use pickle’s load method to convert from a bytes-array type
    back to the original object:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，我们可以使用 `pickle` 的 load 方法将字节数组类型转换回原始对象：
- en: '[PRE5]'
  id: totrans-40
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'One useful thing about pickle is that it can serialize almost any Python object,
    including user-defined ones, such as the following:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '`pickle` 的一个有用功能是它可以序列化几乎任何 Python 对象，包括用户定义的对象，如下所示：'
- en: '[PRE6]'
  id: totrans-42
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: 'The code above will print the following:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码将打印以下内容：
- en: '[PRE7]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Note that the print statement in the class’ constructor is not executed at the
    time `pickle.loads()` is invoked. This is because it reconstructed the object,
    not recreated it.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 注意，在调用 `pickle.loads()` 时，类构造函数中的 print 语句没有执行。这是因为它重建了对象，而不是重新创建它。
- en: 'Pickle can even serialize Python functions since functions are first-class
    objects in Python:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '`pickle` 甚至可以序列化 Python 函数，因为函数在 Python 中是一级对象：'
- en: '[PRE8]'
  id: totrans-47
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'Therefore, we can make use of pickle to save our work. For example, a trained
    model from Keras or scikit-learn can be serialized by pickle and loaded later
    instead of re-training the model every time we use it. The following shows you
    how we can build a LeNet5 model to recognize the MNIST handwritten digits using
    Keras, then serialize the trained model using pickle. Afterward, we can reconstruct
    the model without training it again, and it should produce exactly the same result
    as the original model:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们可以利用 `pickle` 来保存我们的工作。例如，从 Keras 或 scikit-learn 训练的模型可以通过 `pickle` 序列化并在之后加载，而不是每次使用时都重新训练模型。以下示例展示了我们如何使用
    Keras 构建一个 LeNet5 模型来识别 MNIST 手写数字，然后使用 `pickle` 序列化训练好的模型。之后，我们可以在不重新训练的情况下重建模型，它应该会产生与原始模型完全相同的结果：
- en: '[PRE9]'
  id: totrans-49
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: 'The above code will produce the output as follows. Note that the evaluation
    scores from the original and reconstructed models are tied out perfectly in the
    last two lines:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 上述代码将生成如下输出。请注意，原始模型和重建模型的评估分数在最后两行中完全一致：
- en: '[PRE10]'
  id: totrans-51
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: While pickle is a powerful library, it still does have its own limitations to
    what can be pickled. For example, live connections such as database connections
    and opened file handles cannot be pickled. This issue arises because reconstructing
    these objects requires pickle to re-establish the connection with the database/file,
    which is something pickle cannot do for you (because it needs appropriate credentials
    and is out of the scope of what pickle is intended for).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 pickle 是一个强大的库，但它仍然有其自身的限制。例如，无法 pickle 包括数据库连接和已打开的文件句柄在内的活动连接。这个问题的根源在于重建这些对象需要
    pickle 重新建立与数据库/文件的连接，这是 pickle 无法为你做的事情（因为它需要适当的凭证，超出了 pickle 的预期范围）。
- en: Want to Get Started With Python for Machine Learning?
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 想要开始使用 Python 进行机器学习吗？
- en: Take my free 7-day email crash course now (with sample code).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 现在就来参加我的免费 7 天电子邮件速成课程吧（附带示例代码）。
- en: Click to sign-up and also get a free PDF Ebook version of the course.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 点击注册并获取课程的免费 PDF 电子书版本。
- en: Using HDF5 in Python
  id: totrans-56
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Python 中使用 HDF5
- en: Hierarchical Data Format 5 (HDF5) is a binary data format. The `h5py` package
    is a Python library that provides an interface to the HDF5 format. From `h5py`
    docs, HDF5 “lets you store huge amounts of numerical data, and easily manipulate
    that data from Numpy.”
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 层次数据格式 5（HDF5）是一种二进制数据格式。`h5py` 包是一个 Python 库，提供了对 HDF5 格式的接口。根据 `h5py` 文档，HDF5
    “允许你存储大量数值数据，并且可以轻松地使用 Numpy 对该数据进行操作。”
- en: What HDF5 can do better than other serialization formats is store data in a
    file system-like hierarchy. You can store multiple objects or datasets in HDF5,
    like saving multiple files in the file system. You can also read a particular
    dataset from HDF5, like reading one file from the file system without concerning
    the other. If you’re using pickle for this, you will need to read and write everything
    each time you load or create the pickle file. Hence HDF5 is advantageous for huge
    amounts of data that can’t fit entirely into memory.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: HDF5 能比其他序列化格式做得更好的是以文件系统的层次结构存储数据。你可以在 HDF5 中存储多个对象或数据集，就像在文件系统中保存多个文件一样。你也可以从
    HDF5 中读取特定的数据集，就像从文件系统中读取一个文件而不需要考虑其他文件一样。如果你用 pickle 做这件事，每次加载或创建 pickle 文件时都需要读取和写入所有内容。因此，对于无法完全放入内存的大量数据，HDF5
    是一个有利的选择。
- en: 'To get started with `h5py`, you first need to install the `h5py` library, which
    you can do using:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 要开始使用 `h5py`，你首先需要安装 `h5py` 库，可以使用以下命令进行安装：
- en: '[PRE11]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: 'Or, if you are using a conda environment:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 或者，如果你正在使用 conda 环境：
- en: '[PRE12]'
  id: totrans-62
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: We can then get started with creating our first dataset!
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来，我们可以开始创建我们的第一个数据集！
- en: '[PRE13]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: This creates a new dataset in the file `test.hdf5` named “`test_dataset`,” with
    a shape of (100, ) and a type int32\. `h5py` datasets follow a Numpy syntax so
    that you can do slicing, retrieval, get shape, etc., similar to Numpy arrays.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 这将在文件 `test.hdf5` 中创建一个名为 “`test_dataset`” 的新数据集，形状为 (100, )，类型为 int32。`h5py`
    的数据集遵循 Numpy 的语法，因此你可以进行切片、检索、获取形状等操作，类似于 Numpy 数组。
- en: 'To retrieve a specific index:'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 要检索特定索引：
- en: '[PRE14]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: 'To get a slice from index 0 to index 10 of a dataset:'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 要从索引 0 到索引 10 获取数据集的片段：
- en: '[PRE15]'
  id: totrans-69
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: If you initialized the `h5py` file object outside of a `with` statement, remember
    to close the file as well!
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你在 `with` 语句之外初始化了 `h5py` 文件对象，请记得关闭文件！
- en: 'To read from a previously created HDF5 file, you can open the file in “`r`”
    for read mode or “`r+`” for read/write mode:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 要从以前创建的 HDF5 文件中读取数据，你可以以 “`r`” 的方式打开文件进行读取，或者以 “`r+`” 的方式进行读写：
- en: '[PRE16]'
  id: totrans-72
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: 'To organize your HDF5 file, you can use groups:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 要组织你的 HDF5 文件，你可以使用组：
- en: '[PRE17]'
  id: totrans-74
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: 'Another way to create groups and files is by specifying the path to the dataset
    you want to create, and `h5py` will create the groups on that path as well (if
    they don’t exist):'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种创建组和文件的方式是通过指定要创建的数据集的路径，`h5py` 也会在该路径上创建组（如果它们不存在）：
- en: '[PRE18]'
  id: totrans-76
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: The two snippets of code both create `group1` if it has not been created previously
    and then a `dataset1` within `group1`.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这两段代码片段都会在未创建 `group1` 的情况下创建它，然后在 `group1` 中创建 `dataset1`。
- en: HDF5 in Tensorflow
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 在 Tensorflow 中的 HDF5
- en: 'To save a model in Tensorflow Keras using HDF5 format, we can use the `save()`
    function of the model with a filename having extension `.h5`, like the following:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 要在 Tensorflow Keras 中保存模型为 HDF5 格式，我们可以使用模型的 `save()` 函数，并将文件名指定为 `.h5` 扩展名，如下所示：
- en: '[PRE19]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: 'To load the stored HDF5 model, we can also use the function from Keras directly:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 要加载存储的 HDF5 模型，我们也可以直接使用 Keras 中的函数：
- en: '[PRE20]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'One reason we don’t want to use pickle for a Keras model is that we need a
    more flexible format that does not tie to a particular version of Keras. If we
    upgraded our Tensorflow version, the model object might change, and pickle may
    fail to give us a working model. Another reason is to keep only the essential
    data for our model. For example, if we check the HDF5 file `my_model.h5` created
    in the above, we see these are stored:'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 我们不希望为 Keras 模型使用 pickle 的一个原因是，我们需要一种更灵活的格式，不受特定版本 Keras 的限制。如果我们升级了 Tensorflow
    版本，模型对象可能会改变，而 pickle 可能无法给我们一个可工作的模型。另一个原因是保留模型的必要数据。例如，如果我们检查上面创建的 HDF5 文件 `my_model.h5`，我们可以看到其中存储了以下内容：
- en: '[PRE21]'
  id: totrans-84
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: Hence Keras selected only the data that are essential to reconstruct the model.
    A trained model will contain more datasets, namely, there are `/optimizer_weights/`
    besides `/model_weights/`. Keras will reconstruct the model and restore the weights
    appropriately to give us a model that functions the same.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，Keras 仅选择对重建模型至关重要的数据。训练好的模型将包含更多数据集，即 `/optimizer_weights/` 除了 `/model_weights/`。Keras
    将恢复模型并适当地恢复权重，以给我们一个功能相同的模型。
- en: 'Take the example above, for example. We have our model saved in `my_model.h5`.
    Our model is a single dense layer, and we can dig out the kernel of the layer
    by the following:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 以上面的例子为例。我们的模型保存在 `my_model.h5` 中。我们的模型是一个单层的全连接层，我们可以通过以下方式找出该层的内核：
- en: '[PRE22]'
  id: totrans-87
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: 'As we didn’t train our network for anything, it will give us the random matrix
    that initialized the layer:'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 因为我们没有为任何事情训练我们的网络，所以它会给我们初始化层的随机矩阵：
- en: '[PRE23]'
  id: totrans-89
  prefs: []
  type: TYPE_PRE
  zh: '[PRE23]'
- en: 'And in HDF5, the metadata is stored alongside the data. Keras stored the network’s
    architecture in a JSON format in the metadata. Hence we can reproduce our network
    architecture as follows:'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 并且在 HDF5 中，元数据存储在数据旁边。Keras 以 JSON 格式在元数据中存储了网络的架构。因此，我们可以按以下方式复现我们的网络架构：
- en: '[PRE24]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE24]'
- en: 'This produces:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 这会产生：
- en: '[PRE25]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE25]'
- en: The model config (i.e., the architecture of our neural network) and training
    config (i.e., the parameters we passed into the `compile()` function) are stored
    as a JSON string. In the code above, we use the `json` module to reformat it to
    make it easier to read. It is recommended to save your model as HDF5 rather than
    just your Python code because, as we can see above, it contains more detailed
    information than the code on how the network was constructed.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 模型配置（即我们神经网络的架构）和训练配置（即我们传递给 `compile()` 函数的参数）存储为一个 JSON 字符串。在上面的代码中，我们使用 `json`
    模块重新格式化它，以便更容易阅读。建议将您的模型保存为 HDF5，而不仅仅是您的 Python 代码，因为正如我们在上面看到的，它包含比代码更详细的网络构建信息。
- en: Comparing Between Different Serialization Methods
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 比较不同序列化方法之间的差异
- en: In the above, we saw how pickle and h5py can help serialize our Python data.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 在上文中，我们看到 pickle 和 h5py 如何帮助序列化我们的 Python 数据。
- en: We can use pickle to serialize almost any Python object, including user-defined
    ones and functions. But pickle is not language agnostic. You cannot unpickle it
    outside Python. There are even 6 versions of pickle developed so far, and older
    Python may not be able to consume the newer version of pickle data.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以使用 pickle 序列化几乎任何 Python 对象，包括用户定义的对象和函数。但 pickle 不是语言通用的。您不能在 Python 之外反序列化它。到目前为止，甚至有
    6 个版本的 pickle，旧版 Python 可能无法消费新版本的 pickle 数据。
- en: On the contrary, HDF5 is cross-platform and works well with other language such
    as Java and C++. In Python, the `h5py` library implemented the Numpy interface
    to make it easier to manipulate the data. The data can be accessed in a different
    language because the HDF5 format supports only the Numpy data types such as float
    and strings. We cannot store arbitrary objects such as a Python function into
    HDF5.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，HDF5 是跨平台的，并且与其他语言如 Java 和 C++ 兼容良好。在 Python 中，`h5py` 库实现了 Numpy 接口，以便更轻松地操作数据。数据可以在不同语言中访问，因为
    HDF5 格式仅支持 Numpy 的数据类型，如浮点数和字符串。我们不能将任意对象（如 Python 函数）存储到 HDF5 中。
- en: Further Reading
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: This section provides more resources on the topic if you are looking to go deeper.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 本节提供了更多关于此主题的资源，如果您希望深入了解。
- en: Articles
  id: totrans-101
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 文章
- en: Serialization from C# programming guide, [https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/concepts/serialization/](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/concepts/serialization/)
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: C# 编程指南中的序列化，[https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/concepts/serialization/](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/concepts/serialization/)
- en: Save and load Keras models, [https://www.tensorflow.org/guide/keras/save_and_serialize](https://www.tensorflow.org/guide/keras/save_and_serialize)
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 保存和加载 Keras 模型，[https://www.tensorflow.org/guide/keras/save_and_serialize](https://www.tensorflow.org/guide/keras/save_and_serialize)
- en: Libraries
  id: totrans-104
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 库
- en: pickle, [https://docs.python.org/3/library/pickle.html](https://docs.python.org/3/library/pickle.html)
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: pickle，[https://docs.python.org/3/library/pickle.html](https://docs.python.org/3/library/pickle.html)
- en: h5py, [https://docs.h5py.org/en/stable/](https://docs.h5py.org/en/stable/)
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: h5py，[https://docs.h5py.org/en/stable/](https://docs.h5py.org/en/stable/)
- en: APIs
  id: totrans-107
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: API
- en: Tensorflow tf.keras.layers.serialize, [https://www.tensorflow.org/api_docs/python/tf/keras/layers/serialize](https://www.tensorflow.org/api_docs/python/tf/keras/layers/serialize)
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tensorflow tf.keras.layers.serialize，[https://www.tensorflow.org/api_docs/python/tf/keras/layers/serialize](https://www.tensorflow.org/api_docs/python/tf/keras/layers/serialize)
- en: Tensorflow tf.keras.models.load_model, [https://www.tensorflow.org/api_docs/python/tf/keras/models/load_model](https://www.tensorflow.org/api_docs/python/tf/keras/models/load_model)
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tensorflow tf.keras.models.load_model，[https://www.tensorflow.org/api_docs/python/tf/keras/models/load_model](https://www.tensorflow.org/api_docs/python/tf/keras/models/load_model)
- en: Tensorflow tf.keras.models.save_model, [https://www.tensorflow.org/api_docs/python/tf/keras/models/save_model](https://www.tensorflow.org/api_docs/python/tf/keras/models/save_model)
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tensorflow tf.keras.models.save_model，[https://www.tensorflow.org/api_docs/python/tf/keras/models/save_model](https://www.tensorflow.org/api_docs/python/tf/keras/models/save_model)
- en: Summary
  id: totrans-111
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 总结
- en: In this post, you discovered what serialization is and how to use libraries
    in Python to serialize Python objects such as dictionaries and Tensorflow Keras
    models. You have also learned the advantages and disadvantages of two Python libraries
    for serialization (pickle, h5py).
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 在本篇文章中，你将了解什么是序列化以及如何在Python中使用库来序列化Python对象，例如字典和Tensorflow Keras模型。你还学到了两个Python序列化库（pickle、h5py）的优缺点。
- en: 'Specifically, you learned:'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，你学到了：
- en: what is serialization, and why it is useful
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 什么是序列化，以及它的用途
- en: how to get started with pickle and h5py serialization libraries in Python
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何在Python中开始使用pickle和h5py序列化库
- en: pros and cons of different serialization methods
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 不同序列化方法的优缺点
