["```py\nimport numpy as np\nimport torch\nimport cv2\nfrom PIL import Image\nfrom google.colab.patches import cv2_imshow\n\n!pip install 'git+https://github.com/facebookresearch/segment-anything.git'\nfrom segment_anything import sam_model_registry, SamPredictor\n\n!pip install diffusers accelerate\nfrom diffusers import StableDiffusionInpaintPipeline\n\n!wget -q -nc https://dl.fbaipublicfiles.com/segment_anything/sam_vit_b_01ec64.pth\nCHECKPOINT_PATH='/content/sam_vit_b_01ec64.pth'\n\nDEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nMODEL_TYPE = \"vit_b\"\n```", "```py\n# Give the path of your image\nIMAGE_PATH = '/content/Dog.png'\n# Read the image from the path\nimage = cv2.imread(IMAGE_PATH)\ncv2_imshow(image)\n# Convert to RGB format\nimage_rgb = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n```", "```py\nsam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH)\nsam.to(device=DEVICE)\nmask_predictor = SamPredictor(sam)\nmask_predictor.set_image(image_rgb)\n\n# Provide points as input prompt [X, Y]-coordinates\ninput_point = np.array([[250, 250]])\ninput_label = np.array([1])\n\n# Predicting Segmentation mask\nmasks, scores, logits = mask_predictor.predict(\n    point_coords=input_point,\n    point_labels=input_label,\n    multimask_output=False,\n)\n```", "```py\nmask = masks.astype(float) * 255\nmask = np.transpose(mask, (1, 2, 0))\n_ , bw_image = cv2.threshold(mask, 100, 255, cv2.THRESH_BINARY)\ncv2_imshow(bw_image)\ncv2.imwrite('mask.png', bw_image)\ndel sam, mask_predictor   # delete models to conserve GPU memory\n```", "```py\n# Load images using PIL\ninit_image = Image.open(IMAGE_PATH)\nmask_image = Image.open('mask.png')\n\npipe = StableDiffusionInpaintPipeline.from_pretrained(\n    \"runwayml/stable-diffusion-inpainting\", torch_dtype=torch.float16\n)\npipe = pipe.to(DEVICE)\n```", "```py\nprompt = \"a grey cat sitting on a bench, high resolution\"\nimage = pipe(prompt=prompt, image=init_image, mask_image=mask_image).images[0]\nimage.save('output.png')\n```", "```py\nimage = cv2.imread('/content/output.png')\ncv2_imshow(image)\n```", "```py\n# Give the path of your image\nIMAGE_PATH = '/content/Dog.png'\n# Read the image from the path\nimage = cv2.imread(IMAGE_PATH)\nheight, width = image.shape[:2]\npadding = 100 # num pixels to outpaint\nmask = np.ones((height+2*padding, width+2*padding), dtype=np.uint8) * 255\nmask[padding:-padding, padding:-padding] = 0\ncv2_imshow(mask)\ncv2.imwrite(\"mask.png\", mask)\n```", "```py\n# extend the original image\nimage_extended = np.pad(image, ((padding, padding), (padding, padding), (0, 0)), mode='constant', constant_values=128)\ncv2_imshow(image_extended)\ncv2.imwrite(\"image_extended.png\", image_extended)\n```", "```py\n# Load images using PIL\ninit_image = Image.open('image_extended.png')\nmask_image = Image.open('mask.png')\n\npipe = StableDiffusionInpaintPipeline.from_pretrained(\n    \"runwayml/stable-diffusion-inpainting\", torch_dtype=torch.float16\n)\npipe = pipe.to(\"cuda\")\n\ninpaint_image = pipe(prompt=\"a dog on a bench in a park\", image=init_image, mask_image=mask_image).images[0]\ninpaint_image.save('output.png')\n```", "```py\nimage = cv2.imread('/content/output.png')\ncv2_imshow(image)\n```"]