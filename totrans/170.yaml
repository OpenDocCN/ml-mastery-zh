- en: 'Stable Diffusion Project: Reviving Old Photos'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 稳定扩散项目：复兴旧照片
- en: 原文：[https://machinelearningmastery.com/stable-diffusion-project-reviving-old-photos/](https://machinelearningmastery.com/stable-diffusion-project-reviving-old-photos/)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 原文：[https://machinelearningmastery.com/stable-diffusion-project-reviving-old-photos/](https://machinelearningmastery.com/stable-diffusion-project-reviving-old-photos/)
- en: Photography has been around for more than a century. There are many old photos
    around, and probably your family has some, too. Limited by the camera and film
    of the time, you may have photos of low resolution, blurry, or with folds or scratches.
    Restoring these old photos and making them like new ones taken with today’s camera
    is a challenging task, but even you can do that with photo editing software such
    as Photoshop.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 摄影已有一个多世纪的历史。周围有许多旧照片，可能您的家庭也有一些。受当时相机和胶片的限制，您可能有分辨率低、模糊或有折痕或划痕的照片。恢复这些旧照片，使它们像今天用相机拍摄的新照片一样，是一个具有挑战性的任务，但是即使您也可以使用诸如Photoshop等图片编辑软件来完成。
- en: 'In this post, you will see how you can use Stable Diffusion to fix old photos
    and bring a new life to them. After finishing this post, you will learn:'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，您将看到如何使用稳定扩散修复旧照片，并使它们焕发新生。完成本文后，您将学到：
- en: How to clean up defects in scanned photo
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何清除扫描照片中的瑕疵
- en: How to colorize a black and white photo
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何给黑白照片上色
- en: '**Kick-start your project** with my book [Mastering Digital Art with Stable
    Diffusion](https://machinelearningmastery.com/mastering-digital-art-with-stable-diffusion/).
    It provides **self-study tutorials** with **working code**.'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 使用我的书籍[《稳定扩散数字艺术大师》](https://machinelearningmastery.com/mastering-digital-art-with-stable-diffusion/)，**启动您的项目**。它提供**自学教程**和**可运行的代码**。
- en: Let’s get started.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们开始吧。
- en: '![](../Images/e735625e075e47e33f278b9696c92248.png)'
  id: totrans-8
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e735625e075e47e33f278b9696c92248.png)'
- en: 'Stable Diffusion Project: Reviving Old Photos'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 稳定扩散项目：复兴旧照片
- en: Photo by [Antonio Scant](https://unsplash.com/photos/black-and-silver-camera-on-brown-wooden-table-NrcF80ZC8EI).
    Some rights reserved.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 照片由[Antonio Scant](https://unsplash.com/photos/black-and-silver-camera-on-brown-wooden-table-NrcF80ZC8EI)拍摄。部分权利保留。
- en: Overview
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 概览
- en: This tutorial is in three parts; they are
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本教程分为三部分；它们是
- en: Project Idea
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 项目构想
- en: Superresolution
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 超分辨率
- en: Reconstruction
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 重建
- en: Project Idea
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 项目构想
- en: 'Let’s consider an [old photo](https://digitalcollections.nypl.org/items/510d47d9-a975-a3d9-e040-e00a18064a99)
    from the New York Public Library:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来看一个来自纽约公共图书馆的[旧照片](https://digitalcollections.nypl.org/items/510d47d9-a975-a3d9-e040-e00a18064a99)：
- en: '![](../Images/e2d99de9bc5a97f153f0b984b8b67135.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/e2d99de9bc5a97f153f0b984b8b67135.png)'
- en: Photo of “Young oyster shuckers”. From NYPL Digital Collections.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: “年轻的开蚝者”照片。来自NYPL数字收藏。
- en: If you download it, you will notice that the photo is at a low resolution. It
    has a little noise from film grain (not too obvious). And the photo is in black
    and white. The goal of this project is to make this into a high resolution color
    photo depicting the same people.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您下载它，您会注意到照片分辨率低。从胶片颗粒中有少许噪声（不太明显）。照片是黑白的。这个项目的目标是将这个照片制作成高分辨率彩色照片，描绘相同的人物。
- en: Superresolution
  id: totrans-21
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 超分辨率
- en: The original picture has a low resolution. Scaling up the resolution is called
    **super-resolution**, and multiple machine learning models have been developed
    for it.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 原始图片分辨率低。将分辨率放大称为**超分辨率**，已开发了多个机器学习模型用于此目的。
- en: The first step in processing an old photo is to perform superresolution. Usually,
    the old photo is in a low resolution, but that is not the reason. Even if the
    resolution is high (e.g., because you scan the old photo in high resolution),
    you may still want to downsample the photo and run superresolution for its side
    effect of removing noise and film grains.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 处理旧照片的第一步是进行超分辨率处理。通常，旧照片分辨率较低，但这并不是问题所在。即使分辨率很高（例如，因为您以高分辨率扫描了旧照片），您可能仍希望对照片进行降采样，并运行超分辨率以去除噪声和胶片颗粒。
- en: At the Stable Diffusion Web UI, you can upload the photo to the “Extra” tab.
    This tab allows you to do many things but none is related to the diffusion process.
    Rather, it is to apply an image to various existing machine learning models. Here,
    you enable “Upscale” and set “Scale by” for a reasonable factor. For this particular
    photo, you can set the factor to 2\. Then you should pick an upscaler, such as
    “R-ESRGAN 4x+”.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在稳定扩散Web界面中，您可以将照片上传到“额外”选项卡。该选项卡允许您执行许多操作，但与扩散过程无关。相反，它是应用于各种现有机器学习模型的图像。在这里，您可以启用“放大”并设置“按比例缩放”的合理因子。对于这张特定的照片，您可以将因子设置为2。然后，您应该选择一个放大器，例如“R-ESRGAN
    4x+”。
- en: The next thing you can do on the Extra tab is CodeFormer. It is a model for
    fixing faces. Enable it and set the weight. A low weight gives CodeFormer more
    freedom to change the face, while a high weight tends to preserve the original
    facial expressions. The optimal weight should depend on the quality of the original
    photo. If there are more scratches or marks on the faces, you want a lower weight
    to allow for easier reconstruction.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在“Extra”标签页上，您可以做的下一件事是使用 CodeFormer。这是一个用于修复面部的模型。启用它并设置权重。低权重可以使 CodeFormer
    更自由地改变面部，而高权重则倾向于保留原始的面部表情。最佳权重应取决于原始照片的质量。如果面部上有更多划痕或标记，您希望使用较低的权重来更轻松地进行重建。
- en: '![](../Images/2954cd2775a760309601a1d230f60305.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/2954cd2775a760309601a1d230f60305.png)'
- en: Superresolution is the first step in processing an old photo.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 超分辨率是处理旧照片的第一步。
- en: You should download the upscaled output for the next step.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 您应该下载提升后的输出以进行下一步操作。
- en: Reconstruction
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 重建
- en: To reconstruct an old photo, you will use txt2img. You should not use img2img
    because providing the old photo as a starting point is imposing too much influence
    on the output, and you cannot see the correction that you are expecting.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 要重建一张旧照片，您将使用 txt2img。您不应该使用 img2img，因为提供旧照片作为起点会对输出施加太多影响，您无法看到期望的修正。
- en: But first, you should use img2img tab, upload the upscaled output, and click
    on the paper clip icon for the “CLIP interrogator”. This will auto-fill the positive
    prompt based on the uploaded image. You will construct your prompt at the txt2img
    tab based on the CLIP interrogator’s result.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 但首先，您应该在 img2img 标签页中上传提升后的输出，并点击“CLIP 询问器”旁边的纸夹图标。这将根据上传的图像自动填充积极提示。您将根据 CLIP
    询问器的结果在 txt2img 标签页构建您的提示。
- en: '![](../Images/72964ad1603a238aba499d764501d447.png)'
  id: totrans-32
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/72964ad1603a238aba499d764501d447.png)'
- en: You can use CLIP interrogator from the img2img tab
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 您可以在 img2img 标签页中使用 CLIP 询问器。
- en: Now proceed to txt2img tab. Let’s use a SD1.5 model for photorealistic generation,
    such as Realistic Vision v6\. Set the positive prompt, such as
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 现在前往 txt2img 标签页。让我们使用 SD1.5 模型进行逼真生成，例如 Realistic Vision v6。设置积极提示，如
- en: a group of children standing next to each other holding buckets of water and
    wearing hats and dresses with a building in the background, August Sander, a colorized
    photo, wpa, american barbizon school, best quality, 8k raw photo, detailed face
  id: totrans-35
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 一群孩子站在一起，手持水桶，穿着帽子和礼服，背景是一座建筑物，奥古斯特·桑德尔（August Sander）拍摄的彩色照片，WPA，美国巴比松学派，最佳质量，8K
    原始照片，详细的面部
- en: The last few keywords are added to control the style in the output. You can
    use a boilerplate negative prompt, such as
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 最后几个关键词是用来控制输出风格的。您可以使用一个常规的负面提示，例如
- en: drawing, painting, crayon, sketch, graphite, impressionist, noisy, blur, soft,
    deformed, ugly, lowres, bad anatomy, bad hands, cropped, worst quality, low quality,
    normal quality, jpeg artifacts, signature, watermark, monochrome, greyscale, old
    photo
  id: totrans-37
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 绘画，绘画，蜡笔，素描，石墨，印象派，嘈杂，模糊，柔和，畸形，丑陋，低分辨率，坏解剖，坏手，裁剪，最差质量，低质量，普通质量，JPEG伪影，签名，水印，单色，灰度，旧照片
- en: The key for old photo reconstruction is to use ControlNet. You need two ControlNet
    units for the best result.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 旧照片重建的关键是使用 ControlNet。您需要两个 ControlNet 单元以获得最佳结果。
- en: First upload the upscaled image to first ControlNet unit and set the type to
    be Canny. Remember to enable this unit and check “Pixel Perfect”. This helps the
    ControlNet preprocessor to use the optimal resolution. Set the first unit’s control
    weight to 0.8.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 首先将提升后的图像上传到第一个 ControlNet 单元，并设置类型为 Canny。记得启用此单元并勾选“Pixel Perfect”。这有助于 ControlNet
    预处理器使用最佳分辨率。将第一个单元的控制权重设置为 0.8。
- en: Then enable the second ControlNet unit. Upload the same image, turn on Pixel
    Perfect, and select the control type to be “Recolor”. This is a ControlNet model
    to color a black and white photo. You should use “recolor_luminance” model as
    preprocessor. Set the second unit’s control weight to 0.2\. Optionally, you can
    adjust the Gamma correction if you need to fine-tune the output’s brightness.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 然后启用第二个 ControlNet 单元。上传相同的图像，打开 Pixel Perfect，并选择控制类型为“重新着色”。这是一个用于给黑白照片上色的
    ControlNet 模型。您应该使用“recolor_luminance”模型作为预处理器。将第二单元的控制权重设置为 0.2。可选地，您可以调整伽马校正，如果需要微调输出的亮度。
- en: 'Remember to set the output size in txt2img to an aspect ratio similar to the
    original and around the native resolution of your Stable Diffusion model. In this
    example, we use 760×600 pixels. Click generate, you will see the following:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 记得在 txt2img 中设置输出尺寸，以便与原始图像的宽高比类似，并接近你的 Stable Diffusion 模型的原生分辨率。在此示例中，我们使用
    760×600 像素。点击生成，你将看到以下内容：
- en: '![](../Images/5e133f015176cfe571055e79ae594851.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5e133f015176cfe571055e79ae594851.png)'
- en: An old photo colorized using Stable Diffusion
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 一张使用 Stable Diffusion 上色的旧照片
- en: 'You can download the result. Let’s see what you get:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以下载结果。看看你得到的是什么：
- en: '![](../Images/4ec1c0f7cea482a217f3a72a1683bc4f.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4ec1c0f7cea482a217f3a72a1683bc4f.png)'
- en: The reconstructed old photo.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 重建的旧照片。
- en: 'This photo is a bit overexposed but you can see an old photo revived. All the
    details are preserved: All person’s facial expression are kept, the stains on
    the clothes they wore, and so on.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这张照片有些过曝，但你可以看到一张旧照片被复原。所有细节都被保留：人物的面部表情、他们穿的衣物上的污点等等。
- en: But how does it work? This is asking Stable Diffusion to redraw the photo. Hence,
    you need a prompt to guide the diffusion process of the draw. But to control precisely
    the shape and persons, you used the Canny type ControlNet to outline the drawing
    and ask the diffusion process to fit into the outline. However, this outline is
    not perfect because the Canny edge detection algorithm does not convert a picture
    into a line drawing. To lower the distortion, you use the second ControlNet unit
    to recolor the input photo based on brightness. All the original colors were ignored
    (and there were none), and colors were filled based on a machine learning model.
    However, you do not want those defects in the photo. Hence, you set a higher weight
    for Canny and a much lower weight for Recolor.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 那么它是如何工作的？这要求 Stable Diffusion 重新绘制照片。因此，你需要一个提示来指导绘制的扩散过程。但为了精准控制形状和人物，你使用了
    Canny 类型的 ControlNet 来勾勒图像，并要求扩散过程符合轮廓。然而，这个轮廓并不完美，因为 Canny 边缘检测算法无法将照片转换为线条图。为了降低失真，你使用第二个
    ControlNet 单元基于亮度重新上色输入照片。所有原始颜色被忽略（而且没有），颜色是基于机器学习模型填充的。然而，你不希望照片中有这些缺陷。因此，你为
    Canny 设置了更高的权重，为 Recolor 设置了更低的权重。
- en: If you click the generate button again, you may see people wearing clothes of
    different colors. This is because the model is not confident about what color
    they should be wearing. You may want to describe their color in the prompt to
    control that. You can also try to turn off one of the ControlNet units and observe
    the result. The best result should only be obtained when both are working together.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你再次点击生成按钮，你可能会看到人物穿着不同颜色的衣物。这是因为模型对他们应该穿什么颜色没有把握。你可以在提示中描述他们的颜色来控制这一点。你还可以尝试关闭一个
    ControlNet 单元并观察结果。只有当两个单元一起工作时，才能获得最佳结果。
- en: 'Note about a photo with faces: If your original photo is in bad shape that
    the people’s faces are not very recognizable, you want to turn on ADetailer to
    reconstruct the faces. But do that only when necessary! Otherwise you may find
    your photo are depicting entirely different person.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 关于带有面孔的照片的注意事项：如果你的原始照片状况很差，以至于人物面孔不太可辨认，你可能需要启用 ADetailer 来重建面孔。但仅在必要时进行！否则，你可能会发现你的照片描绘了完全不同的人。
- en: In the above, the output was set to resolution 760×600\. But you may want a
    higher resolution than the Stable Diffusion model can support. You can use the
    “Hires. fix” feature in txt2img to run an upscaler after the image is generated.
    The options are very similar to that in Extra tab. But remember to set the denoising
    strength in the upscaler to a low value (such as 0.2) because you do not want
    to impose additional distortion.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述设置中，输出分辨率设置为 760×600。但是，你可能希望获得比 Stable Diffusion 模型支持的更高分辨率。你可以在 txt2img
    中使用“高分辨率修复”功能，在图像生成后运行放大器。选项与 Extra 标签中的非常相似。但记得将放大器中的去噪强度设置为低值（如 0.2），因为你不希望施加额外的失真。
- en: Further Readings
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步阅读
- en: This section provides more resources on the topic if you want to go deeper.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 本节提供了更多关于该主题的资源，如果你想深入了解。
- en: '[Lewis Wickes Hine Documentary Photographs, 1905-1938](https://digitalcollections.nypl.org/collections/lewis-wickes-hine-documentary-photographs-1905-1938#/)
    in New York Public Library Digital Collections'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[Lewis Wickes Hine 纪录片摄影，1905-1938](https://digitalcollections.nypl.org/collections/lewis-wickes-hine-documentary-photographs-1905-1938#/)
    在纽约公共图书馆数字藏品'
- en: Relistic Vision model on [Civitai](https://civitai.com/models/4201/realistic-vision-v60-b1)
    and [Hugging Face Hub](https://huggingface.co/SG161222)
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 在[Civitai](https://civitai.com/models/4201/realistic-vision-v60-b1)和[Hugging
    Face Hub](https://huggingface.co/SG161222)上的**Realistic Vision**模型。
- en: '[OpenModelDB for Upscaling models](https://openmodeldb.info/)'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[OpenModelDB 用于提升模型](https://openmodeldb.info/)'
- en: ControlNet [recolor model](https://civitai.com/models/272562/controlnet-recolor)
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ControlNet的[重新上色模型](https://civitai.com/models/272562/controlnet-recolor)
- en: ControlNet [canny model](https://huggingface.co/lllyasviel/sd-controlnet-canny)
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ControlNet的[canny模型](https://huggingface.co/lllyasviel/sd-controlnet-canny)
- en: Summary
  id: totrans-59
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 摘要
- en: In this post, you cleaned up an old photo. You removed the defects and colored
    a black-and-white photo, bringing the photo to the modern day. In the process,
    you used textual prompts to drive the diffusion process to generate pictures at
    the coarse level. Then you use ControlNet to fine tune the output. You controlled
    the atmosphere at a coarse level and preserved the detail at the fine level. Stable
    Diffusion is to fill the gap and rebuilt the photo.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇文章中，你清理了一张旧照片。你去除了缺陷并给一张黑白照片上色，将其带入了现代。在这个过程中，你使用文本提示来驱动扩散过程，在粗糙层级生成图片。然后你使用ControlNet来微调输出。你在粗略层面控制了氛围，并在精细层面保留了细节。稳定扩散用于填补空白并重建了照片。
