["```py\nimport torch\nimport torchvision\nimport torchvision.transforms as transforms\n\n# import the CIFAR-10 dataset\ntrain_set = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.ToTensor())\ntest_set = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.ToTensor())\n```", "```py\nDownloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n  0%|          | 0/170498071 [00:00<!--?, ?it/s]\nExtracting ./data/cifar-10-python.tar.gz to ./data\nFiles already downloaded and verified\n```", "```py\n# Create the Data object\ndataset = Data()\n```", "```py\nimport torch.nn as nn\n\nclass SimpleNet(nn.Module):\n    def __init__(self, num_classes=10):\n        super(SimpleNet, self).__init__()\n        self.fc1 = nn.Linear(32*32*3, 100) # Fully connected layer with 100 hidden neurons\n        self.fc2 = nn.Linear(100, num_classes) # Fully connected layer with num_classes outputs\n\n    def forward(self, x):\n        x = x.view(-1, 32*32*3) # reshape the input tensor\n        x = self.fc1(x)\n        x = torch.relu(x)\n        x = self.fc2(x)\n        return x\n```", "```py\n# Instantiate the model\nmodel = SimpleNet()\n```", "```py\n# Load the data into PyTorch DataLoader\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=False)\n\n# Define the loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n```", "```py\n# train the model\nnum_epochs = 20\ntrain_loss_history = []\ntrain_acc_history = []\nval_loss_history = []\nval_acc_history = []\n\n# Loop through the number of epochs\nfor epoch in range(num_epochs):\n    train_loss = 0.0\n    train_acc = 0.0\n    val_loss = 0.0\n    val_acc = 0.0\n\n    # set model to train mode\n    model.train()\n    # iterate over the training data\n    for inputs, labels in train_loader:\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        #compute the loss\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        # increment the running loss and accuracy\n        train_loss += loss.item()\n        train_acc += (outputs.argmax(1) == labels).sum().item()\n\n    # calculate the average training loss and accuracy\n    train_loss /= len(train_loader)\n    train_loss_history.append(train_loss)\n    train_acc /= len(train_loader.dataset)\n    train_acc_history.append(train_acc)\n\n    # set the model to evaluation mode\n    model.eval()\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            val_acc += (outputs.argmax(1) == labels).sum().item()\n\n    # calculate the average validation loss and accuracy\n    val_loss /= len(test_loader)\n    val_loss_history.append(val_loss)\n    val_acc /= len(test_loader.dataset)\n    val_acc_history.append(val_acc)\n\n    print(f'Epoch {epoch+1}/{num_epochs}, train loss: {train_loss:.4f}, train acc: {train_acc:.4f}, val loss: {val_loss:.4f}, val acc: {val_acc:.4f}')\n```", "```py\nEpoch 1/20, train loss: 1.8757, train acc: 0.3292, val loss: 1.7515, val acc: 0.3807\nEpoch 2/20, train loss: 1.7254, train acc: 0.3862, val loss: 1.6850, val acc: 0.4008\nEpoch 3/20, train loss: 1.6548, train acc: 0.4124, val loss: 1.6692, val acc: 0.3987\nEpoch 4/20, train loss: 1.6150, train acc: 0.4268, val loss: 1.6052, val acc: 0.4265\nEpoch 5/20, train loss: 1.5874, train acc: 0.4343, val loss: 1.5803, val acc: 0.4384\nEpoch 6/20, train loss: 1.5598, train acc: 0.4424, val loss: 1.5928, val acc: 0.4315\nEpoch 7/20, train loss: 1.5424, train acc: 0.4506, val loss: 1.5489, val acc: 0.4514\nEpoch 8/20, train loss: 1.5310, train acc: 0.4568, val loss: 1.5566, val acc: 0.4454\nEpoch 9/20, train loss: 1.5116, train acc: 0.4626, val loss: 1.5501, val acc: 0.4442\nEpoch 10/20, train loss: 1.5005, train acc: 0.4677, val loss: 1.5282, val acc: 0.4598\nEpoch 11/20, train loss: 1.4911, train acc: 0.4702, val loss: 1.5310, val acc: 0.4629\nEpoch 12/20, train loss: 1.4804, train acc: 0.4756, val loss: 1.5555, val acc: 0.4457\nEpoch 13/20, train loss: 1.4743, train acc: 0.4762, val loss: 1.5207, val acc: 0.4629\nEpoch 14/20, train loss: 1.4658, train acc: 0.4792, val loss: 1.5177, val acc: 0.4570\nEpoch 15/20, train loss: 1.4608, train acc: 0.4819, val loss: 1.5529, val acc: 0.4527\nEpoch 16/20, train loss: 1.4539, train acc: 0.4832, val loss: 1.5066, val acc: 0.4645\nEpoch 17/20, train loss: 1.4486, train acc: 0.4863, val loss: 1.4874, val acc: 0.4727\nEpoch 18/20, train loss: 1.4503, train acc: 0.4866, val loss: 1.5318, val acc: 0.4575\nEpoch 19/20, train loss: 1.4383, train acc: 0.4910, val loss: 1.5065, val acc: 0.4673\nEpoch 20/20, train loss: 1.4348, train acc: 0.4897, val loss: 1.5127, val acc: 0.4679\n```", "```py\nimport matplotlib.pyplot as plt\n\n# Plot the training and validation loss\nplt.plot(train_loss_history, label='train loss')\nplt.plot(val_loss_history, label='val loss')\nplt.legend()\nplt.show()\n\n# Plot the training and validation accuracy\nplt.plot(train_acc_history, label='train acc')\nplt.plot(val_acc_history, label='val acc')\nplt.legend()\nplt.show()\n```", "```py\nimport numpy as np\n\n# get some validation data\nfor inputs, labels in test_loader:\n    break  # this line stops the loop after the first iteration\n\n# make predictions\noutputs = model(inputs)\n_, predicted = torch.max(outputs, 1)\n\n# display the images and their labels\nimg_grid = torchvision.utils.make_grid(inputs)\nimg_grid = img_grid / 2 + 0.5     # unnormalize\nnpimg = img_grid.numpy()\nplt.imshow(np.transpose(npimg, (1, 2, 0)))\n\nprint('True Labels: ', labels)\nprint('Predicted Labels: ', predicted)\n```", "```py\nTrue Labels:  tensor([3, 8, 8, 0, 6, 6, 1, 6, 3, 1, 0, 9, 5, 7, 9, 8, 5, 7, 8, 6, 7, 0, 4, 9,\n        5, 2, 4, 0, 9, 6, 6, 5, 4, 5, 9, 2, 4, 1, 9, 5, 4, 6, 5, 6, 0, 9, 3, 9,\n        7, 6, 9, 8, 0, 3, 8, 8, 7, 7, 4, 6, 7, 3, 6, 3])\nPredicted Labels:  tensor([3, 9, 8, 8, 4, 6, 3, 6, 2, 1, 8, 9, 6, 7, 1, 8, 5, 3, 8, 6, 9, 2, 0, 9,\n        4, 6, 6, 2, 9, 6, 6, 4, 3, 3, 9, 1, 6, 9, 9, 5, 0, 6, 7, 6, 0, 9, 3, 8,\n        4, 6, 9, 4, 6, 3, 8, 8, 5, 8, 8, 2, 7, 3, 6, 9])\n```"]