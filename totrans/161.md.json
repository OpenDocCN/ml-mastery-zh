["```py\nimport torch\nfrom torch.utils.data import Dataset\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\nimport numpy as np\nimport matplotlib.pyplot as plt\ntorch.manual_seed(42)\n```", "```py\ndef imshow(sample_element, shape = (28, 28)):\n    plt.imshow(sample_element[0].numpy().reshape(shape), cmap='gray')\n    plt.title('Label = ' + str(sample_element[1]))\n    plt.show()\n```", "```py\ndataset = datasets.FashionMNIST(\n    root='./data',\n    train=False,\n    download=True,\n    transform=transforms.ToTensor()\n)\n```", "```py\nclasses = dataset.classes\nprint(classes)\n```", "```py\n['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n```", "```py\nprint(dataset.class_to_idx)\n```", "```py\n{'T-shirt/top': 0, 'Trouser': 1, 'Pullover': 2, 'Dress': 3, 'Coat': 4, 'Sandal': 5, 'Shirt': 6, 'Sneaker': 7, 'Bag': 8, 'Ankle boot': 9}\n```", "```py\nimshow(dataset[0])\n```", "```py\nprint(dir(transforms))\n```", "```py\n['AugMix', 'AutoAugment', 'AutoAugmentPolicy', 'CenterCrop', 'ColorJitter',\n 'Compose', 'ConvertImageDtype', 'ElasticTransform', 'FiveCrop', 'GaussianBlur',\n'Grayscale', 'InterpolationMode', 'Lambda', 'LinearTransformation',\n'Normalize', 'PILToTensor', 'Pad', 'RandAugment', 'RandomAdjustSharpness',\n'RandomAffine', 'RandomApply', 'RandomAutocontrast', 'RandomChoice', 'RandomCrop',\n'RandomEqualize', 'RandomErasing', 'RandomGrayscale', 'RandomHorizontalFlip',\n'RandomInvert', 'RandomOrder', 'RandomPerspective', 'RandomPosterize',\n'RandomResizedCrop', 'RandomRotation', 'RandomSolarize', 'RandomVerticalFlip',\n'Resize', 'TenCrop', 'ToPILImage', 'ToTensor', 'TrivialAugmentWide',\n...]\n```", "```py\nrandomcrop_totensor_transform = transforms.Compose([transforms.CenterCrop(16),\n                                                    transforms.ToTensor()])\ndataset = datasets.FashionMNIST(root='./data',\n                                train=False, download=True,\n                                transform=randomcrop_totensor_transform)\nprint(\"shape of the first data sample: \", dataset[0][0].shape)\n```", "```py\nshape of the first data sample:  torch.Size([1, 16, 16])\n```", "```py\nimshow(dataset[0], shape=(16, 16))\n```", "```py\nimport torch\nfrom torch.utils.data import Dataset\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\nimport numpy as np\nimport matplotlib.pyplot as plt\ntorch.manual_seed(42)\n\ndef imshow(sample_element, shape = (28, 28)):\n    plt.imshow(sample_element[0].numpy().reshape(shape), cmap='gray')\n    plt.title('Label = ' + str(sample_element[1]))\n    plt.show()\n\ndataset = datasets.FashionMNIST(\n    root='./data',\n    train=False,\n    download=True,\n    transform=transforms.ToTensor()\n)\n\nclasses = dataset.classes\nprint(classes)\nprint(dataset.class_to_idx)\n\nimshow(dataset[0])\n\nrandomcrop_totensor_transform = transforms.Compose([transforms.CenterCrop(16),\n                                                    transforms.ToTensor()])\ndataset = datasets.FashionMNIST(\n    root='./data',\n    train=False,\n    download=True,\n    transform=randomcrop_totensor_transform)\n)\n\nprint(\"shape of the first data sample: \", dataset[0][0].shape)\nimshow(dataset[0], shape=(16, 16))\n```", "```py\nattface/\n|-- imagedata.csv\n|-- s1/\n|   |-- 1.png\n|   |-- 2.png\n|   |-- 3.png\n|   ...\n|-- s2/\n|   |-- 1.png\n|   |-- 2.png\n|   |-- 3.png\n|   ...\n...\n```", "```py\ns1/1.png,1\ns1/2.png,1\ns1/3.png,1\n...\ns12/1.png,12\ns12/2.png,12\ns12/3.png,12\n```", "```py\nimport os\nimport pandas as pd\nimport numpy as np\nfrom torchvision.io import read_image\n\n# creating object for our image dataset\nclass CustomDatasetForImages(Dataset):\n    # defining constructor\n    def __init__(self, annotations, directory, transform=None):\n        # directory containing the images\n        self.directory = directory\n        annotations_file_dir = os.path.join(self.directory, annotations)\n        # loading the csv with info about images\n        self.labels = pd.read_csv(annotations_file_dir)\n        # transform to be applied on images\n        self.transform = transform\n\n        # Number of images in dataset\n        self.len = self.labels.shape[0]\n\n    # getting the length\n    def __len__(self):\n        return len(self.labels)\n\n    # getting the data items\n    def __getitem__(self, idx):\n        # defining the image path\n        image_path = os.path.join(self.directory, self.labels.iloc[idx, 0])\n        # reading the images\n        image = read_image(image_path)\n        # corresponding class labels of the images \n        label = self.labels.iloc[idx, 1]\n\n        # apply the transform if not set to None\n        if self.transform:\n            image = self.transform(image)\n\n        # returning the image and label\n        return image, label\n```", "```py\ndirectory = \"attface\"\nannotations = \"imagedata.csv\"\ncustom_dataset = CustomDatasetForImages(annotations=annotations,\n                                        directory=directory)\n```", "```py\nrandomcrop_totensor_transform = transforms.RandomCrop(16)\ndataset = CustomDatasetForImages(annotations=annotations,\n                                 directory=directory,\n                                 transform=randomcrop_totensor_transform)\n```"]