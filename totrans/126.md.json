["```py\nimport torch\n\ndef checkpoint(model, filename):\n    torch.save(model.state_dict(), filename)\n\ndef resume(model, filename):\n    model.load_state_dict(torch.load(filename))\n```", "```py\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader, random_split, default_collate\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.preprocessing import LabelEncoder\n\ndata = fetch_openml(\"electricity\", version=1, parser=\"auto\")\n\n# Label encode the target, convert to float tensors\nX = data['data'].astype('float').values\ny = data['target']\nencoder = LabelEncoder()\nencoder.fit(y)\ny = encoder.transform(y)\nX = torch.tensor(X, dtype=torch.float32)\ny = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n\n# train-test split for model evaluation\ntrainset, testset = random_split(TensorDataset(X, y), [0.7, 0.3])\n\n# Define the model\nmodel = nn.Sequential(\n    nn.Linear(8, 12),\n    nn.ReLU(),\n    nn.Linear(12, 12),\n    nn.ReLU(),\n    nn.Linear(12, 1),\n    nn.Sigmoid(),\n)\n\n# Train the model\nn_epochs = 100\nloader = DataLoader(trainset, shuffle=True, batch_size=32)\nX_test, y_test = default_collate(testset)\nloss_fn = nn.BCELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.1)\nfor epoch in range(n_epochs):\n    model.train()\n    for X_batch, y_batch in loader:\n        y_pred = model(X_batch)\n        loss = loss_fn(y_pred, y_batch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    model.eval()\n    y_pred = model(X_test)\n    acc = (y_pred.round() == y_test).float().mean()\n    print(f\"End of epoch {epoch}: accuracy = {float(acc)*100:.2f}%\")\n```", "```py\n...\nfor epoch in range(n_epochs):\n    model.train()\n    for X_batch, y_batch in loader:\n        y_pred = model(X_batch)\n        loss = loss_fn(y_pred, y_batch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    model.eval()\n    y_pred = model(X_test)\n    acc = (y_pred.round() == y_test).float().mean()\n    print(f\"End of epoch {epoch}: accuracy = {float(acc)*100:.2f}%\")\n    checkpoint(model, f\"epoch-{epoch}.pth\")\n```", "```py\nstart_epoch = 0\nif start_epoch > 0:\n    resume_epoch = start_epoch - 1\n    resume(model, f\"epoch-{resume_epoch}.pth\")\n\nfor epoch in range(start_epoch, n_epochs):\n    model.train()\n    for X_batch, y_batch in loader:\n        y_pred = model(X_batch)\n        loss = loss_fn(y_pred, y_batch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    model.eval()\n    y_pred = model(X_test)\n    acc = (y_pred.round() == y_test).float().mean()\n    print(f\"End of epoch {epoch}: accuracy = {float(acc)*100:.2f}%\")\n    checkpoint(model, f\"epoch-{epoch}.pth\")\n```", "```py\ntorch.save({\n    'optimizer': optimizer.state_dict(),\n    'model': model.state_dict(),\n}, filename)\n```", "```py\ncheckpoint = torch.load(filename)\nmodel.load_state_dict(checkpoint['model'])\noptimizer.load_state_dict(checkpoint['optimizer'])\n```", "```py\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader, random_split, default_collate\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.preprocessing import LabelEncoder\n\ndata = fetch_openml(\"electricity\", version=1, parser=\"auto\")\n\n# Label encode the target, convert to float tensors\nX = data['data'].astype('float').values\ny = data['target']\nencoder = LabelEncoder()\nencoder.fit(y)\ny = encoder.transform(y)\nX = torch.tensor(X, dtype=torch.float32)\ny = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n\n# train-test split for model evaluation\ntrainset, testset = random_split(TensorDataset(X, y), [0.7, 0.3])\n\ndef checkpoint(model, filename):\n    torch.save(model.state_dict(), filename)\n\ndef resume(model, filename):\n    model.load_state_dict(torch.load(filename))\n\n# Define the model\nmodel = nn.Sequential(\n    nn.Linear(8, 12),\n    nn.ReLU(),\n    nn.Linear(12, 12),\n    nn.ReLU(),\n    nn.Linear(12, 1),\n    nn.Sigmoid(),\n)\n\n# Train the model\nn_epochs = 100\nstart_epoch = 0\nloader = DataLoader(trainset, shuffle=True, batch_size=32)\nX_test, y_test = default_collate(testset)\nloss_fn = nn.BCELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.1)\n\nif start_epoch > 0:\n    resume_epoch = start_epoch - 1\n    resume(model, f\"epoch-{resume_epoch}.pth\")\n\nfor epoch in range(start_epoch, n_epochs):\n    model.train()\n    for X_batch, y_batch in loader:\n        y_pred = model(X_batch)\n        loss = loss_fn(y_pred, y_batch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    model.eval()\n    y_pred = model(X_test)\n    acc = (y_pred.round() == y_test).float().mean()\n    print(f\"End of epoch {epoch}: accuracy = {float(acc)*100:.2f}%\")\n    checkpoint(model, f\"epoch-{epoch}.pth\")\n```", "```py\n...\nbest_accuracy = -1\nfor epoch in range(start_epoch, n_epochs):\n    model.train()\n    for X_batch, y_batch in loader:\n        y_pred = model(X_batch)\n        loss = loss_fn(y_pred, y_batch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    model.eval()\n    y_pred = model(X_test)\n    acc = (y_pred.round() == y_test).float().mean()\n    acc = float(acc) * 100\n    print(f\"End of epoch {epoch}: accuracy = {acc:.2f}%\")\n    if acc > best_accuracy:\n        best_accuracy = acc\n        checkpoint(model, \"best_model.pth\")\n\nresume(model, \"best_model.pth\")\n```", "```py\nearly_stop_thresh = 5\nbest_accuracy = -1\nbest_epoch = -1\nfor epoch in range(start_epoch, n_epochs):\n    model.train()\n    for X_batch, y_batch in loader:\n        y_pred = model(X_batch)\n        loss = loss_fn(y_pred, y_batch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    model.eval()\n    y_pred = model(X_test)\n    acc = (y_pred.round() == y_test).float().mean()\n    acc = float(acc) * 100\n    print(f\"End of epoch {epoch}: accuracy = {acc:.2f}%\")\n    if acc > best_accuracy:\n        best_accuracy = acc\n        best_epoch = epoch\n        checkpoint(model, \"best_model.pth\")\n    elif epoch - best_epoch > early_stop_thresh:\n        print(\"Early stopped training at epoch %d\" % epoch)\n        break  # terminate the training loop\n\nresume(model, \"best_model.pth\")\n```", "```py\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader, random_split, default_collate\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.preprocessing import LabelEncoder\n\ndata = fetch_openml(\"electricity\", version=1, parser=\"auto\")\n\n# Label encode the target, convert to float tensors\nX = data['data'].astype('float').values\ny = data['target']\nencoder = LabelEncoder()\nencoder.fit(y)\ny = encoder.transform(y)\nX = torch.tensor(X, dtype=torch.float32)\ny = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n\n# train-test split for model evaluation\ntrainset, testset = random_split(TensorDataset(X, y), [0.7, 0.3])\n\ndef checkpoint(model, filename):\n    torch.save(model.state_dict(), filename)\n\ndef resume(model, filename):\n    model.load_state_dict(torch.load(filename))\n\n# Define the model\nmodel = nn.Sequential(\n    nn.Linear(8, 12),\n    nn.ReLU(),\n    nn.Linear(12, 12),\n    nn.ReLU(),\n    nn.Linear(12, 1),\n    nn.Sigmoid(),\n)\n\n# Train the model\nn_epochs = 10000  # more than we needed\nloader = DataLoader(trainset, shuffle=True, batch_size=32)\nX_test, y_test = default_collate(testset)\nloss_fn = nn.BCELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.1)\n\nearly_stop_thresh = 5\nbest_accuracy = -1\nbest_epoch = -1\n\nfor epoch in range(n_epochs):\n    model.train()\n    for X_batch, y_batch in loader:\n        y_pred = model(X_batch)\n        loss = loss_fn(y_pred, y_batch)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    model.eval()\n    y_pred = model(X_test)\n    acc = (y_pred.round() == y_test).float().mean()\n    acc = float(acc) * 100\n    print(f\"End of epoch {epoch}: accuracy = {acc:.2f}%\")\n    if acc > best_accuracy:\n        best_accuracy = acc\n        best_epoch = epoch\n        checkpoint(model, \"best_model.pth\")\n    elif epoch - best_epoch > early_stop_thresh:\n        print(\"Early stopped training at epoch %d\" % epoch)\n        break  # terminate the training loop\n\nresume(model, \"best_model.pth\")\n```", "```py\nEnd of epoch 0: accuracy = 61.84%\nEnd of epoch 1: accuracy = 55.90%\nEnd of epoch 2: accuracy = 63.95%\nEnd of epoch 3: accuracy = 66.87%\nEnd of epoch 4: accuracy = 64.77%\nEnd of epoch 5: accuracy = 60.03%\nEnd of epoch 6: accuracy = 67.16%\nEnd of epoch 7: accuracy = 66.01%\nEnd of epoch 8: accuracy = 62.88%\nEnd of epoch 9: accuracy = 64.28%\nEnd of epoch 10: accuracy = 68.63%\nEnd of epoch 11: accuracy = 70.56%\nEnd of epoch 12: accuracy = 64.62%\nEnd of epoch 13: accuracy = 65.63%\nEnd of epoch 14: accuracy = 66.81%\nEnd of epoch 15: accuracy = 65.11%\nEnd of epoch 16: accuracy = 55.81%\nEnd of epoch 17: accuracy = 54.59%\nEarly stopped training at epoch 17\n```"]